<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Penrose and algorithms from Jesse Mazer on 2007-07-05 (everything)</title>
<meta name="Author" content="Jesse Mazer (lasermazer.domain.name.hidden)" />
<meta name="Subject" content="Re: Penrose and algorithms" />
<meta name="Date" content="2007-07-05" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Penrose and algorithms</h1>
<!-- received="Thu Jul  5 16:14:14 2007" -->
<!-- isoreceived="20070705231414" -->
<!-- sent="Thu, 05 Jul 2007 16:14:03 -0400" -->
<!-- isosent="20070705201403" -->
<!-- name="Jesse Mazer" -->
<!-- email="lasermazer.domain.name.hidden" -->
<!-- subject="Re: Penrose and algorithms" -->
<!-- id="BAY16-F8F1908FA17CB31C0515E0C7020.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="1183662890.652545.69610.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13710" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13711.html" accesskey="d" title="Bruno Marchal: &quot;Re: Penrose and algorithms&quot;">Next message</a> ]
[ <a href="13709.html" title="LauLuna: &quot;Re: Penrose and algorithms&quot;">Previous message</a> ]
[ <a href="13709.html" title="LauLuna: &quot;Re: Penrose and algorithms&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13711.html" accesskey="t" title="Bruno Marchal: &quot;Re: Penrose and algorithms&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13710" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13710" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13710" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13710" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Jesse Mazer &lt;<a href="mailto:lasermazer.domain.name.hidden?Subject=Re%3A%20Penrose%20and%20algorithms">lasermazer.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu, 05 Jul 2007 16:14:03 -0400</span><br />
</address>
<br />
LauLuna wrote:
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;On 29 jun, 19:10, &quot;Jesse Mazer&quot; &lt;laserma....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev2">&gt; &gt; LauLuna  wrote:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;On 29 jun, 02:13, &quot;Jesse Mazer&quot; &lt;laserma....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; LauLuna wrote:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;For any Turing machine there is an equivalent axiomatic system;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;whether we could construct it or not, is of no significance here.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; But for a simulation of a mathematician's brain, the axioms wouldn't 
</em><br />
<em class="quotelev1">&gt;be
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; statements about arithmetic which we could inspect and judge whether
</em><br />
<em class="quotelev3">&gt; &gt; &gt;they
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; were true or false individually, they'd just be statements about the
</em><br />
<em class="quotelev3">&gt; &gt; &gt;initial
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; state and behavior of the simulated brain. So again, there'd be no 
</em><br />
<em class="quotelev1">&gt;way
</em><br />
<em class="quotelev3">&gt; &gt; &gt;to
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; inspect the system and feel perfectly confident the system would 
</em><br />
<em class="quotelev1">&gt;never
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; output a false statement about arithmetic, unlike in the case of the
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; axiomatic systems used by mathematicians to prove theorems.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;Yes, but this is not the point. For any Turing machine performing
</em><br />
<em class="quotelev3">&gt; &gt; &gt;mathematical skills there is also an equivalent mathematical axiomatic
</em><br />
<em class="quotelev3">&gt; &gt; &gt;system; if we are sound Turing machines, then we could never know that
</em><br />
<em class="quotelev3">&gt; &gt; &gt;mathematical system sound, in spite that its axioms are the same we
</em><br />
<em class="quotelev3">&gt; &gt; &gt;use.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I agree, a simulation of a mathematician's brain (or of a giant 
</em><br />
<em class="quotelev1">&gt;simulated
</em><br />
<em class="quotelev2">&gt; &gt; community of mathematicians) cannot be a *knowably* sound system, 
</em><br />
<em class="quotelev1">&gt;because we
</em><br />
<em class="quotelev2">&gt; &gt; can't do the trick of examining each axiom and seeing they are 
</em><br />
<em class="quotelev1">&gt;individually
</em><br />
<em class="quotelev2">&gt; &gt; correct statements about arithmetic as with the normal axiomatic systems
</em><br />
<em class="quotelev2">&gt; &gt; used by mathematicians. But that doesn't mean it's unsound either--it 
</em><br />
<em class="quotelev1">&gt;may in
</em><br />
<em class="quotelev2">&gt; &gt; fact never produce a false statement about arithmetic, it's just that we
</em><br />
<em class="quotelev2">&gt; &gt; can't be sure in advance, the only way to find out is to run it forever 
</em><br />
<em class="quotelev1">&gt;and
</em><br />
<em class="quotelev2">&gt; &gt; check.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Yes, but how can there be a logical impossibility for us to
</em><br />
<em class="quotelev1">&gt;acknowledge as sound the same principles and rules we are using?
</em><br />
<br />The axioms in a simulation of a brain would have nothing to do with the 
<br />
high-level conceptual &quot;principles and rules&quot; we use when thinking about 
<br />
mathematics, they would be axioms concerning the most basic physical laws 
<br />
and microscopic initial conditions of the simulated brain and its simulated 
<br />
environment, like the details of which brain cells are connected by which 
<br />
synapses or how one cell will respond to a particular electrochemical signal 
<br />
from another cell. Just because I think my high-level reasoning is quite 
<br />
reliable in general, that's no reason for me to believe a detailed 
<br />
simulation of my brain would be &quot;sound&quot; in the sense that I'm 100% certain 
<br />
that this precise arrangement of nerve cells in this particular simulated 
<br />
environment, when allowed to evolve indefinitely according to some 
<br />
well-defined deterministic rules, would *never* make a mistake in reasoning 
<br />
and output an incorrect statement about arithmetic (or even that it would 
<br />
never choose to intentionally output a statement it believed to be false 
<br />
just to be contrary).
<br />
<br /><br /><em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; But Penrose was not just arguing that human mathematical ability can't 
</em><br />
<em class="quotelev1">&gt;be
</em><br />
<em class="quotelev2">&gt; &gt; based on a knowably sound algorithm, he was arguing that it must be
</em><br />
<em class="quotelev2">&gt; &gt; *non-algorithmic*.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;No, he argues in Shadows of the Mind exactly what I say. He goes on
</em><br />
<em class="quotelev1">&gt;arguing why a sound algorithm representing human intelligence is
</em><br />
<em class="quotelev1">&gt;unlikely to be not knowably sound.
</em><br />
<br />He does argue that as a first step, but then he goes on to conclude what I 
<br />
said he did, that human intelligence cannot be algorithmic. For example, on 
<br />
p. 40 he makes quite clear that his arguments throughout the rest of the 
<br />
book are intended to show that there must be something non-computational in 
<br />
human mental processes:
<br />
<br />&quot;I shall primarily be concerned, in Part I of this book, with the issue of 
<br />
what it is possible to achieve by use of the mental quality of 
<br />
'understanding.' Though I do not attempt to define what this word means, I 
<br />
hope that its meaning will indeed be clear enough that the reader will be 
<br />
persuaded that this quality--whatever it is--must indeed be an essentail 
<br />
part of that mental activity needed for an acceptance of the arguments of 
<br />
2.5. I propose to show that the appresiation of these arguments must involve 
<br />
something non-computational.&quot;
<br />
<br />Later, on p. 54:
<br />
<br />&quot;Why do I claim that this 'awareness', whatever it is, must be something 
<br />
non-computational, so that no robot, controlled by a computer, based merely 
<br />
on the standard logical ideas of a Turing machine (or equivalent)--whether 
<br />
top-down or bottom-up--can achieve or even simulate it? It is here that the 
<br />
Godelian argument plays its crucial role.&quot;
<br />
<br />His whole Godelian argument is based on the idea that for any computational 
<br />
theorem-proving machine, by examining its construction we can use this 
<br />
&quot;understanding&quot; to find a mathematical statement which *we* know must be 
<br />
true, but which the machine can never output--that we understand something 
<br />
it doesn't. But I think my argument shows that if you were really to build a 
<br />
simulated mathematician or community of mathematicians in a computer, the 
<br />
Godel statement for this system would only be true *if* they never made a 
<br />
mistake in reasoning or chose to output a false statement to be perverse, 
<br />
and that therefore there is no way for us on the outside to have any more 
<br />
confidence about whether they will ever output this statement than they do 
<br />
(and thus neither of us can know whether the statement is actually a true or 
<br />
false theorem of arithmetic).
<br />
<br />It's true that on p. 76, Penrose does restrict his conclusions about &quot;The 
<br />
Godelian Case&quot; to the following statement (which he denotes 'G'):
<br />
<br />&quot;Human mathematicians are not using a knowably sound algorithm in order to 
<br />
ascertain mathematical truth.&quot;
<br />
<br />I have no objection to this proposition on its own, but then in Chapter 3, 
<br />
&quot;The case for non-computability in mathematical thought&quot; he does go on to 
<br />
argue (as the chapter title suggest) that this proposition G justifies the 
<br />
claim that human reasoning must be non-computable. In discussing objections 
<br />
to this argument, he dismisses the possibility that G might be correct but 
<br />
that humans are using an unknowable algorithm, or an unsound algorithm, but 
<br />
as far as I can see he never discusses the possibility I have been 
<br />
suggesting, that an algorithm that faithfully simulated the reasoning of a 
<br />
human mathematician (or community of mathematicians) might be both knowable 
<br />
(in the sense that the beings in the simulation are free to examine their 
<br />
own algorithm) and sound (meaning that if the simulation is run forever, 
<br />
they never output a false statement about arithmetic), but just not knowably 
<br />
sound (meaning that neither they nor us can find a *proof* that will tell us 
<br />
in advance that the simulation will never output a false statement, the only 
<br />
way to check is to run it forever and see).
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;And the impossibility has to be a logical impossibility, not merely a
</em><br />
<em class="quotelev3">&gt; &gt; &gt;technical or physical one since it depends on Gödel's theorem. That's
</em><br />
<em class="quotelev3">&gt; &gt; &gt;a bit odd, isn't it?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; No, I don't see anything very odd about the idea that human mathematical
</em><br />
<em class="quotelev2">&gt; &gt; abilities can't be a knowably sound algorithm--it is no more odd than 
</em><br />
<em class="quotelev1">&gt;the
</em><br />
<em class="quotelev2">&gt; &gt; idea that there are some cellular automata where there is no shortcut to
</em><br />
<em class="quotelev2">&gt; &gt; knowing whether they'll reach a certain state or not other than actually
</em><br />
<em class="quotelev2">&gt; &gt; simulating them, as Wolfram suggests in &quot;A New Kind of Science&quot;.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;The point is that the axioms are exactly our axioms!
</em><br />
<br />Again, the &quot;axioms&quot; would be detailed statements about the initial 
<br />
conditions and behavior of the most basic elements of the simulation--the 
<br />
initial position and velocity of each simulated molecule along with rules 
<br />
for the molecules' behavior, perhaps--not the sort of high-level conceptual 
<br />
axioms we use in our minds when thinking about mathematics. If we can't even 
<br />
predict whether some very simple cellular automata will ever reach a given 
<br />
state, I don't see why it should be surprising that we can't predict whether 
<br />
some very complex physical simulation of an immortal brain and its 
<br />
environment will ever reach a given state (the state in which it decides to 
<br />
output the system's Godel statement, whether because of incorrect reasoning 
<br />
or just out of contrariness).
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;In fact I'd
</em><br />
<em class="quotelev2">&gt; &gt; say it fits nicely with our feeling of &quot;free will&quot;, that there should be 
</em><br />
<em class="quotelev1">&gt;no
</em><br />
<em class="quotelev2">&gt; &gt; way to be sure in advance that we won't break some rules we have been 
</em><br />
<em class="quotelev1">&gt;told
</em><br />
<em class="quotelev2">&gt; &gt; to obey, apart from actually &quot;running&quot; us and seeing what we actually 
</em><br />
<em class="quotelev1">&gt;end up
</em><br />
<em class="quotelev2">&gt; &gt; doing.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;I don't see how to reconcile free will with computationalism either.
</em><br />
<br />I am only talking about the feeling of free will which is perfectly 
<br />
compatible with ultimate determinism (see 
<br />
<a href="http://en.wikipedia.org/wiki/Compatibilism">http://en.wikipedia.org/wiki/Compatibilism</a> ), not the philosophical idea of 
<br />
&quot;libertarian free will&quot; (see 
<br />
<a href="http://en.wikipedia.org/wiki/Libertarianism_(metaphysics">http://en.wikipedia.org/wiki/Libertarianism_(metaphysics</a>) ) which requires 
<br />
determinism to be false. If we had some unerring procedure for predicting 
<br />
whether other people or even ourselves would make a certain decision in the 
<br />
future, it's hard to see how we could still have the same subjective sense 
<br />
of making choices whose outcomes aren't certain until we actually make them.
<br />
<br />Jesse
<br />
<br />_________________________________________________________________
<br />
<a href="http://im.live.com/messenger/im/home/?source=hmtextlinkjuly07">http://im.live.com/messenger/im/home/?source=hmtextlinkjuly07</a>
<br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Thu Jul 05 2007 - 16:14:14 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13710">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13711.html" title="Next message in the list">Bruno Marchal: "Re: Penrose and algorithms"</a></li>
<li><dfn>Previous message</dfn>: <a href="13709.html" title="Previous message in the list">LauLuna: "Re: Penrose and algorithms"</a></li>
<li><dfn>In reply to</dfn>: <a href="13709.html" title="Message to which this message replies">LauLuna: "Re: Penrose and algorithms"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13711.html" title="Next message in this discussion thread">Bruno Marchal: "Re: Penrose and algorithms"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="13711.html" title="Message sent in reply to this message">Bruno Marchal: "Re: Penrose and algorithms"</a></li>
<li><dfn>Reply</dfn>: <a href="13713.html" title="Message sent in reply to this message">LauLuna: "Re: Penrose and algorithms"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13710" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13710" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13710" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13710" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
