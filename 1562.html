<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: The Game of Life from GSLevy.domain.name.hidden on 1999-12-21 (everything)</title>
<meta name="Author" content="GSLevy.domain.name.hidden (GSLevy.domain.name.hidden)" />
<meta name="Subject" content="Re: The Game of Life" />
<meta name="Date" content="1999-12-21" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: The Game of Life</h1>
<!-- received="Tue Dec 21 00:07:59 1999" -->
<!-- isoreceived="19991221080759" -->
<!-- sent="Tue, 21 Dec 1999 03:06:08 EST" -->
<!-- isosent="19991221080608" -->
<!-- name="GSLevy.domain.name.hidden" -->
<!-- email="GSLevy.domain.name.hidden" -->
<!-- subject="Re: The Game of Life" -->
<!-- id="0.571d6dbf.25908ef0.domain.name.hidden" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="The Game of Life" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start1562" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1563.html" accesskey="d" title="Marchal: &quot;Re: The Game of Life&quot;">Next message</a> ]
[ <a href="1561.html" title="Russell Standish: &quot;Re: White Rabbits and QM/Flying rabbits and dragons&quot;">Previous message</a> ]
[ <a href="1471.html" title="Fred Chen: &quot;The Game of Life&quot;">Maybe in reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1563.html" accesskey="t" title="Marchal: &quot;Re: The Game of Life&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1562" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1562" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1562" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1562" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: &lt;<a href="mailto:GSLevy.domain.name.hidden?Subject=Re%3A%20The%20Game%20of%20Life">GSLevy.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 21 Dec 1999 03:06:08 EST</span><br />
</address>
<br />
Sorry, I read Jerry's post too quickly and I was not explicit enough. The 
<br />
paradox I was talking about was the inconsistency that Jerry pointed out 
<br />
about Hal Finney's post. I guess Hal was supporting comp.
<br />
<br />Let me try to be more explicit about my position with regard to comp.
<br />
<br />I believe that it is a necessary condition that consciousness requires a 
<br />
Turing Machine or the equivalent. However, it is not a sufficient condition. 
<br />
For example, a Turing Machine can simulate fluid flow, the weather, the stock 
<br />
market, astronomical events and even the Game of Life. This is not to say 
<br />
that any of those phenomenon, no matter how complicated can lead to 
<br />
consciousness. AN ADDITIONAL CONDITION IS REQUIRED.
<br />
<br />I would like to follow in the footsteps of (I think) Von Neumann and try to 
<br />
describe consciousness, the way he described life. Essentially he said that a 
<br />
living form must include the following functions:
<br />
&nbsp;&nbsp;&nbsp;&nbsp;1) A plan of the living creature itself ( here we have self 
<br />
referentiality)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;2) An execution device (such as a Turing Machine) which reads the plan, 
<br />
execute its instructions including collecting parts and assemble them into a 
<br />
new living form and finally start the execution device in the newly formed 
<br />
living form.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;I think that consciousness requires:
<br />
&nbsp;&nbsp;&nbsp;&nbsp;1) A model of the self (This condition opens the pandora's box of 
<br />
recursion and self-referentiality)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;2) A Turing Machine or the equivalent, which would attempt to simulate 
<br />
the self using the available model. 
<br />
<br />These two conditions lead to an explanation of free will and the feeling of 
<br />
the &quot;I&quot;, &quot;Le Moi&quot; in French. (The English expression &quot;to be reflexive&quot;, to 
<br />
think, is a clue that we are looking at the mental model of our selves in 
<br />
certain thinking situations.)
<br />
<br />Let's create a living form with such a &quot;program&quot; and let's ask it to do the 
<br />
exact opposite of what it would do in a given situation. (I am leading here 
<br />
to Newcomb's paradox: a super being gives you the opportunity to make a 
<br />
million dollars if you make the choice opposite of what you would have made) 
<br />
To answer my question, the creature would simulate itself with its on-board 
<br />
model, but, since this question involves self reference, it would end up in 
<br />
an infinite self referential loop. The result would be total INDETERMINACY: 
<br />
What we call free will. Note: when there is determinacy, there is no free 
<br />
will. 
<br />
<br />As I mentioned a few months ago, free will is also RELATIVE TO THE OBSERVER. 
<br />
A sophisticated observer may predict in advance a persons every single move. 
<br />
In this case this person can be considered, as far as the observer is 
<br />
concerned, to be a robot or a zombie. Yet this sophisticated observer, may 
<br />
himself be observed by an even more intelligent creature and he would be just 
<br />
a zombie in the eyes of this super intelligent creature.
<br />
<br />The &quot;I&quot;, le &quot;Moi&quot; is the decision process BLACK HOLE that we perceive in 
<br />
these situations. FREE WILL is the INDETERMINACY that comes out of this black 
<br />
hole.
<br />
<br />IN SUMMARY: CONSCIOUSNESS IS NOT THE TRIUMPH OF COMP BUT ITS FAILURE!!!!
<br />
Consciousness exist at the boundary between what is computable and what is 
<br />
not.
<br />
<br />And of course the definition of computability depends on the set of axioms or 
<br />
rules or laws that govern your mind, fully in a Godelian sense. Computability 
<br />
is relativistic and the frame of reference is precisely that mental set of 
<br />
axioms or rules or laws. 
<br />
<br />In a perfect state of indecision, that is in a perfect state of 
<br />
indeterminacy, when all the neuronal outputs could equally go one way or the 
<br />
other, in this state, it is probable that quantum effects would become 
<br />
dominant. Hence free will is also a quantum phenomenon AND COMPUTATIONAL 
<br />
INDETERMINACY IS LINKED TO QUANTUM INDETERMINACY. Every time we make a 
<br />
difficult decision, we straddle the quantum branches and end up in all 
<br />
possible worlds. When we make an easy decision we end up in one world.
<br />
<br />George Levy
<br />
<br />n a message dated 12/20/1999 7:46:37 AM Pacific Standard Time, 
<br />
marchal.domain.name.hidden writes:
<br />
<br /><em class="quotelev1">&gt; GSLevy wrote:
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;Jerry makes the mistake of shifting his coordinate system twice, and this 
</em><br />
<em class="quotelev1">&gt; is 
</em><br />
<em class="quotelev2">&gt;  &gt;why the paradox that he describes arises.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  I agree with Jerry here. What paradox ? What error ?
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;
</em><br />
<em class="quotelev2">&gt;  &gt;The first shift in coordinate has to do with 1st and 3rd person.
</em><br />
<em class="quotelev2">&gt;  &gt;Jerry does not see that awareness is a 1st person phenomenon. 
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  I'm not sure that Jerry does not see that awareness is a 1st person 
</em><br />
<em class="quotelev1">&gt;  phenomenon.
</em><br />
<em class="quotelev1">&gt;  When Jerry says:
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;  Are you arguing that a program has to be run before SAS's embodied 
</em><br />
<em class="quotelev2">&gt;  &gt;  in that program experience consciousness? I totally disagree with 
</em><br />
<em class="quotelev2">&gt;  &gt;  this approach, which some people call'computationalism'
</em><br />
<em class="quotelev2">&gt;  &gt;  (confusingly), don't they?
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  I guess that he is talking about Jacques Mallah type of physical
</em><br />
<em class="quotelev1">&gt;   computationalism where there is a need for a &quot;real physical running&quot;
</em><br />
<em class="quotelev1">&gt;  of the machine for consciousness to appear, and so there is a need
</em><br />
<em class="quotelev1">&gt;  for a &quot;real universe&quot; whatever that means.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  GSLevy:
</em><br />
<em class="quotelev2">&gt;  &gt;So those 
</em><br />
<em class="quotelev2">&gt;  &gt;creature in the universe of Life believe themselves to be conscious ( in 
</em><br />
<em class="quotelev1">&gt; the 
</em><br />
<em class="quotelev2">&gt;  &gt;first person) 
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  OK.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;but from the Great Programmer perspective (3rd person) or from 
</em><br />
<em class="quotelev2">&gt;  &gt;any sophisticated external observer they are not.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  Why do you want making these poor little creatures to be
</em><br />
<em class="quotelev1">&gt;  wrong ? And wrong about their own feelings. 
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  How could someone believe to be conscious without being conscious ? 
</em><br />
<em class="quotelev1">&gt;  Consciousness is a &quot;pure&quot; first person phenomenon.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  You *do* believe in 
</em><br />
<em class="quotelev1">&gt;  zombies, don't you ? I mean you think that those creatures are
</em><br />
<em class="quotelev1">&gt;  exactly like us, but that they are unconscious ?
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  Schmidhuber's, not to talk about Tegmark's, universes, or the little 
</em><br />
<em class="quotelev1">&gt;  simple big
</em><br />
<em class="quotelev1">&gt;  everything, all that would be full of creatures believing wrongly they 
</em><br />
<em class="quotelev1">&gt;  feel ?
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  And how could you know you are not among those creatures?
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  (Of course in the UDA it is an *hypothesis* that those machines are 
</em><br />
<em class="quotelev1">&gt;  (relatively) correct.)
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  \begin{for the modalist}
</em><br />
<em class="quotelev1">&gt;  But even without that hypothesis you can also just modelize the 
</em><br />
<em class="quotelev1">&gt;  correcteness 
</em><br />
<em class="quotelev1">&gt;  of the machine by []p -&gt; p, or just by consistency &lt;&gt;T. 
</em><br />
<em class="quotelev1">&gt;  (Jacques Baihache suggests me that I use [] for the modal box and &lt;&gt; for 
</em><br />
<em class="quotelev1">&gt;  the
</em><br />
<em class="quotelev1">&gt;  diamond.) Remeber that [] and &lt;&gt; are interdefinissable: &lt;&gt;p can be seen 
</em><br />
<em class="quotelev1">&gt;  as an 
</em><br />
<em class="quotelev1">&gt;  abreviation of -[]-p, and []p can be seen as an abreviation of -&lt;&gt;-p)
</em><br />
<em class="quotelev1">&gt;  Remember that in classical propositional logic -p is equivalent to p-&gt;F, 
</em><br />
<em class="quotelev1">&gt;  so that &quot;[]F - &gt;F&quot; is equivalent to -[]F, which is equivalent to &lt;&gt;T.
</em><br />
<em class="quotelev1">&gt;   
</em><br />
<em class="quotelev1">&gt;  And let us interview the SRC machine through G and its Guardian Angel G*.
</em><br />
<em class="quotelev1">&gt;  (SRC = self-referentially-correct)
</em><br />
<em class="quotelev1">&gt;  Well the machine seems to remain silent on &lt;&gt;T. The Angel tell us the 
</em><br />
<em class="quotelev1">&gt;  machine is correct (G* proves []p -&gt; p), and consistent (G* proves &lt;&gt;T), 
</em><br />
<em class="quotelev1">&gt;  and he did tell us  that the machine cannot know it, nor justify it 
</em><br />
<em class="quotelev1">&gt;  (G* proves -[]([]p-&gt;p) and G* proves -[]&lt;&gt;T).
</em><br />
<em class="quotelev1">&gt;  Quite the reverse of you, it seems. The little SRC creature seems a little
</em><br />
<em class="quotelev1">&gt;  bit wiser about what she know.
</em><br />
<em class="quotelev1">&gt;  \end{for the modalist}
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  This will not convince you, nor is it intended to convince you. Just to 
</em><br />
<em class="quotelev1">&gt;  tell
</em><br />
<em class="quotelev1">&gt;  you my opinion and the SRC machine's opinion, and its Guardian Angel's, 
</em><br />
<em class="quotelev1">&gt;  opinion. Which is Jerry's opinion too if I
</em><br />
<em class="quotelev1">&gt;  understand and interpret him correctly.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;The second shift has to do with the action of running the program. Before 
</em><br />
<em class="quotelev2">&gt;  &gt;the 
</em><br />
<em class="quotelev2">&gt;  &gt;computer is started, these creatures in the Life Universe do not exist in 
</em><br />
<em class="quotelev2">&gt;  &gt;our 
</em><br />
<em class="quotelev2">&gt;  &gt;*time*. Their time is frozen - compared to ours - so from our point of 
</em><br />
view 
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;  &gt;they are not conscious. They are just a bunch of inert bits. When the 
</em><br />
<em class="quotelev2">&gt;  &gt;computer runs, their time becomes like ours and now they appear to be 
</em><br />
<em class="quotelev2">&gt;  &gt;conscious.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  &quot;Running&quot; a machine is a modality which makes sense only relatively
</em><br />
<em class="quotelev1">&gt;  to you. That relative running makes it possible for the machine to
</em><br />
<em class="quotelev1">&gt;  manifest its consciousness relatively to you. It makes possible
</em><br />
<em class="quotelev1">&gt;  to entangled and share computationnal histories. But consciousness per se
</em><br />
<em class="quotelev1">&gt;  is not linked to the dynamical physical activity itself.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;Resolution of this paradox illustrates the relativistic issues in the 
</em><br />
<em class="quotelev2">&gt;  &gt;observation process and in particular the relativistic quality of the 
</em><br />
<em class="quotelev2">&gt;  &gt;1st/3rd 
</em><br />
<em class="quotelev2">&gt;  &gt;person point of view.  
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  I don't understand.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev2">&gt;  &gt;The relativity of information in terms of mutual 
</em><br />
<em class="quotelev2">&gt;  &gt;information as defined by Claude Shannon has deep consequences in physics 
</em><br />
<em class="quotelev2">&gt;  &gt;that, I feel, should be explored. In this context, Hawkings has made a 
</em><br />
<em class="quotelev1">&gt; major 
</em><br />
<em class="quotelev2">&gt;  &gt;breakthrough in the understanding of black holes by relating entropy to 
</em><br />
<em class="quotelev2">&gt;  &gt;their 
</em><br />
<em class="quotelev2">&gt;  &gt;size.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  I agree although I'm not sure to see the relevance here.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  Perhaps you are correct on all the points in which case comp should
</em><br />
<em class="quotelev1">&gt;  be wrong (or my reasoning!).
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  Bruno
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<span id="received"><dfn>Received on</dfn> Tue Dec 21 1999 - 00:07:59 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start1562">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1563.html" title="Next message in the list">Marchal: "Re: The Game of Life"</a></li>
<li><dfn>Previous message</dfn>: <a href="1561.html" title="Previous message in the list">Russell Standish: "Re: White Rabbits and QM/Flying rabbits and dragons"</a></li>
<li><dfn>Maybe in reply to</dfn>: <a href="1471.html" title="Message to which this message replies">Fred Chen: "The Game of Life"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1563.html" title="Next message in this discussion thread">Marchal: "Re: The Game of Life"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1562" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1562" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1562" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1562" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
