<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Consciousness is information? from Bruno Marchal on 2009-05-19 (everything)</title>
<meta name="Author" content="Bruno Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: Consciousness is information?" />
<meta name="Date" content="2009-05-19" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Consciousness is information?</h1>
<!-- received="Tue May 19 19:37:30 2009" -->
<!-- isoreceived="20090520023730" -->
<!-- sent="Tue, 19 May 2009 19:37:30 +0200" -->
<!-- isosent="20090519173730" -->
<!-- name="Bruno Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: Consciousness is information?" -->
<!-- id="135D8E01-539A-43A4-966B-E28703CCDBFE.domain.name.hidden" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="a7501beb-20bf-4650-8702-501695759d7d.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start16655" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="16656.html" accesskey="d" title="ronaldheld: &quot;Re: No MWI&quot;">Next message</a> ]
[ <a href="16654.html" title="Bruno Marchal: &quot;Re: Consciousness is information?&quot;">Previous message</a> ]
[ <a href="16649.html" title="Alberto G.Corona: &quot;Re: Consciousness is information?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="16658.html" accesskey="t" title="Alberto G.Corona: &quot;Re: Consciousness is information?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg16655" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg16655" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg16655" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg16655" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Bruno Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20Consciousness%20is%20information%3F">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 19 May 2009 19:37:30 +0200</span><br />
</address>
<br />
Hi Alberto,
<br />
<br />On 19 May 2009, at 11:37, Alberto G.Corona wrote:
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That is also my case. I wonder how the materialist hypothesis has
</em><br />
<em class="quotelev1">&gt; advanced in a plausible explanation of consciousness, and I think that
</em><br />
<em class="quotelev1">&gt; this is the right path, and I follow it. But at the deep level, my
</em><br />
<em class="quotelev1">&gt; subjective experience tells me that I must remain dualist.
</em><br />
<br />I am glad you are not an eliminative materialist. But you tell us that  
<br />
you remain a weak-materialist? You believe there is a primary physical  
<br />
or material world, and that physics is the fundamental science. OK?
<br />
The point of most of my posts here is to explain this does not work,  
<br />
at least once we accept the computationalist hypothesis in the  
<br />
cognitive science.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I think however that for evolutionary purposes, the consciousness,
</em><br />
<em class="quotelev1">&gt; being designed by natural selection for keeping an accurate picture of
</em><br />
<em class="quotelev1">&gt; how the others see us, must naturally reject a materialist explanation
</em><br />
<em class="quotelev1">&gt; because this is not an accurate picture.
</em><br />
<br />You mean &quot;must reject eliminative materialism&quot;. I agree with you. All  
<br />
sentient beings do that naturally.
<br />
<br /><br /><br /><em class="quotelev1">&gt; The other people do not see
</em><br />
<em class="quotelev1">&gt; us as a piece of evolved mechanisms, but as moral beings.
</em><br />
<br />As person, yes.
<br />
<br /><br /><br /><em class="quotelev1">&gt; An adaptive
</em><br />
<em class="quotelev1">&gt; self must be, and is, fiercely dualist, with a strong notion of self
</em><br />
<em class="quotelev1">&gt; autonomy and unit of purpose. So all of us feel that way when not
</em><br />
<em class="quotelev1">&gt; thinking about that.
</em><br />
<br />Why dualist? Well, I do agree even animals feel themselves implicitly  
<br />
dualist, they believe they are hungry and that food exist. They does  
<br />
not reflect much on the difference between the appearance of  
<br />
substantial food and they first person hungriness.
<br />
But comp forces us to abandon weak materialism, like I think most of  
<br />
the greek and Indian philosophers already did intuit. The appearance  
<br />
of matter is appearance of something else. The days I believe in comp,  
<br />
I feel myself fiercely monist: I believe, those days, that matter is a  
<br />
construction of the mind. Not the human mind, but the universal  
<br />
machines mind. UDA is an argument showing that the current  
<br />
paradigmatic chain MATTER =&gt; CONSCIOUSNESS =&gt; NUMBER is reversed: with  
<br />
comp I can explain too you in details (it is long) that the chain  
<br />
should be NUMBER =&gt; CONSCIOUSNESS =&gt; MATTER. Some agree already that  
<br />
it could be NUMBER =&gt; MATTER =&gt; CONSCIOUSNESS, and this indeed is more  
<br />
locally obvious, yet I pretend that comp forces eventually the  
<br />
complete reversal.
<br />
Here I agree with Kelly, and probably some others: idealism, or  
<br />
spiritual/mental/informational/number-theoretical monism is where we  
<br />
go, and have to go, once we bet we can survive with a digital brain. I  
<br />
don't pretend this is obvious, but I have an argument, called UDA. It  
<br />
is a constructive argument, it shows how to explicitly derive the  
<br />
physical laws from a theory of mind (computer science), so that we can  
<br />
test comp empirically, by comparing the physics from comp and the  
<br />
physics from usual observation of our neighborhood. Would the world  
<br />
still look Newtonian, I would never dare to suggest that comp is  
<br />
possible. Thanks to QM, the possibility of comp remains. (And QM's MWI  
<br />
prevent comp from solipsism, in case you worried).
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Thus, maybe if ever a robot is made to simulate our behavior must
</em><br />
<em class="quotelev1">&gt; incorporate an inner rejection of materialist explanation about the
</em><br />
<em class="quotelev1">&gt; nature of his higher level circuits, and a vivid notion of subjective
</em><br />
<em class="quotelev1">&gt; experience.
</em><br />
<br />Note that even physicalist explanations are more and more  
<br />
mathematical, and does never really refer to metaphysical materialism.  
<br />
But such beliefs lives in the background, and when defended leads  
<br />
often to eliminativism (of person), or dualism, which are rarely  
<br />
intelligible, or epiphenomenalism, where consciousness loss its grip  
<br />
to reality.
<br />
<br /><br /><br /><br /><br /><em class="quotelev1">&gt; That is not difficult at a certain level of technology, to
</em><br />
<em class="quotelev1">&gt; create a central “self” module that receives the filtered, relevant
</em><br />
<em class="quotelev1">&gt; information, plus information of the commands and actions of other
</em><br />
<em class="quotelev1">&gt; decision modules. This self module must be capable of &quot;inventing&quot; (and
</em><br />
<em class="quotelev1">&gt; that´s the tricky thing) a self centered, socially plausible, moral
</em><br />
<em class="quotelev1">&gt; history that link together such perceptions and such actions.
</em><br />
<br /><br />In our case, we can bet we belong to deep computational histories,  
<br />
which give serious hints.
<br />
<br /><br /><br /><em class="quotelev1">&gt; Then,
</em><br />
<em class="quotelev1">&gt; when someone ask him &quot;do you have subjective experience, qualia and so
</em><br />
<em class="quotelev1">&gt; on&quot; the robot will answer, “of cause, yes, I have a very strong
</em><br />
<em class="quotelev1">&gt; sensation of unity of mind, perception and I´m a moral subject capable
</em><br />
<em class="quotelev1">&gt; of self determination”.  Otherwise, he will be inconsistent or non
</em><br />
<em class="quotelev1">&gt; functional as human simulation.
</em><br />
<br />This is a bit tautological, but OK.
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; By the way, the role of the self process as a creator of self centered
</em><br />
<em class="quotelev1">&gt; histories that are credible for the rest of us, that tend to show a
</em><br />
<em class="quotelev1">&gt; favorable moral image of the self has been checked in different
</em><br />
<em class="quotelev1">&gt; experiments, especially with lobotomized people (that invent two
</em><br />
<em class="quotelev1">&gt; different histories of the same perception-action in each hemisphere).
</em><br />
<em class="quotelev1">&gt; It also explains many mental disorders: compulsive liars and crazy
</em><br />
<em class="quotelev1">&gt; overhyped egos made of fantastic histories (reincarnations of
</em><br />
<em class="quotelev1">&gt; Napoleon) for example. It also explains many effects in social life of
</em><br />
<em class="quotelev1">&gt; sane people. How hard is to achieve objectivity, for example?
</em><br />
<br /><br />Right. I agree here. And objectivity exists only as far as we can  
<br />
doubt it, by being clear o sharable hypotheses and questions, so that  
<br />
all person can confirm the theories locally or refute it globally. OK.
<br />
<br />I think Kelly's point is a defense of monism, but idealist monism, not  
<br />
materialist monism. (Kelly: correct me if I was wrong). I think that  
<br />
if we accept the computationalist hypothesis, we must indeed abandon  
<br />
materialism, even weak materialism: the metaphysical doctrine of the  
<br />
material ontological commitment.  (some people are &quot;religious&quot; about  
<br />
that!)
<br />
Substantial matter can subsist, but it looses all explanatory powers,  
<br />
because it appears to be a reification of a projection of infinities  
<br />
of computations or number relations (or combinators relation , or  
<br />
relations on any finite concepts as rich as numbers you want to use)  
<br />
as &quot;seen&quot;, observed, betted, etc.  by the machine/numbers/finite  
<br />
entities themselves.
<br />
<br />Bruno
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; On May 18, 4:50 am, Kelly Harmon &lt;harmon....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev2">&gt;&gt; On Sun, May 17, 2009 at 9:13 PM, Brent Meeker  
</em><br />
<em class="quotelev2">&gt;&gt; &lt;meeke....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; Generally I don't think that what we experience is necessarily  
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; caused
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; by physical systems.  I think that sometimes physical systems  
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; assume
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; configurations that &quot;shadow&quot;, or represent, our conscious  
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; experience.
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; But they don't CAUSE our conscious experience.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; So if we could track the functions of the brain at a fine enough  
</em><br />
<em class="quotelev3">&gt;&gt;&gt; scale,
</em><br />
<em class="quotelev3">&gt;&gt;&gt; we'd see physical events that didn't have physical causes (ones that
</em><br />
<em class="quotelev3">&gt;&gt;&gt; were caused by mental events?).
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; No, no, no.  I'm not saying that at all.  Ultimately I'm saying that
</em><br />
<em class="quotelev2">&gt;&gt; if there is a physical world, it's irrelevant to consciousness.
</em><br />
<em class="quotelev2">&gt;&gt; Consciousness is information.  Physical systems can be interpreted as
</em><br />
<em class="quotelev2">&gt;&gt; representing, or &quot;storing&quot;, information, but that act of &quot;storage&quot;
</em><br />
<em class="quotelev2">&gt;&gt; isn't what gives rise to conscious experience.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; You're aware of course that the same things were said about the
</em><br />
<em class="quotelev3">&gt;&gt;&gt; physio/chemical bases of life.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; You mentioned that point before, as I recall.  Dennett made a similar
</em><br />
<em class="quotelev2">&gt;&gt; argument against Chalmers, to which Chalmers had what I thought was  
</em><br />
<em class="quotelev2">&gt;&gt; an
</em><br />
<em class="quotelev2">&gt;&gt; effective response:
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; -------<a href="http://consc.net/papers/moving.html">http://consc.net/papers/moving.html</a>
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Perhaps the most common strategy for a type-A materialist is to
</em><br />
<em class="quotelev2">&gt;&gt; deflate the &quot;hard problem&quot; by using analogies to other domains, where
</em><br />
<em class="quotelev2">&gt;&gt; talk of such a problem would be misguided. Thus Dennett imagines a
</em><br />
<em class="quotelev2">&gt;&gt; vitalist arguing about the hard problem of &quot;life&quot;, or a  
</em><br />
<em class="quotelev2">&gt;&gt; neuroscientist
</em><br />
<em class="quotelev2">&gt;&gt; arguing about the hard problem of &quot;perception&quot;. Similarly, Paul
</em><br />
<em class="quotelev2">&gt;&gt; Churchland (1996) imagines a nineteenth century philosopher worrying
</em><br />
<em class="quotelev2">&gt;&gt; about the hard problem of &quot;light&quot;, and Patricia Churchland brings up
</em><br />
<em class="quotelev2">&gt;&gt; an analogy involving &quot;heat&quot;. In all these cases, we are to suppose,
</em><br />
<em class="quotelev2">&gt;&gt; someone might once have thought that more needed explaining than
</em><br />
<em class="quotelev2">&gt;&gt; structure and function; but in each case, science has proved them
</em><br />
<em class="quotelev2">&gt;&gt; wrong. So perhaps the argument about consciousness is no better.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; This sort of argument cannot bear much weight, however. Pointing out
</em><br />
<em class="quotelev2">&gt;&gt; that analogous arguments do not work in other domains is no news: the
</em><br />
<em class="quotelev2">&gt;&gt; whole point of anti-reductionist arguments about consciousness is  
</em><br />
<em class="quotelev2">&gt;&gt; that
</em><br />
<em class="quotelev2">&gt;&gt; there is a disanalogy between the problem of consciousness and
</em><br />
<em class="quotelev2">&gt;&gt; problems in other domains. As for the claim that analogous arguments
</em><br />
<em class="quotelev2">&gt;&gt; in such domains might once have been plausible, this strikes me as
</em><br />
<em class="quotelev2">&gt;&gt; something of a convenient myth: in the other domains, it is more or
</em><br />
<em class="quotelev2">&gt;&gt; less obvious that structure and function are what need explaining, at
</em><br />
<em class="quotelev2">&gt;&gt; least once any experiential aspects are left aside, and one would be
</em><br />
<em class="quotelev2">&gt;&gt; hard pressed to find a substantial body of people who ever argued
</em><br />
<em class="quotelev2">&gt;&gt; otherwise.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; When it comes to the problem of life, for example, it is just obvious
</em><br />
<em class="quotelev2">&gt;&gt; that what needs explaining is structure and function: How does a
</em><br />
<em class="quotelev2">&gt;&gt; living system self-organize? How does it adapt to its environment?  
</em><br />
<em class="quotelev2">&gt;&gt; How
</em><br />
<em class="quotelev2">&gt;&gt; does it reproduce? Even the vitalists recognized this central point:
</em><br />
<em class="quotelev2">&gt;&gt; their driving question was always &quot;How could a mere physical system
</em><br />
<em class="quotelev2">&gt;&gt; perform these complex functions?&quot;, not &quot;Why are these functions
</em><br />
<em class="quotelev2">&gt;&gt; accompanied by life?&quot; It is no accident that Dennett's version of a
</em><br />
<em class="quotelev2">&gt;&gt; vitalist is &quot;imaginary&quot;. There is no distinct &quot;hard problem&quot; of life,
</em><br />
<em class="quotelev2">&gt;&gt; and there never was one, even for vitalists.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; In general, when faced with the challenge &quot;explain X&quot;, we need to  
</em><br />
<em class="quotelev2">&gt;&gt; ask:
</em><br />
<em class="quotelev2">&gt;&gt; what are the phenomena in the vicinity of X that need explaining, and
</em><br />
<em class="quotelev2">&gt;&gt; how might we explain them? In the case of life, what cries out for
</em><br />
<em class="quotelev2">&gt;&gt; explanation are such phenomena as reproduction, adaptation,
</em><br />
<em class="quotelev2">&gt;&gt; metabolism, self-sustenance, and so on: all complex functions. There
</em><br />
<em class="quotelev2">&gt;&gt; is not even a plausible candidate for a further sort of property of
</em><br />
<em class="quotelev2">&gt;&gt; life that needs explaining (leaving aside consciousness itself), and
</em><br />
<em class="quotelev2">&gt;&gt; indeed there never was. In the case of consciousness, on the other
</em><br />
<em class="quotelev2">&gt;&gt; hand, the manifest phenomena that need explaining are such things as
</em><br />
<em class="quotelev2">&gt;&gt; discrimination, reportability, integration (the functions), and
</em><br />
<em class="quotelev2">&gt;&gt; experience. So this analogy does not even get off the ground.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; ------
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; Though it DOES seem plausible/obvious to me that a physical system
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; going through a sequence of these representations is what produces
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; human behavior.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; So you're saying that a sequence of physical representations is  
</em><br />
<em class="quotelev3">&gt;&gt;&gt; enough
</em><br />
<em class="quotelev3">&gt;&gt;&gt; to produce behavior.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Right, observed behavior.  What I'm saying here is that it seems
</em><br />
<em class="quotelev2">&gt;&gt; obvious to me that mechanistic computation is sufficient to explain
</em><br />
<em class="quotelev2">&gt;&gt; observed human behavior.  If that was the only thing that needed
</em><br />
<em class="quotelev2">&gt;&gt; explaining, we'd be done.  Mission accomplished.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; BUT...there's subjective experience that also needs explained, and
</em><br />
<em class="quotelev2">&gt;&gt; this is actually the first question that needs answered.  All other
</em><br />
<em class="quotelev2">&gt;&gt; answers are suspect until subjective experience has been explained.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; And there must be conscious experience associated
</em><br />
<em class="quotelev3">&gt;&gt;&gt; with behavior.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Well, here's where it gets tricky.  Conscious experience is  
</em><br />
<em class="quotelev2">&gt;&gt; associated
</em><br />
<em class="quotelev2">&gt;&gt; with information.  But how information is tied to physical systems is
</em><br />
<em class="quotelev2">&gt;&gt; a different question.  Any physical systems can be interpreted as
</em><br />
<em class="quotelev2">&gt;&gt; representing all sorts of things (again, back to Putnam and Searle,
</em><br />
<em class="quotelev2">&gt;&gt; one-time pads, Maudlin's Olympia example, Bruno's movie graph
</em><br />
<em class="quotelev2">&gt;&gt; argument, rocks implementing every FSA, Stathis's birds and trees,  
</em><br />
<em class="quotelev2">&gt;&gt; and
</em><br />
<em class="quotelev2">&gt;&gt; triviality attacks on functionalism).
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; That seems to me to imply that physical representations
</em><br />
<em class="quotelev3">&gt;&gt;&gt; are enough to produce consciousness.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; The problem is that physical &quot;representations&quot; are everywhere.  The
</em><br />
<em class="quotelev2">&gt;&gt; problem is coming up with a non-arbitrary way of deciding when a
</em><br />
<em class="quotelev2">&gt;&gt; physical system represents something that's conscious and when it
</em><br />
<em class="quotelev2">&gt;&gt; doesn't.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Physical systems are too representationally promiscuous!
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Which leads me to abandon physicalism/materialism for idealism.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<br /><a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
<br />
<br /><br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue May 19 2009 - 19:37:30 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start16655">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="16656.html" title="Next message in the list">ronaldheld: "Re: No MWI"</a></li>
<li><dfn>Previous message</dfn>: <a href="16654.html" title="Previous message in the list">Bruno Marchal: "Re: Consciousness is information?"</a></li>
<li><dfn>In reply to</dfn>: <a href="16649.html" title="Message to which this message replies">Alberto G.Corona: "Re: Consciousness is information?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="16658.html" title="Next message in this discussion thread">Alberto G.Corona: "Re: Consciousness is information?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="16658.html" title="Message sent in reply to this message">Alberto G.Corona: "Re: Consciousness is information?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg16655" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg16655" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg16655" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg16655" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
