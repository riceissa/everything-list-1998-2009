<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Dreaming On from Brent Meeker on 2009-08-26 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: Dreaming On" />
<meta name="Date" content="2009-08-26" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Dreaming On</h1>
<!-- received="Wed Aug 26 16:15:55 2009" -->
<!-- isoreceived="20090826231555" -->
<!-- sent="Wed, 26 Aug 2009 16:15:55 -0700" -->
<!-- isosent="20090826231555" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: Dreaming On" -->
<!-- id="4A95C22B.3090807.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="b0b263660908261446n6d46379ao763109ec96f57b43.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start17498" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="17499.html" accesskey="d" title="David Nyman: &quot;Re: Dreaming On&quot;">Next message</a> ]
[ <a href="17497.html" title="David Nyman: &quot;Re: Dreaming On&quot;">Previous message</a> ]
[ <a href="17497.html" title="David Nyman: &quot;Re: Dreaming On&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="17500.html" accesskey="t" title="David Nyman: &quot;Re: Dreaming On&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg17498" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg17498" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg17498" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg17498" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20Dreaming%20On">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Wed, 26 Aug 2009 16:15:55 -0700</span><br />
</address>
<br />
David Nyman wrote:
<br />
<em class="quotelev1">&gt; 2009/8/26 Brent Meeker &lt;meekerdb.domain.name.hidden&gt;:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; I don't see that.  I conjectured that with sufficient knowledge of the
</em><br />
<em class="quotelev2">&gt;&gt; environment in which the alien functioned and input-outputs at the
</em><br />
<em class="quotelev2">&gt;&gt; corresponding level, one could provide and account of the alien's
</em><br />
<em class="quotelev2">&gt;&gt; experience.  I was my point that simply looking at the alien's brain,
</em><br />
<em class="quotelev2">&gt;&gt; without the context of its function, would not suffice.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I can't tell what you mean by &quot;provide an account&quot;.  Do you mean that
</em><br />
<em class="quotelev1">&gt; one could provide some account of all this in functional terms that
</em><br />
<em class="quotelev1">&gt; *we could interpret* in ways that made contextual sense *for us* -
</em><br />
<em class="quotelev1">&gt; standing in, as it were, for the alien?  If so, this is what I meant
</em><br />
<em class="quotelev1">&gt; when I said to Stathis that it really becomes equivalent to the
</em><br />
<em class="quotelev1">&gt; problem of other minds, in that if we can coax the data into making
</em><br />
<em class="quotelev1">&gt; sense for us, we can extrapolate this by implication to the alien.
</em><br />
<em class="quotelev1">&gt; But that would tend to make it a rather human alien, wouldn't it?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; The question is whether PM is sufficient to describe the system.
</em><br />
<em class="quotelev2">&gt;&gt; Language is almost certainly inadequate to describing what it is like
</em><br />
<em class="quotelev2">&gt;&gt; to 'be' the system - you cannot even fully describe what it is like to
</em><br />
<em class="quotelev2">&gt;&gt; be you.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I'm questioning something more subtle here, I think.  First, one could
</em><br />
<em class="quotelev1">&gt; simply decide to be eliminativist about experience, and hold that the
</em><br />
<em class="quotelev1">&gt; extrinsic PM account is both exhaustive and singular.  In this case,
</em><br />
<em class="quotelev1">&gt; 'being' anything is simply an extrinsic notion.  But if we're not in
</em><br />
<em class="quotelev1">&gt; this sort of denial, then the idea of 'being' the system subtly
</em><br />
<em class="quotelev1">&gt; encourages the intuition that there's some way to be that
</em><br />
<em class="quotelev1">&gt; simultaneously satisfies two criteria:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 1) Point-for-point isomorphism - in some suitable sense - with the
</em><br />
<em class="quotelev1">&gt; extrinsic description.
</em><br />
<em class="quotelev1">&gt; 2) An intrinsic nature that is incommunicable in terms of the
</em><br />
<em class="quotelev1">&gt; extrinsic description alone.
</em><br />
<br />Even if there PM and functionalism is true, (1) and (2) are dubious. 
<br />
Extrinsic descriptions are necessarily in terms of shared experiences 
<br />
and so may not be complete.  &quot;Incommunicable&quot; is ambiguous. It could 
<br />
mean impossible in principle or it could mean we haven't developed the 
<br />
words or pictures for it.  Assuming there's something incommunicable 
<br />
in the later sense doesn't imply that PM or functionalism are false.
<br />
<br />The idea of 'being' somebody (or thing) else already assumes dualism. 
<br />
It assumes some 'I' that could move to be Stathis or a bat and yet 
<br />
retain some identity.  But on a functionalist view 'I' already am 
<br />
Stathis and a bat - in other words there is no 'I', it's the creation 
<br />
of viewpoint by each functional entity.  In that case being someone 
<br />
else in incommunicable in principle because the concept in incoherent.
<br />
<br />Brent
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; This intuition has a lot of work to do to stay monistic - i.e. to
</em><br />
<em class="quotelev1">&gt; claim to refer to a unique existent.  First it has to justify why
</em><br />
<em class="quotelev1">&gt; there's still a gap between the 'extrinsic' system-as-described and
</em><br />
<em class="quotelev1">&gt; the 'intrinsic' system-as-instantiated - i.e. the description can no
</em><br />
<em class="quotelev1">&gt; longer be considered exhaustive.  Then it has to explain the existence
</em><br />
<em class="quotelev1">&gt; of the former as some mode of the latter.   Finally, it has to
</em><br />
<em class="quotelev1">&gt; dispense with any implied referent of the former, except in the guise
</em><br />
<em class="quotelev1">&gt; of the latter - i.e. it has to dispense with any fundamental notion of
</em><br />
<em class="quotelev1">&gt; the extrinsic except as a metaphor or mode of the intrinsic.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Dispensing with the extrinsic in this way leaves us with 'being' as a
</em><br />
<em class="quotelev1">&gt; fundamentally intrinsic notion.  Not doing so is an implicit appeal to
</em><br />
<em class="quotelev1">&gt; dualism.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; David
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; David Nyman wrote:
</em><br />
<em class="quotelev3">&gt;&gt;&gt; 2009/8/26 Stathis Papaioannou &lt;stathisp.domain.name.hidden&gt;:
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; With the example of the light, you alter the photoreceptors in the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; retina so that they respond the same way when to a blue light that
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; they would have when exposed to a red light.
</em><br />
<em class="quotelev3">&gt;&gt;&gt; Ah, so the alien has photoreceptors and retinas?  That's an assumption
</em><br />
<em class="quotelev3">&gt;&gt;&gt; worth knowing!  This is why I said &quot;a successful theory wouldn't be
</em><br />
<em class="quotelev3">&gt;&gt;&gt; very distant from the belief that the alien was, in effect, human, or
</em><br />
<em class="quotelev3">&gt;&gt;&gt; alternatively that you were,  in effect, alien&quot;.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; I think what I have proposed is consistent with functionalism, which
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; may or may not be true. A functionally identical system produces the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; same outputs for the same inputs, and functionalism says that
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; therefore it will also have the same experiences, such as they may be.
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; But what those experiences are like cannot be known unless you are the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; system, or perhaps understand it so well that you can effectively run
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; it in your head.
</em><br />
<em class="quotelev3">&gt;&gt;&gt; Well, it's precisely the conjunction of functionalism with a
</em><br />
<em class="quotelev3">&gt;&gt;&gt; primitively material assumption that prompted this part of the thread.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;  Peter asked me if I thought a brain scan at some putatively
</em><br />
<em class="quotelev3">&gt;&gt;&gt; fundamental physical level would be an exhaustive account of all the
</em><br />
<em class="quotelev3">&gt;&gt;&gt; information that was available experientially, and I was attempting to
</em><br />
<em class="quotelev3">&gt;&gt;&gt; respond specifically to that.  Given what you say above, I would again
</em><br />
<em class="quotelev3">&gt;&gt;&gt; say - for all the reasons I've argued up to this point - that a purely
</em><br />
<em class="quotelev3">&gt;&gt;&gt; functional account on the assumption of PM gives me no reason to
</em><br />
<em class="quotelev3">&gt;&gt;&gt; attribute experience of any kind to the system in question.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; The way you phrase it rightly emphasises the focus on invariance of
</em><br />
<em class="quotelev3">&gt;&gt;&gt; inputs and outputs as definitive of invariance of experience, rather
</em><br />
<em class="quotelev3">&gt;&gt;&gt; than the variability of the actual PM process that performs the
</em><br />
<em class="quotelev3">&gt;&gt;&gt; transformation.  As Brent has commented, this seems a somewhat
</em><br />
<em class="quotelev3">&gt;&gt;&gt; arbitrary assumption, with the implied rider of &quot;what else could it
</em><br />
<em class="quotelev3">&gt;&gt;&gt; be?&quot;  Well, whatever else could provide an account of experience, this
</em><br />
<em class="quotelev3">&gt;&gt;&gt; particular conjecture happens to fly directly in the face of the
</em><br />
<em class="quotelev3">&gt;&gt;&gt; simultaneous assumption of primitively physical causation.
</em><br />
<em class="quotelev2">&gt;&gt; I don't see that.  I conjectured that with sufficient knowledge of the
</em><br />
<em class="quotelev2">&gt;&gt; environment in which the alien functioned and input-outputs at the
</em><br />
<em class="quotelev2">&gt;&gt; corresponding level, one could provide and account of the alien's
</em><br />
<em class="quotelev2">&gt;&gt; experience.  I was my point that simply looking at the alien's brain,
</em><br />
<em class="quotelev2">&gt;&gt; without the context of its function, would not suffice.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; There's something trickier here, too.  When you say &quot;unless you are
</em><br />
<em class="quotelev3">&gt;&gt;&gt; the system&quot;, this masks an implicit - and dualistic - assumption in
</em><br />
<em class="quotelev3">&gt;&gt;&gt; addition to PM monism.  It is axiomatic that any properly monistic
</em><br />
<em class="quotelev3">&gt;&gt;&gt; materialist account must hold all properties of a system to be
</em><br />
<em class="quotelev3">&gt;&gt;&gt; extrinsic, and hence capable of *exhaustive* extrinsic formulation.
</em><br />
<em class="quotelev3">&gt;&gt;&gt; IOW if it's not extrinsically describable, it doesn't exist in terms
</em><br />
<em class="quotelev3">&gt;&gt;&gt; of PM.  So what possible difference could it make, under this
</em><br />
<em class="quotelev3">&gt;&gt;&gt; restriction, to 'be' the system?
</em><br />
<em class="quotelev2">&gt;&gt; The question is whether PM is sufficient to describe the system.
</em><br />
<em class="quotelev2">&gt;&gt; Language is almost certainly inadequate to describing what it is like
</em><br />
<em class="quotelev2">&gt;&gt; to 'be' the system - you cannot even fully describe what it is like to
</em><br />
<em class="quotelev2">&gt;&gt; be you.  That's why I think the &quot;hard problem&quot; of consciouness will
</em><br />
<em class="quotelev2">&gt;&gt; not be &quot;solved&quot; it will just wither away.  Eventually we will
</em><br />
<em class="quotelev2">&gt;&gt; understand brains sufficiently to create AI with specifically designed
</em><br />
<em class="quotelev2">&gt;&gt; memories, emotions, and cogitation, as evidenced by their behavior and
</em><br />
<em class="quotelev2">&gt;&gt; the similarity of their processes to human ones.  We won't *know* that
</em><br />
<em class="quotelev2">&gt;&gt; they are conscious, but we'll believe they are.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Brent
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; If the reply is that it makes just
</em><br />
<em class="quotelev3">&gt;&gt;&gt; the somewhat epoch-making difference of conjuring up an otherwise
</em><br />
<em class="quotelev3">&gt;&gt;&gt; unknowable world of qualitative experience, can we still lay claim to
</em><br />
<em class="quotelev3">&gt;&gt;&gt; a monistic ontology, in any sense that doesn't beggar the term?
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt; David
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; 2009/8/26 David Nyman &lt;david.nyman.domain.name.hidden&gt;:
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; On 25 Aug, 14:32, Stathis Papaioannou &lt;stath....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; Let's say the alien brain in its initial environment produced a
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; certain output when it was presented with a certain input, such as a
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; red light. The reconstructed brain is in a different environment and
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; is presented with a blue light instead of a red light. To deal with
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; this, you alter the brain's configuration so that it produces the same
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; output with the blue light that it would have produced with the red
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt; light.
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; In terms of our discussion on the indispensability of an
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; interpretative context for assigning meaning to 'raw data', I'm not
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; sure exactly how much you're presupposing when you say that &quot;you alter
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; the brain's configuration&quot;.  You have a bunch of relational data
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; purporting to correspond to the existing configuration of the alien's
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; brain and its relation to its environment.  This is available to you
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; solely in terms of your interpretation, on the basis of which you
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; attempt to come up with a theory that correlates the observed 'inputs'
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; and 'outputs' (assuming these can be unambiguously isolated).  But how
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; would you know that you had arrived at a successful theory of the
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; alien's experience?  Even if you somehow succeeded in observing
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; consistent correlations between inputs and outputs, how could you ever
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; be sure what this 'means' for the alien brain?
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; With the example of the light, you alter the photoreceptors in the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; retina so that they respond the same way when to a blue light that
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; they would have when exposed to a red light. Photoreceptors are
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; neurons and synapse with other neurons, further up the pathway of
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; visual perception. The alien will compare his perception of the blue
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; sky of Earth with his memory of the red sky of his home planet and
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; declare it looks the same. Now it is possible that it doesn't look the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; same and he only thinks it looks the same, but the same could be said
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; of ordinary life: perhaps yesterday the sky looked green, and today
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; that it looks blue we only think it looks the same because we are
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; deluded.
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; I would say that in effect what you have posed here is 'the problem of
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; other minds', and that consequently a 'successful' theory wouldn't be
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; very distant from the belief that the alien was, in effect, human, or
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; alternatively that you were,  in effect, alien.  And, mutatis
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt; mutandis, I guess this would apply to rocks too.
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; I think what I have proposed is consistent with functionalism, which
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; may or may not be true. A functionally identical system produces the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; same outputs for the same inputs, and functionalism says that
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; therefore it will also have the same experiences, such as they may be.
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; But what those experiences are like cannot be known unless you are the
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; system, or perhaps understand it so well that you can effectively run
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; it in your head.
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; --
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt; Stathis Papaioannou
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Wed Aug 26 2009 - 16:15:55 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start17498">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="17499.html" title="Next message in the list">David Nyman: "Re: Dreaming On"</a></li>
<li><dfn>Previous message</dfn>: <a href="17497.html" title="Previous message in the list">David Nyman: "Re: Dreaming On"</a></li>
<li><dfn>In reply to</dfn>: <a href="17497.html" title="Message to which this message replies">David Nyman: "Re: Dreaming On"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="17500.html" title="Next message in this discussion thread">David Nyman: "Re: Dreaming On"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="17500.html" title="Message sent in reply to this message">David Nyman: "Re: Dreaming On"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg17498" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg17498" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg17498" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg17498" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:16 PST
</em></small></p>
</body>
</html>
