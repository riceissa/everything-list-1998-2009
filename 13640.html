<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: How would a computer know if it were conscious? from David Nyman on 2007-06-24 (everything)</title>
<meta name="Author" content="David Nyman (david.nyman.domain.name.hidden)" />
<meta name="Subject" content="Re: How would a computer know if it were conscious?" />
<meta name="Date" content="2007-06-24" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: How would a computer know if it were conscious?</h1>
<!-- received="Sun Jun 24 18:54:50 2007" -->
<!-- isoreceived="20070625015450" -->
<!-- sent="Sun, 24 Jun 2007 23:54:27 +0100" -->
<!-- isosent="20070624225427" -->
<!-- name="David Nyman" -->
<!-- email="david.nyman.domain.name.hidden" -->
<!-- subject="Re: How would a computer know if it were conscious?" -->
<!-- id="b0b263660706241554h3ef41c4j9aabe5b450005c14.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="467ED4F3.7060504.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13640" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13641.html" accesskey="d" title="Russell Standish: &quot;Re: How would a computer know if it were conscious?&quot;">Next message</a> ]
[ <a href="13639.html" title="Brent Meeker: &quot;Re: How would a computer know if it were conscious?&quot;">Previous message</a> ]
[ <a href="13639.html" title="Brent Meeker: &quot;Re: How would a computer know if it were conscious?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13641.html" accesskey="t" title="Russell Standish: &quot;Re: How would a computer know if it were conscious?&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13640" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13640" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13640" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13640" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: David Nyman &lt;<a href="mailto:david.nyman.domain.name.hidden?Subject=Re%3A%20How%20would%20a%20computer%20know%20if%20it%20were%20conscious%3F">david.nyman.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sun, 24 Jun 2007 23:54:27 +0100</span><br />
</address>
<br />
On 24/06/07, Brent Meeker &lt;meekerdb.domain.name.hidden&gt; wrote:
<br />
<br />BM:  I think I agree with your concern
<br />
<br />DN:  Ah...
<br />
<br />BM:  and I think the answer is that &quot;conscious&quot; implies &quot;conscious of
<br />
something&quot;.  For a computer or an animal to be conscious is really a
<br />
relation to an environment.
<br />
<br />DN:  Yes
<br />
<br />BM:  So for a computer to be conscious, as a human is, it must be able to
<br />
perceive and act in our environment.
<br />
<br />DN:   My point precisely.
<br />
<br />BM:  Or it could be running a program in which a conscious being is
<br />
simulated and that being would be conscious relative to a simulated
<br />
environment in the computer.
<br />
<br />DN:  I'm prepared to be agnostic on this.  But as your 'or' rightly
<br />
indicates, if so, it would be conscious relative to the simulated
<br />
environment, *not* the human one.
<br />
<br />BM:  In the latter case there might be an infinite number of different
<br />
interpretations that could be consistently placed on the computer's
<br />
execution; or there might not.  Maybe all those different interpretations
<br />
aren't really different.  Maybe they are just translations into different
<br />
words.  It seems to me to be jumping to a conclusion to claim they are
<br />
different in some significant way.
<br />
<br />DN:  Not sure... but I don't see how any of this changes the essential
<br />
implication, which is that however many interpretations you place on it, and
<br />
however many of these may evoke 'consciousness of something' (or as I would
<br />
prefer to say, a personal or observer world) it would be the simulated
<br />
world, not the human one (as you rightly point out).  From Bruno's
<br />
perspective (I think - and AFAICS, also TON) these two 'worlds' would be
<br />
different 'levels of substitution'.  So, if I said 'yes' to the doctor's
<br />
proposal to upload me as an AI program, this might evoke some observer
<br />
world, but any such would be 'orthogonal' to my and the computer's shared
<br />
'level of origin'.  Consequently, no new observer evoked in this way could
<br />
have any ability to interact with that level.  As an aside, it's an
<br />
interesting take on the semantics of 'imaginary' - and you know Occam's
<br />
attitude to such entities.
<br />
<br />Anyway, I'm prepared to be agnostic for the moment about such specifics of
<br />
simulated worlds, but the key conclusion seems to be that in no case could
<br />
such a 'world' participate at the same causal level as the human one, which
<br />
vitiates any sense of its 'interacting' with, or being 'conscious of', the
<br />
same 'environment'.  AFAICS you have actually reached the same conclusion,
<br />
so I don't see in what sense you mean that it's the 'answer'.  You seem to
<br />
be supporting my point.  Do I misunderstand?
<br />
<br />David
<br />
<br /><br /><em class="quotelev1">&gt; OOPS! I accidentally hit the &quot;send&quot; button on the wrong copy.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Here's what I intended to send below:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; David Nyman wrote:
</em><br />
<em class="quotelev2">&gt; &gt; On 23/06/07, *Russell Standish* &lt;lists.domain.name.hidden
</em><br />
<em class="quotelev2">&gt; &gt; &lt;mailto:lists.domain.name.hidden&gt;&gt; wrote:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; RS:  Perhaps you are one of those rare souls with a foot in
</em><br />
<em class="quotelev2">&gt; &gt; each camp. That could be be very productive!
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I hope so!  Let's see...
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; RS:  This last post is perfectly lucid to me.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Phew!!  Well, that's a good start.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; RS:  I hope I've answered it
</em><br />
<em class="quotelev2">&gt; &gt; adequately.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Your answer is very interesting - not quite what I expected:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; RS:  In some Platonic sense, all possible observers are already
</em><br />
<em class="quotelev2">&gt; &gt; out there, but by physically instantiating it in our world, we are in
</em><br />
<em class="quotelev2">&gt; &gt; effect opening up a communication channel between ourselves and the
</em><br />
<em class="quotelev2">&gt; &gt; new consciousness.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I think I must be missing something profound in your intended meanings
</em><br />
<em class="quotelev1">&gt; of:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 1) 'out there'
</em><br />
<em class="quotelev2">&gt; &gt; 2) 'physically instantiating'
</em><br />
<em class="quotelev2">&gt; &gt; 3) 'our world'
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; My current 'picture' of it is as follows.  The 'Platonic sense' I assume
</em><br />
<em class="quotelev2">&gt; &gt; equates to the 'bit-string plenitude' (which is differentiable from 'no
</em><br />
<em class="quotelev2">&gt; &gt; information' only by internal observers, like the Library of Babel - a
</em><br />
<em class="quotelev2">&gt; &gt; beautiful idea BTW).  But I'm assuming a 'hierarchy' of recursive
</em><br />
<em class="quotelev2">&gt; &gt; computational emergence through bits up through, say, strings, quarks,
</em><br />
<em class="quotelev2">&gt; &gt; atoms, molecules, etc - in other words what is perceived as
</em><br />
<em class="quotelev2">&gt; &gt; matter-energy by observers.  I then assume that both 'physical objects'
</em><br />
<em class="quotelev2">&gt; &gt; and any correlated observers emerge from this matter-energy level, and
</em><br />
<em class="quotelev2">&gt; &gt; that this co-emergence accomplishes the 'physical instantiation'.  IOW,
</em><br />
<em class="quotelev2">&gt; &gt; the observer is the 1-person view, and the physical behaviour the
</em><br />
<em class="quotelev2">&gt; &gt; 3-person view, of the same underlying complex emergent - they're
</em><br />
<em class="quotelev2">&gt; &gt; different descriptions of the same events.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; If this is so, then as you say, the opening of the 'communication
</em><br />
<em class="quotelev2">&gt; &gt; channel' would be a matter of establishing the means and modes of
</em><br />
<em class="quotelev2">&gt; &gt; interaction with any new consciousness, because the same seamless
</em><br />
<em class="quotelev2">&gt; &gt; underlying causal sequence unites observer-world and physical-world:
</em><br />
<em class="quotelev2">&gt; &gt; again, different descriptions, same events.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; If the above is accepted (but I'm beginning to suspect there's something
</em><br />
<em class="quotelev2">&gt; &gt; deeply wrong with it), then the 'stability' of the world of the observer
</em><br />
<em class="quotelev2">&gt; &gt; should equate to the 'stability' of the physical events to which it is
</em><br />
<em class="quotelev2">&gt; &gt; linked through *identity*.  Now here's what puzzles me.  ISTM that the
</em><br />
<em class="quotelev2">&gt; &gt; imputation of 'computation' to the physical computer is only through the
</em><br />
<em class="quotelev2">&gt; &gt; systematic correspondence of certain stable aspects of its (principally)
</em><br />
<em class="quotelev2">&gt; &gt; electronic behaviour to computational elements: numbers,
</em><br />
<em class="quotelev2">&gt; &gt; mathematical-logical operators, etc.  The problem is in the terms
</em><br />
<em class="quotelev2">&gt; &gt; 'imputation' and 'correspondence': this is surely merely a *way of
</em><br />
<em class="quotelev2">&gt; &gt; speaking* about the physical events in the computer, an arbitrary
</em><br />
<em class="quotelev2">&gt; &gt; ascription, from an infinite possible set, of externally-established
</em><br />
<em class="quotelev2">&gt; &gt; semantics to the intrinsic physical syntactics.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Consequently, ISTM that the emergence of observer-worlds has to be
</em><br />
<em class="quotelev2">&gt; &gt; correlated (somehow) - one-to-one, or isomorphically - with
</em><br />
<em class="quotelev2">&gt; &gt; corresponding 'physical' events: IOW these events, with their 'dual
</em><br />
<em class="quotelev2">&gt; &gt; description', constitute a single 'distinguished' *causal* sequence.  By
</em><br />
<em class="quotelev2">&gt; &gt; contrast, *any* of the myriad 'computational worlds' that could be
</em><br />
<em class="quotelev2">&gt; &gt; ascribed to the same events must remain - to the computer, rather than
</em><br />
<em class="quotelev2">&gt; &gt; the programmer - only arbitrary or 'imaginary' ones.  This is why I
</em><br />
<em class="quotelev2">&gt; &gt; described them as 'nested' - perhaps 'orthogonal' or 'imaginary' are
</em><br />
<em class="quotelev2">&gt; &gt; better: they may - 'platonically' - exist somewhere in the plenitude,
</em><br />
<em class="quotelev2">&gt; &gt; but causally disconnected from the physical world in which the computer
</em><br />
<em class="quotelev2">&gt; &gt; participates. The computer doesn't 'know' anything about them.
</em><br />
<em class="quotelev2">&gt; &gt; Consequently, how could they possess any 'communication channel' to the
</em><br />
<em class="quotelev2">&gt; &gt; computer's - and our - world 'out there'?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I think I agree with your concern and I think the answer is that
</em><br />
<em class="quotelev1">&gt; &quot;conscious&quot; implies &quot;conscious of something&quot;.  For a computer or an animal
</em><br />
<em class="quotelev1">&gt; to be conscious is really a relation to an environment.  So for a computer
</em><br />
<em class="quotelev1">&gt; to be conscious, as a human is, it must be able to perceive and act in our
</em><br />
<em class="quotelev1">&gt; environment.  Or it could be running a program in which a conscious being is
</em><br />
<em class="quotelev1">&gt; simulated and that being would be conscious relative to a simulated
</em><br />
<em class="quotelev1">&gt; environment in the computer.  In the latter case there might be an infinite
</em><br />
<em class="quotelev1">&gt; number of different interpretations that could be consistently placed on the
</em><br />
<em class="quotelev1">&gt; computer's execution; or there might not.  Maybe all those different
</em><br />
<em class="quotelev1">&gt; interpretations aren't really different.  Maybe they are just translations
</em><br />
<em class="quotelev1">&gt; into different words.  It seems to me to be jumping to a conclusion to claim
</em><br />
<em class="quotelev1">&gt; they are different in some significant way.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The importance of the environment for consciousness is suggested by the
</em><br />
<em class="quotelev1">&gt; sensory deprivation experiments of the late '60s.  It was observed by people
</em><br />
<em class="quotelev1">&gt; who spent a long time in a sensory deprivation tank (an hour or more) that
</em><br />
<em class="quotelev1">&gt; their mind would enter a loop and they lost all sense of time.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Brent Meeker
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Of course I'm not claiming by this that machines couldn't be conscious.
</em><br />
<em class="quotelev2">&gt; &gt; My claim is rather that if they are, it couldn't be solely in virtue of
</em><br />
<em class="quotelev2">&gt; &gt; any 'imaginary computational worlds' imputed to them, but rather because
</em><br />
<em class="quotelev2">&gt; &gt; they support some unique, distinguished process of *physical* emergence
</em><br />
<em class="quotelev2">&gt; &gt; that also corresponds to a unique observer-world: and of course, mutatis
</em><br />
<em class="quotelev2">&gt; &gt; mutandis, this must also apply to the 'mind-brain' relationship.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; If I'm wrong (as no doubt I am), ISTM I must have erred in some step or
</em><br />
<em class="quotelev2">&gt; &gt; other of my logic above.  How do I debug it?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; David
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sun Jun 24 2007 - 18:54:50 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13640">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13641.html" title="Next message in the list">Russell Standish: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13639.html" title="Previous message in the list">Brent Meeker: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13639.html" title="Message to which this message replies">Brent Meeker: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13641.html" title="Next message in this discussion thread">Russell Standish: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13640" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13640" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13640" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13640" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
