<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Statistical Measure, does it matter? from John Mikes on 2007-04-02 (everything)</title>
<meta name="Author" content="John Mikes (jamikes.domain.name.hidden)" />
<meta name="Subject" content="Re: Statistical Measure, does it matter?" />
<meta name="Date" content="2007-04-02" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Statistical Measure, does it matter?</h1>
<!-- received="Mon Apr  2 09:01:46 2007" -->
<!-- isoreceived="20070402160146" -->
<!-- sent="Mon, 2 Apr 2007 09:01:33 -0400" -->
<!-- isosent="20070402130133" -->
<!-- name="John Mikes" -->
<!-- email="jamikes.domain.name.hidden" -->
<!-- subject="Re: Statistical Measure, does it matter?" -->
<!-- id="1acbded70704020601y753dfcccr55bc933ab874e3cc.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="f21c22e30703312048h1acffef0l905987cb3943fb99.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13238" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13239.html" accesskey="d" title="James N Rose: &quot;Re: Statistical Measure, does it matter?&quot;">Next message</a> ]
[ <a href="13237.html" title="Stathis Papaioannou: &quot;Re: Statistical Measure, does it matter?&quot;">Previous message</a> ]
[ <a href="13237.html" title="Stathis Papaioannou: &quot;Re: Statistical Measure, does it matter?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13239.html" accesskey="t" title="James N Rose: &quot;Re: Statistical Measure, does it matter?&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13238" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13238" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13238" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13238" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: John Mikes &lt;<a href="mailto:jamikes.domain.name.hidden?Subject=Re%3A%20Statistical%20Measure%2C%20does%20it%20matter%3F">jamikes.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon, 2 Apr 2007 09:01:33 -0400</span><br />
</address>
<br />
It's getting such and sucher - the multiple, back-and-forth gets dizzying.
<br />
So I will copy certain sentences of the &quot;Stathistical&quot; discussion for
<br />
reflection.-Below is the orig.Maze.
<br />
John
<br />
-------------------------------
<br />
<br /><em class="quotelev1">&gt; JM earlier: What else can we 'imagine'? Ideational -- of whom? Mine?
</em><br />
<em class="quotelev1">&gt; Yours? I would not recite &quot;of the universe&quot; because HOW do we have access to
</em><br />
<em class="quotelev1">&gt; a conscious process of the totality with our limited mind?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />SP:&quot;I don't quite understand this question. &quot;
<br />
<br />First: I corrected typos, but that will not solve the understandability. I
<br />
try to paraphrase the question, although that usually makes it even more
<br />
convoluted&lt;G&gt;:
<br />
I suppose, you imagine THAT computer to be 'above' our limited knowledge of
<br />
the human mind, (what we do not know in its entirety) to simulate it in 'all
<br />
conscious' aspect.
<br />
Maybe a 'consciousness of the totality of the entire universe?'  We can
<br />
'simulate' in a computer only the part we know of and that is insufficient
<br />
for representing &quot;it all&quot;.  Of course we should not reduce our
<br />
'comp'-substrate to an Apple, IBM, or similar.
<br />
--------------------
<br />
&quot;My &quot;in principle&quot; is somewhat narrower: I meant physically possible, given
<br />
the laws of our universe, without recourse to multiverses etc.&quot;
<br />
<br />&quot; Physically&quot; - as in our imaginational (I almost wrote: figment)
<br />
reductionist science e.g. &quot;Physics 101&quot;? I mean: &quot;material&quot;? I don't know
<br />
about the 'laws' of the universes,
<br />
(I don't know how to restrict such from the other universes - if such exist)
<br />
- I know only
<br />
about those in-model-findings (see below) that produced the most match in
<br />
our limited ways of past observations/explanations and our 'science'
<br />
declared (and calculated) them &quot;laws of physics&quot;. With new findings such
<br />
&quot;laws&quot; may change. Not the universe(s)
<br />
------------------------------------
<br />
&quot;If we could model a hurricane on a computer....&quot;
<br />
<br />Here come the 'models'. Not the gorgeous chicks in skimpy clothes and NOT
<br />
the functional simulations of constructs for easier study/understanding,
<br />
(like to simulate a biological process by an electrical/mathematical
<br />
construct, etc.). I mentioned earlier and I paraphrase:
<br />
as I use the word (non-exclusively my way) it is a topical/functional
<br />
limitation of a part of the totality (a limited extract) for the
<br />
understanding and handling of our limited minds. A mental cut to our
<br />
capabilities. Of course it does not collapse buildings. In &quot;my&quot; model we
<br />
consider about a hurricane only what we know of, speed, geometry, pressure
<br />
etc., I wish we knew about more from beyond-our-model circumstances and
<br />
could so interfere with its occurrence, or even stop them.
<br />
Like our 'model' of the brain is tissue within the skull and no link to
<br />
ideational qualities,
<br />
personal topical thoughts, experiences - memories, which are all handled in
<br />
the churning of these tissues - (and maybe else, still to be found). They
<br />
are believed to be linked, some say: they are included in those (physical??)
<br />
measurements we use in the present practice. I consider such reductionist
<br />
science a pars pro toto.
<br />
A 'complete' version of (my type) model is the thing itself (Robert Rosen).
<br />
Had we such 'complete mode' available your 'zombie' would be a real person.
<br />
-------------------------------------
<br />
&quot; You don't even need &quot;science&quot;:
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and:
<br />
&quot;for each part of the brain, a precise description of what happens when, for
<br />
example, a certain neurotransmitter is released into a certain synapse, will
<br />
allow you eventually to predict how the whole brain will behave, amazingly
<br />
difficult though that task would be. &quot;
<br />
<br />I accept the findings of our reductionist science with awe it is the only
<br />
and efficient way how we learn about the world. And the results are
<br />
astonishingly proliferous. I would add: in spite of our little understanding
<br />
what we are talking about. The edifice of 'science' is remarkable, with all
<br />
those &quot;it must be&quot;, &quot;it may be&quot;, &quot;it is assumed&quot; and &quot;as postulated&quot;  qualia
<br />
of very smart people. I seek a peek 'beyond', like some do it with
<br />
'numbers', some with UD, Multiverse, Q-science or religious faith.
<br />
That 'certain neurotransmitter into certain synapse' may explain many
<br />
processes, not exclusively though: given changes from other parts (in or
<br />
outside the skull) may alter the way how &quot;the whole brain behaves&quot; . We
<br />
think in a narrow window of the 'givens'
<br />
Reproducibility is usual within fixed model-framework, easily misunderstood
<br />
for the general processes. Matching experiments are designed and
<br />
quantitatively evaluated.
<br />
Engineered. Technology is an incredible model-achievement. Almost perfect. .
<br />
<br />--------------------------
<br />
&quot; I can't explain exactly how my computer works, but I that doesn't mean it
<br />
must contain magical processes.
<br />
<br />This after the complexity of biological processes is IMO exaggerated.
<br />
(After the French aristocratic 'Academy's verdicts' that Stevenson's
<br />
locomotive will not move, just turn its wheels on the spot and Fulton's
<br />
impeller will just drill a hole in the water,  magical is what we cannot
<br />
explain as of today). Then came epistemic enrichment.
<br />
It's OK to postpone understanding, wrong is to force a (model-based)
<br />
solution upon 'things' exceeding the boundaries of the model (like: we know
<br />
the brain-tissue and its histological churning, so EVERYTHING we assign to
<br />
brain function is explainable by such 'data')
<br />
--------------------------------
<br />
&quot;You build your model of the brain, then you test it to see if it behaves
<br />
like a real brain. If it doesn't, you go back and try to refine your model.
<br />
When you can't tell the difference between the model and the real brain you
<br />
have succeeded.
<br />
<br />&quot;Real brain&quot;? according to our present (omniscient!) thinking?
<br />
Finding no difference?  Some success you deem. Remember, please, that
<br />
'model' in my vocabulary is the limited topical fraction of the total
<br />
interconnected 'thing' and we use it for practical reasons (which comes
<br />
already to the next remark)
<br />
-------------------------
<br />
&quot;Do you acknowledge that there is a difference between the physically
<br />
impossible, and the merely practically impossible?
<br />
<br />Since I consider 'physical' a 'practical explanatory mode': principally NO,
<br />
but you asked 'practically' as a sub-chapter of 'physical' and in this
<br />
respect I certainly do.
<br />
With my previous stance about 'everything' ('anything') possible (even if
<br />
not plausible or probable) I may resort to denying 'logically improper' as
<br />
impossible, however it may be false when using ONLY human logic.
<br />
--------------
<br />
&quot;That's right; but are you suggesting that in addition to the physical
<br />
parts, there are other parts? &quot;  with the added: ...&quot;There is no evidence
<br />
for this&quot;
<br />
<br /><br />I don't know about 'parts'  if they are not in our physical setup. I
<br />
consider the ideational or whatever 'features' in the totality as
<br />
inter-effective qualia unidentified today for our mind. Remember my slogan
<br />
&quot;I dunno&quot; (not academic tenure-stuff).
<br />
I consider an idea NOT as constructed by sub-idea components, which can be
<br />
interchanged into 'other' ideas. If I consider some 'comp' it is pure
<br />
analogue. I am not at the level to formulate a world on such principle. So
<br />
please, don't ask me.
<br />
To the added remark of yours: 'no evidence' is not 'evidence for no'.
<br />
&nbsp;Ignorantia non est argumentum.
<br />
*
<br />
Sorry for being so verbose, I wanted to reflect to ALL your remarks and
<br />
wanted  to be more accommodating than it turned out to be. Sorry.
<br />
<br />John
<br />
<br /><br /><br /><br />On 3/31/07, Stathis Papaioannou &lt;stathisp.domain.name.hidden&gt; wrote:
<br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; On 3/31/07, John Mikes &lt;jamikes.domain.name.hidden &gt; wrote:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The non-standard part of Bruno's comp, as I see it, is to accept that
</em><br />
<em class="quotelev3">&gt; &gt; &gt; computation can lead to thought but to reject the physical supervenience
</em><br />
<em class="quotelev3">&gt; &gt; &gt; theory, i.e. that computation requires certain physical processes to
</em><br />
<em class="quotelev3">&gt; &gt; &gt; take place in order to &quot;happen&quot;. But that question aside, computationalism
</em><br />
<em class="quotelev3">&gt; &gt; &gt; depends on the idea that (a) it is *in principle* possible to reproduce all
</em><br />
<em class="quotelev3">&gt; &gt; &gt; the physical processes in our brain using a computer, to an arbitrary degree
</em><br />
<em class="quotelev3">&gt; &gt; &gt; of precision, and (b) such a reproduction, yielding by definition a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; functionally identical brain, also yields a functionally identical mind -
</em><br />
<em class="quotelev3">&gt; &gt; &gt; i.e., as opposed to a zombie. Roger Penrose says that (a) is false;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; John Searle and religious people say that even if (a) is true, (b) is false.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I tend to think that (a) and (b) are both true, but I am not completely
</em><br />
<em class="quotelev3">&gt; &gt; &gt; sure.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Here we go:
</em><br />
<em class="quotelev2">&gt; &gt; i.e. that computation requires certain physical processes to take place
</em><br />
<em class="quotelev2">&gt; &gt; in order to &quot;happen&quot;.
</em><br />
<em class="quotelev2">&gt; &gt;  What else can we 'imagine'? Ideationa -- of whom? Mine? Yours? I wouild
</em><br />
<em class="quotelev2">&gt; &gt; not recite &quot;of the unioverse&quot; because HOW do we have access to a conscious
</em><br />
<em class="quotelev2">&gt; &gt; process of the totality with our limited mind?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I don't quite understand this question.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;  ...(a) it is *in principle* possible to reproduce all the physical
</em><br />
<em class="quotelev2">&gt; &gt; processes in our brain using a computer,...
</em><br />
<em class="quotelev2">&gt; &gt; In principle EVERYTHING is possible. Look at the discussions on this
</em><br />
<em class="quotelev2">&gt; &gt; list.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; My &quot;in principle&quot; is somewhat narrower: I meant physically possible, given
</em><br />
<em class="quotelev1">&gt; the laws of our universe, without recourse to multiverses etc.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; ...(b) such a reproduction, yielding by definition a functionally
</em><br />
<em class="quotelev2">&gt; &gt; identical brain,...
</em><br />
<em class="quotelev2">&gt; &gt; If a 'model' is identical in all respects (&quot;functionally&quot;) it is not a
</em><br />
<em class="quotelev2">&gt; &gt; model, it is the THING itself. So we are in this case playing withg words.
</em><br />
<em class="quotelev2">&gt; &gt; NOTHING can be completely identical in this world, because everything is the
</em><br />
<em class="quotelev2">&gt; &gt; product of ALL the actual circumstances co- functioning in the construction
</em><br />
<em class="quotelev2">&gt; &gt; of the 'thing' (process). And ALL the circumstances do not ever repeat
</em><br />
<em class="quotelev2">&gt; &gt; themselves identically: it would be a merrygoround world loop what we so far
</em><br />
<em class="quotelev2">&gt; &gt; did not experience. We can find similarity in ALL aspects we observe, but
</em><br />
<em class="quotelev2">&gt; &gt; that does not include the complete totality. We like to call such similarity
</em><br />
<em class="quotelev2">&gt; &gt; an 'identity'..
</em><br />
<em class="quotelev2">&gt; &gt; .So I do not argue against your finding a) and b) possible, but does it
</em><br />
<em class="quotelev2">&gt; &gt; make sense?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; If we could model a hurricane on a computer the simulation would not
</em><br />
<em class="quotelev1">&gt; destroy houses, but if the model were good enough it would tell us which
</em><br />
<em class="quotelev1">&gt; houses a real hurricane would destroy. Similarly, if we could model a brain,
</em><br />
<em class="quotelev1">&gt; we would be in a position to know how a person would behave in a given
</em><br />
<em class="quotelev1">&gt; situation. We could use the computer model to control the person's muscles
</em><br />
<em class="quotelev1">&gt; and no-one would realise he wasn't a &quot;real&quot; person, i.e. we would have at
</em><br />
<em class="quotelev1">&gt; least a zombie.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;  2. Replaced? meaning one takes out that goo of neurons, proteins and
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; other tissue-stuff with its blood suply and replace the cavity (no matter
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; how bigger or smaller) by a (watch it): *digital* computer, &quot;appropriately
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; configured&quot; and electric flow in it. For the quale-details see the par #1.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Each neuron is made up of macromolecules in a watery medium. The
</em><br />
<em class="quotelev3">&gt; &gt; &gt; macromolecules follow the laws of physics: there are equations which
</em><br />
<em class="quotelev3">&gt; &gt; &gt; describe how phospholipid bilayers form membranes, how proteins embedded in
</em><br />
<em class="quotelev3">&gt; &gt; &gt; these membranes change conformation when ligands bind to them, how these
</em><br />
<em class="quotelev3">&gt; &gt; &gt; conformation changes result in ion fluxes and changes in transmembrane
</em><br />
<em class="quotelev3">&gt; &gt; &gt; potential, and so on. So if you ignore for the moment the technical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; difficulties involved in working all this out and implementing it, it should
</em><br />
<em class="quotelev3">&gt; &gt; &gt; be possible to program a computer to behave just like a biological brain,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; receiving afferent impulses from sense organs and sending afferent impulses
</em><br />
<em class="quotelev3">&gt; &gt; &gt; to muscles, which would result in a being whose behaviour is
</em><br />
<em class="quotelev3">&gt; &gt; &gt; indistinguishable from that of an intact human. The only way around this
</em><br />
<em class="quotelev3">&gt; &gt; &gt; conclusion is if the behaviour of the brain depends on physical processes
</em><br />
<em class="quotelev3">&gt; &gt; &gt; which are not computable, like Penrose's postulated quantum gravity effects.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; This is possible, but there isn't really any good evidence supporting it, as
</em><br />
<em class="quotelev3">&gt; &gt; &gt; far as I'm aware.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 3-29 insert s:
</em><br />
<em class="quotelev2">&gt; &gt; ...The macromolecules follow the laws of physics:...
</em><br />
<em class="quotelev2">&gt; &gt; NONONONONO!  Certain experiences with macromolecules are described in
</em><br />
<em class="quotelev2">&gt; &gt; our incompletge views as being described by certain (statistical?
</em><br />
<em class="quotelev2">&gt; &gt; probabilistic?) findings in the physical domain. Macro- or
</em><br />
<em class="quotelev2">&gt; &gt; nonmacromolecules, atoms, their parts, show behavior in our 'slanted',
</em><br />
<em class="quotelev2">&gt; &gt; 'partial'. observation which have been matched to calculations drawn upon
</em><br />
<em class="quotelev2">&gt; &gt; similarly era-restricted observational explanatory calculations (physics). I
</em><br />
<em class="quotelev2">&gt; &gt; did not work with atoms or molecules, when I made my macromo;leculs and
</em><br />
<em class="quotelev2">&gt; &gt; their applications. I worked with masses that behaved. Then I put them into
</em><br />
<em class="quotelev2">&gt; &gt; a reductionist analysis and tried to 'match' the numerical data to those in
</em><br />
<em class="quotelev2">&gt; &gt; the books. I made 'bilayers', 'ligands'. Indeed I got responses which I
</em><br />
<em class="quotelev2">&gt; &gt; described as performing as expected. And got the patents.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; But you wouldn't have been granted the patents if your experiments were
</em><br />
<em class="quotelev1">&gt; not repeatable. You don't even need &quot;science&quot;: a precise description of what
</em><br />
<em class="quotelev1">&gt; happens when you mix substance A with substance B under physical conditions
</em><br />
<em class="quotelev1">&gt; C will suffice. Similarly, for each part of the brain, a precise description
</em><br />
<em class="quotelev1">&gt; of what happens when, for example, a certain neurotransmitter is released
</em><br />
<em class="quotelev1">&gt; into a certain synapse, will allow you eventually to predict how the whole
</em><br />
<em class="quotelev1">&gt; brain will behave, amazingly difficult though that task would be.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; ...it should be possible to program a computer to behave just like a
</em><br />
<em class="quotelev2">&gt; &gt; biological brain,...
</em><br />
<em class="quotelev2">&gt; &gt; How does a 'biological brain' work? we - so far - extracted some
</em><br />
<em class="quotelev2">&gt; &gt; behavioral deductions into the model we have about the goo-in-the-skull and
</em><br />
<em class="quotelev2">&gt; &gt; call it a &quot;total&quot; - even with those unknown parts which come from outside
</em><br />
<em class="quotelev2">&gt; &gt; the matter-reactions we have access to - or even from so far undiscovered
</em><br />
<em class="quotelev2">&gt; &gt; aspects/factors. And I would not call it &quot;biological&quot; which is a limited
</em><br />
<em class="quotelev2">&gt; &gt; model of the functionality. One difficulty is the baggage in the words we
</em><br />
<em class="quotelev2">&gt; &gt; are restrict to in our historically developed language.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; With all the scrutiny, there would be some evidence of behaviour in the
</em><br />
<em class="quotelev1">&gt; brain that biochemistry cannot explain. There isn't, any more than there is
</em><br />
<em class="quotelev1">&gt; for any other organ in the body. Certainly there are many things in biology
</em><br />
<em class="quotelev1">&gt; that we can't yet explain, but the sheer complexity of the biochemical
</em><br />
<em class="quotelev1">&gt; processes makes this inevitable. I can't explain exactly how my computer
</em><br />
<em class="quotelev1">&gt; works, but I that doesn't mean it must contain magical processes.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; ... it should be possible ...
</em><br />
<em class="quotelev2">&gt; &gt; Amen. It should. I would be happy. (But, alas, it isn't)
</em><br />
<em class="quotelev2">&gt; &gt; ... indistinguishable from that of an intact human....
</em><br />
<em class="quotelev2">&gt; &gt; looks to me like the right sentence, just let it be known by what
</em><br />
<em class="quotelev2">&gt; &gt; model-characteristics (qualia) do we distinguish? Or 'can' we distinguish. In
</em><br />
<em class="quotelev2">&gt; &gt; what respect? First: Do we KNOW all details of an 'infact human' full
</em><br />
<em class="quotelev2">&gt; &gt; process? I think we know only a part of it, the oneS which ARE accessible to
</em><br />
<em class="quotelev2">&gt; &gt; our presently applied observational power and knowledge base. Just compare
</em><br />
<em class="quotelev2">&gt; &gt; to the 'infact' human as described in 1000AD or 3000BC. etc. - not in
</em><br />
<em class="quotelev2">&gt; &gt; 2300AD.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; You build your model of the brain, then you test it to see if it behaves
</em><br />
<em class="quotelev1">&gt; like a real brain. If it doesn't, you go back and try to refine your model.
</em><br />
<em class="quotelev1">&gt; When you can't tell the difference between the model and the real brain you
</em><br />
<em class="quotelev1">&gt; have succeeded.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; ...if you ignore for the moment the technical difficulties involved in
</em><br />
<em class="quotelev2">&gt; &gt; working all this out and implementing it,
</em><br />
<em class="quotelev2">&gt; &gt; in other words it is impossible, but we can think about it. No, in my
</em><br />
<em class="quotelev2">&gt; &gt; practical thinking only the possible (everything though it may be) is
</em><br />
<em class="quotelev2">&gt; &gt; usable, not input of which we presume that it is not feasible (possible?).
</em><br />
<em class="quotelev2">&gt; &gt; The difficulties are not 'technical', they are ontological. Not fitting into
</em><br />
<em class="quotelev2">&gt; &gt; circumstances we 'even suppose' .
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Do you acknowledge that there is a difference between the physically
</em><br />
<em class="quotelev1">&gt; impossible, and the merely practically impossible?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;  3. &quot;you&quot; - and who should that be? can we separate our living
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; brain (I mean with all its functionality) from 'YOU', the self, the
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; person, or call it the simulacron of yourself? What's left? Is there &quot;me&quot;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; and &quot;my brain&quot;? As I like to call it: the brain is the 'tool' of my
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; mind, mind is pretty unidentified,  but - is close to my-self, some call it
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; life, some consciousness, - those items we like to argue about because none
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; of us knows what we are talking about (some DO THINK they know, but only
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; something and for themselves).
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I find it hard to define consciousness, but I know what it is, and so
</em><br />
<em class="quotelev3">&gt; &gt; &gt; does everyone who has it.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; And everyone (not really) knows it personalized and differently.
</em><br />
<em class="quotelev2">&gt; &gt; Scholars: slanted to their theoretical needs, others maybe to their
</em><br />
<em class="quotelev2">&gt; &gt; emotions.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;  4. &quot;feel&quot; ----????---- who/what? the transistors?
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; (Let me repeat: I am not talking about Transistor Stathis).
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; You could equally well ask, do the proteins/ phospholipids/ nucleic
</em><br />
<em class="quotelev3">&gt; &gt; &gt; acids etc. feel? Apparently, they do. If your brain stops working or
</em><br />
<em class="quotelev3">&gt; &gt; &gt; is seriously damaged, you stop feeling.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I am not speaking about how 'parts' feel, rather how the complexity
</em><br />
<em class="quotelev2">&gt; &gt; acts. The brain is a tool cooperating in our mental factor, so if the tool
</em><br />
<em class="quotelev2">&gt; &gt; is damaged certain activities of it may be missing, or perform
</em><br />
<em class="quotelev2">&gt; &gt; inadequately.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That's right; but are you suggesting that in addition to the physical
</em><br />
<em class="quotelev1">&gt; parts, there are other parts? That is, that even though a brain is perfectly
</em><br />
<em class="quotelev1">&gt; intact physically and seems to be functioning normally to an outside
</em><br />
<em class="quotelev1">&gt; observer, it might yet not be conscious because it lacks some non-physical
</em><br />
<em class="quotelev1">&gt; component, such as a soul? There is no evidence for this.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;  *-SP:
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Bruno goes on to show that this entails there is no separate
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; physical reality by means of the UDA, but we can still talk about
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; computationalism - the predominant theory in cognitive science - without
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; discussing the UDA. And in any case, the ideas Brent and I have been
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; discussing are still relevant if computationalism is wrong and (again a
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; separate matter) there is only one universe.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Stathis Papaioannou-*
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; &lt;JM&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Yes, &quot;we today&quot; KNOW about only 1 universe. But we believe in a
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; physical reality what we 'feel', 'live it' and hold as our 'truth' as well.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Even those 'more advanced' minds saying they don't believe in it, cry out
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; (OMIGOD!) when &quot;Dr. Johnson's stone&quot; hurts their toe in the shoe.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; I like to draw comparisons between &quot;what we know today&quot; and what we
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; knew 1000, 3000, or 5000 years ago and ask: what will we 'know' just 500
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; years ahead in the future by a continuing epistemic enrichment? (If humanity
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; survives that long).
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Please, readers, just list the answers alphabetically.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I don't know the answer. Maybe next year there will be some discovery
</em><br />
<em class="quotelev3">&gt; &gt; &gt; which will have us all laughing at the idea that computers can be conscious,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; but at present we can only go on the information available to us, and try to
</em><br />
<em class="quotelev3">&gt; &gt; &gt; keep an open mind.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Stathis, I may cross my fingers, but would not hold my breath. IMO we
</em><br />
<em class="quotelev2">&gt; &gt; 'know' a little part, the unknown may be the essential and overwhelming.
</em><br />
<em class="quotelev2">&gt; &gt; Good luck to humanity to become smarter before extinct.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Stathis Papaioannou
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Mon Apr 02 2007 - 09:01:46 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13238">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13239.html" title="Next message in the list">James N Rose: "Re: Statistical Measure, does it matter?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13237.html" title="Previous message in the list">Stathis Papaioannou: "Re: Statistical Measure, does it matter?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13237.html" title="Message to which this message replies">Stathis Papaioannou: "Re: Statistical Measure, does it matter?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13239.html" title="Next message in this discussion thread">James N Rose: "Re: Statistical Measure, does it matter?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13238" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13238" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13238" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13238" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:13 PST
</em></small></p>
</body>
</html>
