<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: QTI &amp; euthanasia from Brent Meeker on 2008-11-09 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: QTI &amp; euthanasia" />
<meta name="Date" content="2008-11-09" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: QTI &amp; euthanasia</h1>
<!-- received="Sun Nov  9 14:29:00 2008" -->
<!-- isoreceived="20081109222900" -->
<!-- sent="Sun, 09 Nov 2008 11:29:00 -0800" -->
<!-- isosent="20081109192900" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: QTI &amp; euthanasia" -->
<!-- id="491739FC.7060207.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="76887636-F652-45CE-B4CB-B6D2DA90FA61.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start15174" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="15175.html" accesskey="d" title="Brent Meeker: &quot;Re: QTI &#0038; euthanasia (brouillon)&quot;">Next message</a> ]
[ <a href="15173.html" title="Bruno Marchal: &quot;Re: QTI &#0038; euthanasia (brouillon)&quot;">Previous message</a> ]
[ <a href="15080.html" title="Bruno Marchal: &quot;Re: QTI &#0038; euthanasia&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="15179.html" accesskey="t" title="Bruno Marchal: &quot;Re: QTI &#0038; euthanasia&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15174" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15174" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15174" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15174" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20QTI%20%26%20euthanasia">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sun, 09 Nov 2008 11:29:00 -0800</span><br />
</address>
<br />
Bruno Marchal wrote:
<br />
<em class="quotelev1">&gt; Replies to Jason Resch and Brent Meeker:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; On 01 Nov 2008, at 12:26, Jason Resch wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; I've thought of an interesting modification to the original UDA  
</em><br />
<em class="quotelev2">&gt;&gt; argument which would suggest that one's consciousness is at both  
</em><br />
<em class="quotelev2">&gt;&gt; locations simultaneously.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Since the UDA accepts digital mechanism as its first premise, then  
</em><br />
<em class="quotelev2">&gt;&gt; it is possible to instantiate a consciousness within a computer.   
</em><br />
<em class="quotelev2">&gt;&gt; Therefore instead of a physical teleportation from Brussels to  
</em><br />
<em class="quotelev2">&gt;&gt; Washington and Moscow instead we will have a digital transfer.  This  
</em><br />
<em class="quotelev2">&gt;&gt; will allow the experimenter to have complete control over the input  
</em><br />
<em class="quotelev2">&gt;&gt; each mind receives and guarantee identical content of experience.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; A volunteer in Brussels has her brain frozen and scanned at the  
</em><br />
<em class="quotelev2">&gt;&gt; necessary substitution level and the results are loaded into a  
</em><br />
<em class="quotelev2">&gt;&gt; computer with the appropriate simulation software that can  
</em><br />
<em class="quotelev2">&gt;&gt; accurately model her brain's functions, therefore from her  
</em><br />
<em class="quotelev2">&gt;&gt; perspective, her consciousness continues onward from the time her  
</em><br />
<em class="quotelev2">&gt;&gt; brain was frozen.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; To implement the teleportation, the simulation in the computer in  
</em><br />
<em class="quotelev2">&gt;&gt; Brussels is paused, and a snapshot of the current state is sent over  
</em><br />
<em class="quotelev2">&gt;&gt; the Internet to two computers, one in Washington and the other in  
</em><br />
<em class="quotelev2">&gt;&gt; Moscow, each of these computers has the same simulation software and  
</em><br />
<em class="quotelev2">&gt;&gt; upon receipt, resume the simulation of the brain where it left off  
</em><br />
<em class="quotelev2">&gt;&gt; in Brussels.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; The question is: if the sensory input is pre-fabricated and  
</em><br />
<em class="quotelev2">&gt;&gt; identical in both computers, are there two minds, or simply two  
</em><br />
<em class="quotelev2">&gt;&gt; implementations of the same mind?  If you believe there are two  
</em><br />
<em class="quotelev2">&gt;&gt; minds, consider the following additional steps.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Only one mind, belonging to two relative histories (among an infinity).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; Since it was established that the experimenter can &quot;teleport&quot; minds  
</em><br />
<em class="quotelev2">&gt;&gt; by pausing a simulation, sending their content over the network, and  
</em><br />
<em class="quotelev2">&gt;&gt; resuming it elsewhere, then what happens if the experimenter wants  
</em><br />
<em class="quotelev2">&gt;&gt; to teleport the Washington mind to Moscow, and the Moscow mind to  
</em><br />
<em class="quotelev2">&gt;&gt; Washington?  Assume that both computers were preset to run the  
</em><br />
<em class="quotelev2">&gt;&gt; simulation for X number of CPU instructions before pausing the  
</em><br />
<em class="quotelev2">&gt;&gt; simulation and transferring the state, such that the states are  
</em><br />
<em class="quotelev2">&gt;&gt; exactly the same when each is sent.  Further assume that the  
</em><br />
<em class="quotelev2">&gt;&gt; harddrive space on the computers is limited, so as they receive the  
</em><br />
<em class="quotelev2">&gt;&gt; brain state, they overwrite their original save.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; During this procedure, the computers in Washington and Moscow each  
</em><br />
<em class="quotelev2">&gt;&gt; receive the other's brain state, however, it is exactly the same as  
</em><br />
<em class="quotelev2">&gt;&gt; the one they already had.  Therefore the overwriting is a no-op.   
</em><br />
<em class="quotelev2">&gt;&gt; After the transfer is complete, each computer resumes the  
</em><br />
<em class="quotelev2">&gt;&gt; simulation.  Now is Moscow's mind on the Washington computer?  If so  
</em><br />
<em class="quotelev2">&gt;&gt; how did a no-op (overwriting the file with the same bits) accomplish  
</em><br />
<em class="quotelev2">&gt;&gt; the teleportation, if not, what makes the teleportation fail?
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; What happens in the case where the Washington and Moscow computer  
</em><br />
<em class="quotelev2">&gt;&gt; shutdown for some period of time (5 minutes for example) and then  
</em><br />
<em class="quotelev2">&gt;&gt; ONLY the Moscow computer is turned back on.  Did a &quot;virtual&quot;  
</em><br />
<em class="quotelev2">&gt;&gt; teleportation occur between Washington and Moscow to allow the  
</em><br />
<em class="quotelev2">&gt;&gt; consciousness that was in Washington to continue?  If not, then  
</em><br />
<em class="quotelev2">&gt;&gt; would a physical transfer of the data from Washington to Moscow have  
</em><br />
<em class="quotelev2">&gt;&gt; saved its consciousness, and if so, what happened to the Moscow  
</em><br />
<em class="quotelev2">&gt;&gt; consciousness?
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; The above thought experiments led me to conclude that both computers  
</em><br />
<em class="quotelev2">&gt;&gt; implement the same mind and are the same mind, despite  having  
</em><br />
<em class="quotelev2">&gt;&gt; different explanations.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Rigth.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;  Turning off one of the computers in either Washington or Moscow,  
</em><br />
<em class="quotelev2">&gt;&gt; therefore, does not end the consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Yes.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; Per the conclusions put forth in the UDA, the volunteer in Brussels  
</em><br />
<em class="quotelev2">&gt;&gt; would say she has a 1/2 chance of ending up in the Washington  
</em><br />
<em class="quotelev2">&gt;&gt; computer and 1/2 chance of ending up in the Moscow computer.   
</em><br />
<em class="quotelev2">&gt;&gt; Therefore, if you told her &quot;15 minutes after the teleportation the  
</em><br />
<em class="quotelev2">&gt;&gt; computer in Washington will be shut off forever&quot; she should expect a  
</em><br />
<em class="quotelev2">&gt;&gt; 1/2 chance of dying.  This seems to be a contradiction, as there is  
</em><br />
<em class="quotelev2">&gt;&gt; a &quot;virtual&quot; teleportation from Washington to Moscow which saves the  
</em><br />
<em class="quotelev2">&gt;&gt; consciousness in Washington from oblivion.  So her chances of death  
</em><br />
<em class="quotelev2">&gt;&gt; are 0, not 1/2, which is only explainable if we assume that her mind  
</em><br />
<em class="quotelev2">&gt;&gt; is subjectively in both places after the first teleport from  
</em><br />
<em class="quotelev2">&gt;&gt; Brussels, and so long as a simulation of her mind exists somewhere  
</em><br />
<em class="quotelev2">&gt;&gt; she will never die.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; And an infinity of those simulations exists, a-spatially and a- 
</em><br />
<em class="quotelev1">&gt; temporally, in arithmetic, (or in  the &quot;standard model of  
</em><br />
<em class="quotelev1">&gt; arithmetic&quot;)  which entails comp-immortality (need step 8!). Actually  
</em><br />
<em class="quotelev1">&gt; a mind is never really located somewhere. Location is a construct of  
</em><br />
<em class="quotelev1">&gt; the mind. A (relative) body is what makes it possible for a mind to  
</em><br />
<em class="quotelev1">&gt; manifest itself relatively to some history/computation-from-inside.
</em><br />
<em class="quotelev1">&gt; The movie graph argument (the 8th of UDA) justifies the necessity of  
</em><br />
<em class="quotelev1">&gt; this, but just meditation on the phantom limbs can help. The pain is  
</em><br />
<em class="quotelev1">&gt; not in the limb (given the absence of the limb), and the pain is not  
</em><br />
<em class="quotelev1">&gt; in the brain, (the brain is not sensitive) yet the subject locates the  
</em><br />
<em class="quotelev1">&gt; pain in the limb. Similarly we located ourself in space time, but if  
</em><br />
<em class="quotelev1">&gt; you push the logic of comp to its ultimate conclusion you understand  
</em><br />
<em class="quotelev1">&gt; that, assuming comp, space time is a phantom itself. Plato was on the  
</em><br />
<em class="quotelev1">&gt; right (with respect to comp) track.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; (Math: And computer science makes it possible to derive the  
</em><br />
<em class="quotelev1">&gt; mathematical description of that phantom,  making comp Popper  
</em><br />
<em class="quotelev1">&gt; falsifiable. The phantom can be mathematically recovered from  
</em><br />
<em class="quotelev1">&gt; intensional variants of self-referential (Godel) provability modality  
</em><br />
<em class="quotelev1">&gt; G and G*).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; ==========================
</em><br />
<em class="quotelev1">&gt; Brent Meeker wrote
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; My guess is that eventually we'll be able to create AI/robots that  
</em><br />
<em class="quotelev2">&gt;&gt; seem
</em><br />
<em class="quotelev2">&gt;&gt; as intelligent and conscious as, for example, dogs seem.
</em><br />
<em class="quotelev2">&gt;&gt; We'll also be
</em><br />
<em class="quotelev2">&gt;&gt; able to partially map brains so that we can say that when these  
</em><br />
<em class="quotelev2">&gt;&gt; neurons
</em><br />
<em class="quotelev2">&gt;&gt; do this the person is thinking thus and so. Once we have this degree  
</em><br />
<em class="quotelev2">&gt;&gt; of
</em><br />
<em class="quotelev2">&gt;&gt; understanding and control, questions about &quot;consciousness&quot; will no
</em><br />
<em class="quotelev2">&gt;&gt; longer seem relevant.  They'll be like the questions that philosophers
</em><br />
<em class="quotelev2">&gt;&gt; asked about life before we understood the molecular functions of  
</em><br />
<em class="quotelev2">&gt;&gt; living
</em><br />
<em class="quotelev2">&gt;&gt; systems.  They would ask:Where is the life?  Is a virus alive?  How  
</em><br />
<em class="quotelev2">&gt;&gt; does
</em><br />
<em class="quotelev2">&gt;&gt; life get passed from parent to child?   The questions won't get
</em><br />
<em class="quotelev2">&gt;&gt; answered; they'll just be seen as the wrong questions.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; You don't get the point. Mechanism is incompatible with naturalism. To  
</em><br />
<em class="quotelev1">&gt; solve the mind body problem, keeping mechanism, the laws of physicist  
</em><br />
<em class="quotelev1">&gt; have to be explained from computer science, even from the gap between  
</em><br />
<em class="quotelev1">&gt; computer science and computer's computer science ...
</em><br />
<em class="quotelev1">&gt; Physics is the fixed point of universal machine self observation.
</em><br />
<br />That would be a very impressive result if you could prove it - and you could
<br />
prove that there is no other empirically equivalent model.  I've long been of
<br />
the opinion that space and time are constructs.  I also think the integers and
<br />
arithmetic are constructs.  But so far I understand your thesis to be that
<br />
physics consists of certain relations among experiences regarded as mental
<br />
events.  This solves the mind-body problem by making the body a construct of the
<br />
mind.  So far, so good. Further, you hold that these relations are Turing
<br />
computable and so exist in Platonia as a subset of all arithmetic.  I like this
<br />
better than Tegmark's idea of our physics as a subset of all mathematics because
<br />
your idea is more specific and leads to questions that may be answerable.  But I
<br />
still see some problems:
<br />
<br />First, it doesn't eliminate the possibility that some other subset of Platonia,
<br />
e.g. geometry or topology, might also provide a representation of our physics.
<br />
In fact, given that our knowledge of physics is imprecise, it seems likely that
<br />
there are infinitely many subsets of Platonia that are models of our physics. Of
<br />
course you can argue that even a non-computable model of physics may be
<br />
approximated by a computable model to an adequate degree.  But this just pushes
<br />
the question off to what is &quot;adequate&quot; and it does not warrant rejecting
<br />
materialism as explicated by Peter.
<br />
<br />Second, is the problem of finding the fixed point, or distinguishing the measure
<br />
on all the Turing computations that picks out our physics.  I understand you
<br />
have some results, such as &quot;no computation can know which computation it is&quot;,
<br />
which are interesting, but do not pick out any particular physics.  There's a
<br />
general problem here in that the current best theories of physics are based on
<br />
continuous variables.  Many physicists think that an ultimate theory would be
<br />
discrete, but nobody knows how to make a discrete theory from which our
<br />
continuous theories would emerge.
<br />
<br /><em class="quotelev1">&gt; Let me know at which step (1?, ... 8?) you have a problem? The only  
</em><br />
<em class="quotelev1">&gt; one not discussed thoroughly is the 8th one.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; To be sure, do you understand the nuance between the following theses:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; WEAK AI: some machines can behave as if their were conscious (but  
</em><br />
<em class="quotelev1">&gt; could as well be zombies)
</em><br />
<em class="quotelev1">&gt; STRONG AI: some machines can be conscious
</em><br />
<em class="quotelev1">&gt; COMP: I am a machine
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; We have
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; COMP =&gt; STRONG AI =&gt; WEAK AI
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; WEAK does not imply STRONG AI which does not imply COMP. (it is not  
</em><br />
<em class="quotelev1">&gt; because machine can be conscious that we are necessarily machine  
</em><br />
<em class="quotelev1">&gt; ourself, of course with occam razor, STRONG AI go in the direction of  
</em><br />
<em class="quotelev1">&gt; COMP).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Does those nuances make sense? If not (1...8) does not, indeed, make  
</em><br />
<em class="quotelev1">&gt; sense. You just don't believe in consciousness and/or person like in  
</em><br />
<em class="quotelev1">&gt; the eliminative materialism of neuro-philosophers ( the Churchland,  
</em><br />
<em class="quotelev1">&gt; amost Dennett in &quot;consciousness explained&quot;).
</em><br />
<br />As my lawyer friend says, &quot;I'm not in the belief business.&quot;
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Or you make us very special infinite analogical machines, but then you  
</em><br />
<em class="quotelev1">&gt; drop the digital mechanist thesis (even the naturalist one, which has  
</em><br />
<em class="quotelev1">&gt; been shown inconsistent by 1...8.)
</em><br />
<br />I think it might be that the universe is not computable.  But I think it is very 
<br />
likely that one's consciousness is computable, at least for a finite time period.
<br />
<br />Brent
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Bruno Marchal
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; <a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sun Nov 09 2008 - 14:29:00 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start15174">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="15175.html" title="Next message in the list">Brent Meeker: "Re: QTI &#0038; euthanasia (brouillon)"</a></li>
<li><dfn>Previous message</dfn>: <a href="15173.html" title="Previous message in the list">Bruno Marchal: "Re: QTI &#0038; euthanasia (brouillon)"</a></li>
<li><dfn>In reply to</dfn>: <a href="15080.html" title="Message to which this message replies">Bruno Marchal: "Re: QTI &#0038; euthanasia"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="15179.html" title="Next message in this discussion thread">Bruno Marchal: "Re: QTI &#0038; euthanasia"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="15179.html" title="Message sent in reply to this message">Bruno Marchal: "Re: QTI &#0038; euthanasia"</a></li>
<li><dfn>Reply</dfn>: <a href="15188.html" title="Message sent in reply to this message">Bruno Marchal: "Re: QTI &#0038; euthanasia"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15174" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15174" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15174" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15174" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
