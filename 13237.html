<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Statistical Measure, does it matter? from Stathis Papaioannou on 2007-03-31 (everything)</title>
<meta name="Author" content="Stathis Papaioannou (stathisp.domain.name.hidden)" />
<meta name="Subject" content="Re: Statistical Measure, does it matter?" />
<meta name="Date" content="2007-03-31" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Statistical Measure, does it matter?</h1>
<!-- received="Sat Mar 31 23:49:06 2007" -->
<!-- isoreceived="20070401064906" -->
<!-- sent="Sun, 1 Apr 2007 13:48:55 +1000" -->
<!-- isosent="20070401034855" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathisp.domain.name.hidden" -->
<!-- subject="Re: Statistical Measure, does it matter?" -->
<!-- id="f21c22e30703312048h1acffef0l905987cb3943fb99.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="1acbded70703301445j4c95f7efg1c30a3e4555ee383.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13237" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13238.html" accesskey="d" title="John Mikes: &quot;Re: Statistical Measure, does it matter?&quot;">Next message</a> ]
[ <a href="13236.html" title="John Mikes: &quot;Re: Statistical Measure, does it matter?&quot;">Previous message</a> ]
[ <a href="13236.html" title="John Mikes: &quot;Re: Statistical Measure, does it matter?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13238.html" accesskey="t" title="John Mikes: &quot;Re: Statistical Measure, does it matter?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13237" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13237" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13237" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13237" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Stathis Papaioannou &lt;<a href="mailto:stathisp.domain.name.hidden?Subject=Re%3A%20Statistical%20Measure%2C%20does%20it%20matter%3F">stathisp.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sun, 1 Apr 2007 13:48:55 +1000</span><br />
</address>
<br />
On 3/31/07, John Mikes &lt;jamikes.domain.name.hidden&gt; wrote:
<br />
<br />The non-standard part of Bruno's comp, as I see it, is to accept that
<br />
<em class="quotelev2">&gt; &gt; computation can lead to thought but to reject the physical supervenience
</em><br />
<em class="quotelev2">&gt; &gt; theory, i.e. that computation requires certain physical processes to
</em><br />
<em class="quotelev2">&gt; &gt; take place in order to &quot;happen&quot;. But that question aside, computationalism
</em><br />
<em class="quotelev2">&gt; &gt; depends on the idea that (a) it is *in principle* possible to reproduce all
</em><br />
<em class="quotelev2">&gt; &gt; the physical processes in our brain using a computer, to an arbitrary degree
</em><br />
<em class="quotelev2">&gt; &gt; of precision, and (b) such a reproduction, yielding by definition a
</em><br />
<em class="quotelev2">&gt; &gt; functionally identical brain, also yields a functionally identical mind -
</em><br />
<em class="quotelev2">&gt; &gt; i.e., as opposed to a zombie. Roger Penrose says that (a) is false; John
</em><br />
<em class="quotelev2">&gt; &gt; Searle and religious people say that even if (a) is true, (b) is false. I
</em><br />
<em class="quotelev2">&gt; &gt; tend to think that (a) and (b) are both true, but I am not completely sure.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt; Here we go:
</em><br />
<em class="quotelev1">&gt; i.e. that computation requires certain physical processes to take place in
</em><br />
<em class="quotelev1">&gt; order to &quot;happen&quot;.
</em><br />
<em class="quotelev1">&gt; What else can we 'imagine'? Ideationa -- of whom? Mine? Yours? I wouild
</em><br />
<em class="quotelev1">&gt; not recite &quot;of the unioverse&quot; because HOW do we have access to a conscious
</em><br />
<em class="quotelev1">&gt; process of the totality with our limited mind?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />I don't quite understand this question.
<br />
<br />...(a) it is *in principle* possible to reproduce all the physical processes
<br />
<em class="quotelev1">&gt; in our brain using a computer,...
</em><br />
<em class="quotelev1">&gt; In principle EVERYTHING is possible. Look at the discussions on this list.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />My &quot;in principle&quot; is somewhat narrower: I meant physically possible, given
<br />
the laws of our universe, without recourse to multiverses etc.
<br />
<br />...(b) such a reproduction, yielding by definition a functionally identical
<br />
<em class="quotelev1">&gt; brain,...
</em><br />
<em class="quotelev1">&gt; If a 'model' is identical in all respects (&quot;functionally&quot;) it is not a
</em><br />
<em class="quotelev1">&gt; model, it is the THING itself. So we are in this case playing withg words.
</em><br />
<em class="quotelev1">&gt; NOTHING can be completely identical in this world, because everything is the
</em><br />
<em class="quotelev1">&gt; product of ALL the actual circumstances co- functioning in the construction
</em><br />
<em class="quotelev1">&gt; of the 'thing' (process). And ALL the circumstances do not ever repeat
</em><br />
<em class="quotelev1">&gt; themselves identically: it would be a merrygoround world loop what we so far
</em><br />
<em class="quotelev1">&gt; did not experience. We can find similarity in ALL aspects we observe, but
</em><br />
<em class="quotelev1">&gt; that does not include the complete totality. We like to call such similarity
</em><br />
<em class="quotelev1">&gt; an 'identity'..
</em><br />
<em class="quotelev1">&gt; .So I do not argue against your finding a) and b) possible, but does it
</em><br />
<em class="quotelev1">&gt; make sense?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />If we could model a hurricane on a computer the simulation would not destroy
<br />
houses, but if the model were good enough it would tell us which houses a
<br />
real hurricane would destroy. Similarly, if we could model a brain, we would
<br />
be in a position to know how a person would behave in a given situation. We
<br />
could use the computer model to control the person's muscles and no-one
<br />
would realise he wasn't a &quot;real&quot; person, i.e. we would have at least a
<br />
zombie.
<br />
<br />2. Replaced? meaning one takes out that goo of neurons, proteins and other
<br />
<em class="quotelev3">&gt; &gt; &gt; tissue-stuff with its blood suply and replace the cavity (no matter how
</em><br />
<em class="quotelev3">&gt; &gt; &gt; bigger or smaller) by a (watch it): *digital* computer, &quot;appropriately
</em><br />
<em class="quotelev3">&gt; &gt; &gt; configured&quot; and electric flow in it. For the quale-details see the par #1.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Each neuron is made up of macromolecules in a watery medium. The
</em><br />
<em class="quotelev2">&gt; &gt; macromolecules follow the laws of physics: there are equations which
</em><br />
<em class="quotelev2">&gt; &gt; describe how phospholipid bilayers form membranes, how proteins embedded in
</em><br />
<em class="quotelev2">&gt; &gt; these membranes change conformation when ligands bind to them, how these
</em><br />
<em class="quotelev2">&gt; &gt; conformation changes result in ion fluxes and changes in transmembrane
</em><br />
<em class="quotelev2">&gt; &gt; potential, and so on. So if you ignore for the moment the technical
</em><br />
<em class="quotelev2">&gt; &gt; difficulties involved in working all this out and implementing it, it should
</em><br />
<em class="quotelev2">&gt; &gt; be possible to program a computer to behave just like a biological brain,
</em><br />
<em class="quotelev2">&gt; &gt; receiving afferent impulses from sense organs and sending afferent impulses
</em><br />
<em class="quotelev2">&gt; &gt; to muscles, which would result in a being whose behaviour is
</em><br />
<em class="quotelev2">&gt; &gt; indistinguishable from that of an intact human. The only way around this
</em><br />
<em class="quotelev2">&gt; &gt; conclusion is if the behaviour of the brain depends on physical processes
</em><br />
<em class="quotelev2">&gt; &gt; which are not computable, like Penrose's postulated quantum gravity effects.
</em><br />
<em class="quotelev2">&gt; &gt; This is possible, but there isn't really any good evidence supporting it, as
</em><br />
<em class="quotelev2">&gt; &gt; far as I'm aware.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; 3-29 insert s:
</em><br />
<em class="quotelev1">&gt; ...The macromolecules follow the laws of physics:...
</em><br />
<em class="quotelev1">&gt; NONONONONO!  Certain experiences with macromolecules are described in our
</em><br />
<em class="quotelev1">&gt; incompletge views as being described by certain (statistical?
</em><br />
<em class="quotelev1">&gt; probabilistic?) findings in the physical domain. Macro- or
</em><br />
<em class="quotelev1">&gt; nonmacromolecules, atoms, their parts, show behavior in our 'slanted',
</em><br />
<em class="quotelev1">&gt; 'partial'. observation which have been matched to calculations drawn upon
</em><br />
<em class="quotelev1">&gt; similarly era-restricted observational explanatory calculations (physics). I
</em><br />
<em class="quotelev1">&gt; did not work with atoms or molecules, when I made my macromo;leculs and
</em><br />
<em class="quotelev1">&gt; their applications. I worked with masses that behaved. Then I put them into
</em><br />
<em class="quotelev1">&gt; a reductionist analysis abd tried to 'match' the numerical data to those in
</em><br />
<em class="quotelev1">&gt; the books. I made 'bilayers', 'ligands'. Indeed I got responses which I
</em><br />
<em class="quotelev1">&gt; described as performing as expected. And got the patents.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />But you wouldn't have been granted the patents if your experiments were not
<br />
repeatable. You don't even need &quot;science&quot;: a precise description of what
<br />
happens when you mix substance A with substance B under physical conditions
<br />
C will suffice. Similarly, for each part of the brain, a precise description
<br />
of what happens when, for example, a certain neurotransmitter is released
<br />
into a certain synapse, will allow you eventually to predict how the whole
<br />
brain will behave, amazingly difficult though that task would be.
<br />
<br />...it should be possible to program a computer to behave just like a
<br />
<em class="quotelev1">&gt; biological brain,...
</em><br />
<em class="quotelev1">&gt; How does a 'biological brain' work? we - so far - extracted some
</em><br />
<em class="quotelev1">&gt; behavioral deductions into the model we have about the goo-in-the-skull and
</em><br />
<em class="quotelev1">&gt; call it a &quot;total&quot; - even with those unknown parts which come from outside
</em><br />
<em class="quotelev1">&gt; the matter-reactions we have access to - or even from so far undiscovered
</em><br />
<em class="quotelev1">&gt; aspects/factors. And I would not call it &quot;biological&quot; which is a limited
</em><br />
<em class="quotelev1">&gt; model of the functionality. One difficulty is the baggage in the words we
</em><br />
<em class="quotelev1">&gt; are restrict to in our historically developed language.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />With all the scrutiny, there would be some evidence of behaviour in the
<br />
brain that biochemistry cannot explain. There isn't, any more than there is
<br />
for any other organ in the body. Certainly there are many things in biology
<br />
that we can't yet explain, but the sheer complexity of the biochemical
<br />
processes makes this inevitable. I can't explain exactly how my computer
<br />
works, but I that doesn't mean it must contain magical processes.
<br />
<br />... it should be possible ...
<br />
<em class="quotelev1">&gt; Amen. It should. I would be happy. (But, alas, it isn't)
</em><br />
<em class="quotelev1">&gt; ... indistinguishable from that of an intact human....
</em><br />
<em class="quotelev1">&gt; looks to me like the right sentence, just let it be known by what
</em><br />
<em class="quotelev1">&gt; model-characteristics (qualia) do we distinguish? Or 'can' we distinguish. In
</em><br />
<em class="quotelev1">&gt; what respect? First: Do we KNOW all details of an 'infact human' full
</em><br />
<em class="quotelev1">&gt; process? I think we know only a part of it, the oneS which ARE accessible to
</em><br />
<em class="quotelev1">&gt; our presently applied observational power and knowledge base. Just compare
</em><br />
<em class="quotelev1">&gt; to the 'infact' human as described in 1000AD or 3000BC. etc. - not in
</em><br />
<em class="quotelev1">&gt; 2300AD.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />You build your model of the brain, then you test it to see if it behaves
<br />
like a real brain. If it doesn't, you go back and try to refine your model.
<br />
When you can't tell the difference between the model and the real brain you
<br />
have succeeded.
<br />
<br />...if you ignore for the moment the technical difficulties involved in
<br />
<em class="quotelev1">&gt; working all this out and implementing it,
</em><br />
<em class="quotelev1">&gt; in other words it is impossible, but we can think about it. No, in my
</em><br />
<em class="quotelev1">&gt; practical thinking only the possible (everything though it may be) is
</em><br />
<em class="quotelev1">&gt; usable, not input of which we presume that it is not feasible (possible?).
</em><br />
<em class="quotelev1">&gt; The difficulties are not 'technical', they are ontological. Not fitting into
</em><br />
<em class="quotelev1">&gt; circumstances we 'even suppose' .
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />Do you acknowledge that there is a difference between the physically
<br />
impossible, and the merely practically impossible?
<br />
<br /><em class="quotelev1">&gt; 3. &quot;you&quot; - and who should that be? can we separate our living
</em><br />
<em class="quotelev3">&gt; &gt; &gt; brain (I mean with all its functionality) from 'YOU', the self, the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; person, or call it the simulacron of yourself? What's left? Is there &quot;me&quot;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; and &quot;my brain&quot;? As I like to call it: the brain is the 'tool' of my
</em><br />
<em class="quotelev3">&gt; &gt; &gt; mind, mind is pretty unidentified,  but - is close to my-self, some call it
</em><br />
<em class="quotelev3">&gt; &gt; &gt; life, some consciousness, - those items we like to argue about because none
</em><br />
<em class="quotelev3">&gt; &gt; &gt; of us knows what we are talking about (some DO THINK they know, but only
</em><br />
<em class="quotelev3">&gt; &gt; &gt; something and for themselves).
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I find it hard to define consciousness, but I know what it is, and so
</em><br />
<em class="quotelev2">&gt; &gt; does everyone who has it.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; And everyone (not really) knows it personalized and differently. Scholars:
</em><br />
<em class="quotelev1">&gt; slanted to their theoretical needs, others maybe to their emotions.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;  4. &quot;feel&quot; ----????---- who/what? the transistors?
</em><br />
<em class="quotelev3">&gt; &gt; &gt; (Let me repeat: I am not talking about Transistor Stathis).
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; You could equally well ask, do the proteins/ phospholipids/ nucleic
</em><br />
<em class="quotelev2">&gt; &gt; acids etc. feel? Apparently, they do. If your brain stops working or is
</em><br />
<em class="quotelev2">&gt; &gt; seriously damaged, you stop feeling.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I am not speaking about how 'parts' feel, rather how the complexity acts.
</em><br />
<em class="quotelev1">&gt; The brain is a tool cooperating in our mental factor, so if the tool is
</em><br />
<em class="quotelev1">&gt; damaged certain activities of it may be missing, or perform inadequately.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />That's right; but are you suggesting that in addition to the physical parts,
<br />
there are other parts? That is, that even though a brain is perfectly intact
<br />
physically and seems to be functioning normally to an outside observer, it
<br />
might yet not be conscious because it lacks some non-physical component,
<br />
such as a soul? There is no evidence for this.
<br />
<br /><em class="quotelev1">&gt; *-SP:
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Bruno goes on to show that this entails there is no separate physical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; reality by means of the UDA, but we can still talk about computationalism -
</em><br />
<em class="quotelev3">&gt; &gt; &gt; the predominant theory in cognitive science - without discussing the UDA.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; And in any case, the ideas Brent and I have been discussing are still
</em><br />
<em class="quotelev3">&gt; &gt; &gt; relevant if computationalism is wrong and (again a separate matter) there is
</em><br />
<em class="quotelev3">&gt; &gt; &gt; only one universe.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Stathis Papaioannou-*
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; &lt;JM&gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Yes, &quot;we today&quot; KNOW about only 1 universe. But we believe in a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; physical reality what we 'feel', 'live it' and hold as our 'truth' as well.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Even those 'more advanced' minds saying they don't believe in it, cry out
</em><br />
<em class="quotelev3">&gt; &gt; &gt; (OMIGOD!) when &quot;Dr. Johnson's stone&quot; hurts their toe in the shoe.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I like to draw comparisons between &quot;what we know today&quot; and what we
</em><br />
<em class="quotelev3">&gt; &gt; &gt; knew 1000, 3000, or 5000 years ago and ask: what will we 'know' just 500
</em><br />
<em class="quotelev3">&gt; &gt; &gt; years ahead in the future by a continuing epistemic enrichment? (If humanity
</em><br />
<em class="quotelev3">&gt; &gt; &gt; survives that long).
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Please, readers, just list the answers alphabetically.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I don't know the answer. Maybe next year there will be some discovery
</em><br />
<em class="quotelev2">&gt; &gt; which will have us all laughing at the idea that computers can be conscious,
</em><br />
<em class="quotelev2">&gt; &gt; but at present we can only go on the information available to us, and try to
</em><br />
<em class="quotelev2">&gt; &gt; keep an open mind.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Stathis, I may cross my fingers, but would not hold my breath. IMO we
</em><br />
<em class="quotelev1">&gt; 'know' a little part, the unknown may be the essential and overwhelming.
</em><br />
<em class="quotelev1">&gt; Good luck to humanity to become smarter before extinct.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />Stathis Papaioannou
<br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sat Mar 31 2007 - 23:49:06 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13237">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13238.html" title="Next message in the list">John Mikes: "Re: Statistical Measure, does it matter?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13236.html" title="Previous message in the list">John Mikes: "Re: Statistical Measure, does it matter?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13236.html" title="Message to which this message replies">John Mikes: "Re: Statistical Measure, does it matter?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13238.html" title="Next message in this discussion thread">John Mikes: "Re: Statistical Measure, does it matter?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="13238.html" title="Message sent in reply to this message">John Mikes: "Re: Statistical Measure, does it matter?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13237" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13237" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13237" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13237" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:13 PST
</em></small></p>
</body>
</html>
