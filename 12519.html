<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: The Meaning of Life from John Mikes on 2007-01-12 (everything)</title>
<meta name="Author" content="John Mikes (jamikes.domain.name.hidden)" />
<meta name="Subject" content="Re: The Meaning of Life" />
<meta name="Date" content="2007-01-12" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: The Meaning of Life</h1>
<!-- received="Fri Jan 12 09:04:50 2007" -->
<!-- isoreceived="20070112170450" -->
<!-- sent="Fri, 12 Jan 2007 09:04:36 -0500" -->
<!-- isosent="20070112140436" -->
<!-- name="John Mikes" -->
<!-- email="jamikes.domain.name.hidden" -->
<!-- subject="Re: The Meaning of Life" -->
<!-- id="1acbded70701120604k4fda878es5f7c5580fa7356d1.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY124-W58D26C514EF8B90FDD853FD2B10.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start12519" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="12520.html" accesskey="d" title="Mark Peaty: &quot;Re: Evil ?&quot;">Next message</a> ]
[ <a href="12518.html" title="Brent Meeker: &quot;Re: Evil ?&quot;">Previous message</a> ]
[ <a href="12513.html" title="Stathis Papaioannou: &quot;RE: The Meaning of Life&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="12522.html" accesskey="t" title="Stathis Papaioannou: &quot;RE: The Meaning of Life&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg12519" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg12519" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg12519" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg12519" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: John Mikes &lt;<a href="mailto:jamikes.domain.name.hidden?Subject=Re%3A%20The%20Meaning%20of%20Life">jamikes.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 12 Jan 2007 09:04:36 -0500</span><br />
</address>
<br />
On 1/10/07, Stathis Papaioannou &lt;stathispapaioannou.domain.name.hidden&gt; wrote:
<br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Bruno Marchal writes:
</em><br />
<em class="quotelev1">&gt; ....
</em><br />
<em class="quotelev1">&gt; Regarding consciousness being generated by physical activity, would it
</em><br />
<em class="quotelev1">&gt; help if
</em><br />
<em class="quotelev1">&gt; I said that if a conventional computer is conscious, then, to be
</em><br />
<em class="quotelev1">&gt; consistent, a
</em><br />
<em class="quotelev1">&gt; rock would also have to be conscious?


</em><br />
JM:  Bruno:
<br />
A rock will not read an article in the Figaro, but that is not the rock's
<br />
fault. It is our usage of the human terms transferred into non-human
<br />
applications, what I sense all over. Did we properly identified 'conscious'?
<br />
I feel (generalized DOWN the complexity-scale)  it is some 'mental
<br />
sensitivity' - maybe more. Human mentality of course. Even if animals are
<br />
deemed conscious, it is in human measures. Like: animals are stupid: cannot
<br />
talk. Washoe chimp 'talked' US sign language and how else should a creature
<br />
articulate its sounds (for human talk) without proper equipment to do so?
<br />
Sensitivity with the proper premises is 'conscious' in humans - as we call
<br />
it. A rock has response to information it can acknowledge, it is semantics
<br />
what word we use to mark it. A pine tree does not run, a human does not fly.
<br />
(how stupid, says the chicken),

<br />
<em class="quotelev1">&gt; Also, when you say:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; It is a way to sum up my point. If we are machine, then the assumption
</em><br />
<em class="quotelev2">&gt; &gt; of a physical reality cannot explain why we believe in a physical
</em><br />
<em class="quotelev2">&gt; &gt; reality. Indeed the believe in a physical reality is something
</em><br />
<em class="quotelev2">&gt; &gt; emergent. With comp the mind-body problem is two times more difficult
</em><br />
<em class="quotelev2">&gt; &gt; than without, because we have to explain &quot;matter appearance&quot; without
</em><br />
<em class="quotelev2">&gt; &gt; assuming it.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Why do you think all the evidence of our senses would be illusory?
</em><br />
<em class="quotelev2">&gt; &gt; Nobody has seen &quot;primitive matter&quot;. I thought even just Kant made this
</em><br />
<em class="quotelev2">&gt; &gt; clear.
</em><br />
<em class="quotelev2">&gt; &gt; Paper by physicists never assume &quot;primitive matter&quot;, except in some
</em><br />
<em class="quotelev2">&gt; &gt; implicit background which play no role in the ideas. All papers by
</em><br />
<em class="quotelev2">&gt; &gt; physicists just propose relation between numbers, and eventually &quot;I&quot; do
</em><br />
<em class="quotelev2">&gt; &gt; relate those numbers with some of my qualia (like the qualia of being
</em><br />
<em class="quotelev2">&gt; &gt; convinced having seen a needle in such or such places. Primitive matter
</em><br />
<em class="quotelev2">&gt; &gt; is a metaphysical concept, today, and with comp it is has been made
</em><br />
<em class="quotelev2">&gt; &gt; scientific: indeed it is made quasi-contradictory.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; I believe in the moon, but I don't believe the moon is made of atoms
</em><br />
<em class="quotelev2">&gt; &gt; (this is just a good local description). I believe in atoms, but I
</em><br />
<em class="quotelev2">&gt; &gt; don't believe atoms are made of elementary particles (this is just a
</em><br />
<em class="quotelev2">&gt; &gt; good local description). I believe in elementary particles, but I don't
</em><br />
<em class="quotelev2">&gt; &gt; believe elementary particles are made of strings (this could be a good
</em><br />
<em class="quotelev2">&gt; &gt; local description), etc. (and with comp probably the &quot;etc&quot; is
</em><br />
<em class="quotelev2">&gt; &gt; obligatory).
</em><br />
<em class="quotelev2">&gt; &gt; I believe in strings, but I don't believe strings are made of something
</em><br />
<em class="quotelev2">&gt; &gt; else, except in some first approximation.
</em><br />
<em class="quotelev2">&gt; &gt; But with comp I do believe all that *must* emerge from the &quot;collective
</em><br />
<em class="quotelev2">&gt; &gt; behavior&quot; of numbers.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Regards,
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Bruno
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It's difficult to find the right words here. I think we can all agree on
</em><br />
<em class="quotelev1">&gt; the appearance
</em><br />
<em class="quotelev1">&gt; of a physical reality as a starting point. The common sense view is that
</em><br />
<em class="quotelev1">&gt; there is an
</em><br />
<em class="quotelev1">&gt; underlying primitive physical reality generating this appearance, without
</em><br />
<em class="quotelev1">&gt; which the
</em><br />
<em class="quotelev1">&gt; appearance would vanish and relative to which dream and illusion can be
</em><br />
<em class="quotelev1">&gt; defined.
</em><br />
<em class="quotelev1">&gt; If this is so, it is not a scientifically testable theory. We can't just
</em><br />
<em class="quotelev1">&gt; switch off the
</em><br />
<em class="quotelev1">&gt; physical reality to see whether it changes the appearance, and the further
</em><br />
<em class="quotelev1">&gt; we delve
</em><br />
<em class="quotelev1">&gt; into matter all we see is more appearance (and stranger and stranger
</em><br />
<em class="quotelev1">&gt; appearance at
</em><br />
<em class="quotelev1">&gt; that). Moreover, dream and illusion are defined relative to the appearance
</em><br />
<em class="quotelev1">&gt; of regular
</em><br />
<em class="quotelev1">&gt; physical reality, not relative to the postulated primitive physical
</em><br />
<em class="quotelev1">&gt; reality.


</em><br />
JM:
<br />
At least so we have it in our presently formulated &quot;scientific belief
<br />
system'&quot; (a.k.a. science religion).
<br />
Instead of assuming &quot;God's Words&quot; as evidence, we imply tests - within the
<br />
system - by instruments made FOR the system BY the system and &quot;nothing but
<br />
the system&quot;. And explanations (calculations) drawn FROM the system we
<br />
believe in as scientific (physical?). Preliminaries are nicely written in
<br />
the (holy?) books of science - The Scripture - and all college kids learn it
<br />
and believe (in?) it.
<br />
Physical reality? My foot (especially if it aches).

<br />
Regards

<br />
John M



<br />
<em class="quotelev1">&gt; Le 08-janv.-07, à 23:36, Stathis Papaioannou a écrit :
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Bruno Marchal writes:
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; Le 07-janv.-07, à 19:21, Brent Meeker a écrit :
</em><br />
<em class="quotelev3">&gt; &gt; &gt;&gt; &gt;&gt; &gt; And does it even have to be very good?  Suppose it made a sloppy
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; copy &gt; of me that left out 90% of my memories - would it still be
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; &quot;me&quot;?  How &gt; much fidelity is required for Bruno's argument?  I
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; think &gt;&gt; not much.
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; The argument does not depend at all of the level of fidelity.
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; Indeed &gt;&gt; I make clear (as much as possible) that comp is equivalent
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; to the &gt;&gt; belief there is a level of substitution of myself
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; (3-person) such &gt;&gt; that I (1-person) survive a functional
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; substitution done at that &gt;&gt; level. Then I show no machine can know
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; what is her level of &gt;&gt; substitution (and thus has to bet or guess
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; about it).
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; This is also the reason why comp is not jeopardized by the idea
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; that &gt;&gt; the environment is needed: just put the environment in the
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; definition &gt;&gt; of my &quot;generalized brain&quot;.
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; Imagine someone who say that his brain is the entire galaxy, &gt;&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; described at the level of all interacting quantum strings. This can
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; be captured by giant (to say the least) but finite, rational
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; complex &gt;&gt; matrices. Of course the thought experiment with the &quot;yes
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; doctor&quot; will &gt;&gt; look very non-realist, but *in fine*, all what is
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; needed (for the &gt;&gt; reversal) is that the Universal Dovetailer get
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; through the state of &gt;&gt; my generalized brain, and the UD will get it
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; even if my &quot;state&quot; is &gt;&gt; the state of the whole galaxy, or more.
</em><br />
<em class="quotelev2">&gt; &gt; &gt;&gt; &gt;&gt; If it happens that my state is the galaxy state AND that the
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; galaxy &gt;&gt; state cannot be captured in a finite ('even giant) way(*),
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; then we &gt;&gt; are just out of the scope of the comp- reasoning. This is
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; possible &gt;&gt; because comp may be wrong.
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; This is right, and it is perhaps a consequence of comp that &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; computationalists did not brgain on. If the functional equivalent of
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; my brain has to interact with the environment in the same way that
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; I &gt; do then that puts a constraint what sort of machine it can be, as
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; well &gt; as necessitating of course that it be an actual physical
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; machine. For &gt; example, if as part of asserting my status as a
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; conscious being I &gt; decide to lift my hand in the air when I see a
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; red ball, then my &gt; functional replacement must (at least) have
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; photoreceptors which send &gt; a signal to a central processor which
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; then sends a motor signal to its &gt; hand. If it fails the red ball
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; test, then it isn't functionally &gt; equivalent to me.
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; However, what if you put the red ball, the hand and the whole &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; environment inside the central processor? You program in data which &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; tells it is seeing a red ball, it sends a signal to what it thinks is
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; its hand, and it receives visual and proprioceptive data telling it
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; it &gt; has successfully raised the hand. Given that this self-contained
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; machine was derived from a known computer architecture with known &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; sensors and effectors, we would know what it was thinking by &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; eavesdropping on its internal processes. But if we didn't have this &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; knowledge, is there any way, even in theory, that we could figure it
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; out? The answer in general is &quot;no&quot;: without benefit of
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; environmental &gt; interaction, or an instruction manual, there is no
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; way to assign &gt; meaning to the workings of a machine and there is no
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; way to know &gt; anything about its consciousness.
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; Up to here I do agree.
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; The corollary of this is that under the right interpretation a
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; machine &gt; could have any meaning or any consciousness.
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; I don't think that this corollary follows. Unless you are postulating
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; a &quot;physical world&quot; having some special property (and then the
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; question is: what are your axiom for that physical realm, and where
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; does those axioms come from). Even in classical physics, where a
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; point can move along &quot;all real numbers&quot;, I don't see any reason such
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; move can represent any computation. Of course I consider a
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; computation as being something non physical, and essentially
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; discrete, at the start. The physical and continuous aspect comes from
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; the fact that any computation is &quot;embedded&quot; into an infinity of
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; &quot;parallel&quot; computations (those generated by the UD).
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; Brent says that the &quot;evil problem&quot; is a problem only for those who
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; postulate an omniscient and omnipotent good god. I believe that
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; somehow a large part of the &quot;mind/body&quot; problem comes from our
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; (instinctive) assumption of a basic (primitive) physical reality.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Yes, but you're assuming here that which I (you?) set out to prove. In
</em><br />
<em class="quotelev3">&gt; &gt; &gt; your UDA you do not explicitly start out with &quot;there is no physical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; world&quot; but arrive at this as a conclusion. Consider the following
</em><br />
<em class="quotelev3">&gt; &gt; &gt; steps:
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 1. There appears to be a physical world
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 2. Some of the substructures in this world appear to be conscious,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; namely brains
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 3. The third person behaviour of these brains can be copied by an
</em><br />
<em class="quotelev3">&gt; &gt; &gt; appropriate digital computer
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 4. The first person experience of these brains would also thereby be
</em><br />
<em class="quotelev3">&gt; &gt; &gt; copied by such a computer
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 5. The first person experience of the computer would remain unchanged
</em><br />
<em class="quotelev3">&gt; &gt; &gt; if the third person behaviour were made part of the program
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 6. But this would mean there is no way to attach meaning or
</em><br />
<em class="quotelev3">&gt; &gt; &gt; consciousness to the self-contained computer - it could be thinking of
</em><br />
<em class="quotelev3">&gt; &gt; &gt; a red ball, blue ball, or no ball
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; This is an unexpected result, which can be resolved several ways:
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 7. (3) is incorrect, and we need not worry about the rest
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 8. (4) is incorrect, and we need not worry about the rest
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 9. (5) is incorrect, and we need not worry about the rest
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; [(7) or (8) would mean that there is something non-computational about
</em><br />
<em class="quotelev3">&gt; &gt; &gt; the brain; (9) would mean there is something non-computational about a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; computer interacting with its environment, which seems to me even less
</em><br />
<em class="quotelev3">&gt; &gt; &gt; plausible.]
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; But if (3) to (5) are all correct, that leaves (6) as correct, which
</em><br />
<em class="quotelev3">&gt; &gt; &gt; implies that consciousness is decoupled from physical activity. This
</em><br />
<em class="quotelev3">&gt; &gt; &gt; would mean that in those cases where we do associate consciousness
</em><br />
<em class="quotelev3">&gt; &gt; &gt; with particular physical activity, such as in brains or computers, it
</em><br />
<em class="quotelev3">&gt; &gt; &gt; is not really the physical activity which is &quot;causing&quot; the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; consciousness. I think of it as analogous to a computer doing
</em><br />
<em class="quotelev3">&gt; &gt; &gt; arithmetic: it is not &quot;causing&quot; the arithmetic, but is harnessing a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; mathematical truth to some physical task.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; If consciousness is decoupled from physical activity, this means that
</em><br />
<em class="quotelev3">&gt; &gt; &gt; our conscious experience would be unchanged if the apparent physical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; activity of our brain were not really there. This would make all the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; evidence of our senses on which we base the existence of a physical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; world illusory: we would have these same experiences if the physical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; world suddenly disappeared or never existed in the first place. We can
</em><br />
<em class="quotelev3">&gt; &gt; &gt; keep (1) and (2) because I qualified them with the word &quot;appears&quot;, but
</em><br />
<em class="quotelev3">&gt; &gt; &gt; the necessity of a separate physical reality accounting for this
</em><br />
<em class="quotelev3">&gt; &gt; &gt; appearance goes.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt;&gt; &gt; You can't avoid the above problem without making changes to
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; (standard) &gt; computationalism. You can drop computationalism
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; altogether and say &gt; that the brain + environment is not Turing
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; emulable. Or, as Bruno has &gt; suggested, you can keep computationalism
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; and drop the physical &gt; supervenience criterion.
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; I am OK with this ('course).
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; Bruno
</em><br />
<em class="quotelev4">&gt; &gt; &gt;&gt; <a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Stathis Papaioannou
</em><br />
<em class="quotelev1">&gt;


</em><br />
--~--~---------~--~----~------------~-------~--~----~
<br />
&nbsp;You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---

<br />
<span id="received"><dfn>Received on</dfn> Fri Jan 12 2007 - 09:04:50 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start12519">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="12520.html" title="Next message in the list">Mark Peaty: "Re: Evil ?"</a></li>
<li><dfn>Previous message</dfn>: <a href="12518.html" title="Previous message in the list">Brent Meeker: "Re: Evil ?"</a></li>
<li><dfn>In reply to</dfn>: <a href="12513.html" title="Message to which this message replies">Stathis Papaioannou: "RE: The Meaning of Life"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="12522.html" title="Next message in this discussion thread">Stathis Papaioannou: "RE: The Meaning of Life"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg12519" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg12519" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg12519" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg12519" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:13 PST
</em></small></p>
</body>
</html>
