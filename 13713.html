<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Penrose and algorithms from LauLuna on 2007-07-06 (everything)</title>
<meta name="Author" content="LauLuna (laureanoluna.domain.name.hidden)" />
<meta name="Subject" content="Re: Penrose and algorithms" />
<meta name="Date" content="2007-07-06" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Penrose and algorithms</h1>
<!-- received="Fri Jul  6 08:54:24 2007" -->
<!-- isoreceived="20070706155424" -->
<!-- sent="Fri, 06 Jul 2007 05:53:54 -0700" -->
<!-- isosent="20070706125354" -->
<!-- name="LauLuna" -->
<!-- email="laureanoluna.domain.name.hidden" -->
<!-- subject="Re: Penrose and algorithms" -->
<!-- id="1183726434.194369.162020.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="BAY16-F8F1908FA17CB31C0515E0C7020.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13713" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13714.html" accesskey="d" title="LauLuna: &quot;Re: Penrose and algorithms&quot;">Next message</a> ]
[ <a href="13712.html" title="Jason: &quot;Re: Penrose and algorithms&quot;">Previous message</a> ]
[ <a href="13710.html" title="Jesse Mazer: &quot;Re: Penrose and algorithms&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13721.html" accesskey="t" title="Bruno Marchal: &quot;Re: Penrose and algorithms&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13713" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13713" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13713" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13713" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: LauLuna &lt;<a href="mailto:laureanoluna.domain.name.hidden?Subject=Re%3A%20Penrose%20and%20algorithms">laureanoluna.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 06 Jul 2007 05:53:54 -0700</span><br />
</address>
<br />
On Jul 5, 10:14 pm, &quot;Jesse Mazer&quot; &lt;laserma....domain.name.hidden&gt; wrote:
<br />
<em class="quotelev1">&gt; LauLuna wrote:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;On 29 jun, 19:10, &quot;Jesse Mazer&quot; &lt;laserma....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev3">&gt; &gt; &gt; LauLuna  wrote:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;On 29 jun, 02:13, &quot;Jesse Mazer&quot; &lt;laserma....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; LauLuna wrote:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt;For any Turing machine there is an equivalent axiomatic system;
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt;whether we could construct it or not, is of no significance here.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; But for a simulation of a mathematician's brain, the axioms wouldn't
</em><br />
<em class="quotelev2">&gt; &gt;be
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; statements about arithmetic which we could inspect and judge whether
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;they
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; were true or false individually, they'd just be statements about the
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;initial
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; state and behavior of the simulated brain. So again, there'd be no
</em><br />
<em class="quotelev2">&gt; &gt;way
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;to
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; inspect the system and feel perfectly confident the system would
</em><br />
<em class="quotelev2">&gt; &gt;never
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; output a false statement about arithmetic, unlike in the case of the
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; axiomatic systems used by mathematicians to prove theorems.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;Yes, but this is not the point. For any Turing machine performing
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;mathematical skills there is also an equivalent mathematical axiomatic
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;system; if we are sound Turing machines, then we could never know that
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;mathematical system sound, in spite that its axioms are the same we
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;use.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I agree, a simulation of a mathematician's brain (or of a giant
</em><br />
<em class="quotelev2">&gt; &gt;simulated
</em><br />
<em class="quotelev3">&gt; &gt; &gt; community of mathematicians) cannot be a *knowably* sound system,
</em><br />
<em class="quotelev2">&gt; &gt;because we
</em><br />
<em class="quotelev3">&gt; &gt; &gt; can't do the trick of examining each axiom and seeing they are
</em><br />
<em class="quotelev2">&gt; &gt;individually
</em><br />
<em class="quotelev3">&gt; &gt; &gt; correct statements about arithmetic as with the normal axiomatic systems
</em><br />
<em class="quotelev3">&gt; &gt; &gt; used by mathematicians. But that doesn't mean it's unsound either--it
</em><br />
<em class="quotelev2">&gt; &gt;may in
</em><br />
<em class="quotelev3">&gt; &gt; &gt; fact never produce a false statement about arithmetic, it's just that we
</em><br />
<em class="quotelev3">&gt; &gt; &gt; can't be sure in advance, the only way to find out is to run it forever
</em><br />
<em class="quotelev2">&gt; &gt;and
</em><br />
<em class="quotelev3">&gt; &gt; &gt; check.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;Yes, but how can there be a logical impossibility for us to
</em><br />
<em class="quotelev2">&gt; &gt;acknowledge as sound the same principles and rules we are using?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The axioms in a simulation of a brain would have nothing to do with the
</em><br />
<em class="quotelev1">&gt; high-level conceptual &quot;principles and rules&quot; we use when thinking about
</em><br />
<em class="quotelev1">&gt; mathematics, they would be axioms concerning the most basic physical laws
</em><br />
<em class="quotelev1">&gt; and microscopic initial conditions of the simulated brain and its simulated
</em><br />
<em class="quotelev1">&gt; environment, like the details of which brain cells are connected by which
</em><br />
<em class="quotelev1">&gt; synapses or how one cell will respond to a particular electrochemical signal
</em><br />
<em class="quotelev1">&gt; from another cell. Just because I think my high-level reasoning is quite
</em><br />
<em class="quotelev1">&gt; reliable in general, that's no reason for me to believe a detailed
</em><br />
<em class="quotelev1">&gt; simulation of my brain would be &quot;sound&quot; in the sense that I'm 100% certain
</em><br />
<em class="quotelev1">&gt; that this precise arrangement of nerve cells in this particular simulated
</em><br />
<em class="quotelev1">&gt; environment, when allowed to evolve indefinitely according to some
</em><br />
<em class="quotelev1">&gt; well-defined deterministic rules, would *never* make a mistake in reasoning
</em><br />
<em class="quotelev1">&gt; and output an incorrect statement about arithmetic (or even that it would
</em><br />
<em class="quotelev1">&gt; never choose to intentionally output a statement it believed to be false
</em><br />
<em class="quotelev1">&gt; just to be contrary).
</em><br />
<br />But again, for any set of such 'physiological' axioms there is a
<br />
corresponding equivalent set of 'conceptual' axioms. There is all the
<br />
same a logical impossibility for us to know the second set is sound.
<br />
No consistent (and strong enough) system S can prove the soundness of
<br />
any system S' equivalent to S: otherwise S' would prove its own
<br />
soundness and would be inconsistent.  And this is just what is odd.
<br />
<br /><em class="quotelev3">&gt; &gt; &gt; But Penrose was not just arguing that human mathematical ability can't
</em><br />
<em class="quotelev2">&gt; &gt;be
</em><br />
<em class="quotelev3">&gt; &gt; &gt; based on a knowably sound algorithm, he was arguing that it must be
</em><br />
<em class="quotelev3">&gt; &gt; &gt; *non-algorithmic*.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;No, he argues in Shadows of the Mind exactly what I say. He goes on
</em><br />
<em class="quotelev2">&gt; &gt;arguing why a sound algorithm representing human intelligence is
</em><br />
<em class="quotelev2">&gt; &gt;unlikely to be not knowably sound.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; He does argue that as a first step, but then he goes on to conclude what I
</em><br />
<em class="quotelev1">&gt; said he did, that human intelligence cannot be algorithmic. For example, on
</em><br />
<em class="quotelev1">&gt; p. 40 he makes quite clear that his arguments throughout the rest of the
</em><br />
<em class="quotelev1">&gt; book are intended to show that there must be something non-computational in
</em><br />
<em class="quotelev1">&gt; human mental processes:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; &quot;I shall primarily be concerned, in Part I of this book, with the issue of
</em><br />
<em class="quotelev1">&gt; what it is possible to achieve by use of the mental quality of
</em><br />
<em class="quotelev1">&gt; 'understanding.' Though I do not attempt to define what this word means, I
</em><br />
<em class="quotelev1">&gt; hope that its meaning will indeed be clear enough that the reader will be
</em><br />
<em class="quotelev1">&gt; persuaded that this quality--whatever it is--must indeed be an essentail
</em><br />
<em class="quotelev1">&gt; part of that mental activity needed for an acceptance of the arguments of
</em><br />
<em class="quotelev1">&gt; 2.5. I propose to show that the appresiation of these arguments must involve
</em><br />
<em class="quotelev1">&gt; something non-computational.&quot;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Later, on p. 54:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; &quot;Why do I claim that this 'awareness', whatever it is, must be something
</em><br />
<em class="quotelev1">&gt; non-computational, so that no robot, controlled by a computer, based merely
</em><br />
<em class="quotelev1">&gt; on the standard logical ideas of a Turing machine (or equivalent)--whether
</em><br />
<em class="quotelev1">&gt; top-down or bottom-up--can achieve or even simulate it? It is here that the
</em><br />
<em class="quotelev1">&gt; Godelian argument plays its crucial role.&quot;
</em><br />
<br />Yes, he ultimately argues for that.
<br />
<br /><em class="quotelev1">&gt; His whole Godelian argument is based on the idea that for any computational
</em><br />
<em class="quotelev1">&gt; theorem-proving machine, by examining its construction we can use this
</em><br />
<em class="quotelev1">&gt; &quot;understanding&quot; to find a mathematical statement which *we* know must be
</em><br />
<em class="quotelev1">&gt; true, but which the machine can never output--that we understand something
</em><br />
<em class="quotelev1">&gt; it doesn't.
</em><br />
<br />I'd say this is rather Lucas's argument. Penrose's is like this:
<br />
<br />1. Mathematicians are not using a knowably sound algorithm to do math.
<br />
2. If they were using any algorithm whatsoever, they would be using a
<br />
knowably sound one.
<br />
3. Ergo, they are not using any algorithm at all.
<br />
<br /><br /><em class="quotelev1">&gt;But I think my argument shows that if you were really to build a
</em><br />
<em class="quotelev1">&gt; simulated mathematician or community of mathematicians in a computer, the
</em><br />
<em class="quotelev1">&gt; Godel statement for this system would only be true *if* they never made a
</em><br />
<em class="quotelev1">&gt; mistake in reasoning or chose to output a false statement to be perverse,
</em><br />
<em class="quotelev1">&gt; and that therefore there is no way for us on the outside to have any more
</em><br />
<em class="quotelev1">&gt; confidence about whether they will ever output this statement than they do
</em><br />
<em class="quotelev1">&gt; (and thus neither of us can know whether the statement is actually a true or
</em><br />
<em class="quotelev1">&gt; false theorem of arithmetic).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It's true that on p. 76, Penrose does restrict his conclusions about &quot;The
</em><br />
<em class="quotelev1">&gt; Godelian Case&quot; to the following statement (which he denotes 'G'):
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; &quot;Human mathematicians are not using a knowably sound algorithm in order to
</em><br />
<em class="quotelev1">&gt; ascertain mathematical truth.&quot;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I have no objection to this proposition on its own, but then in Chapter 3,
</em><br />
<em class="quotelev1">&gt; &quot;The case for non-computability in mathematical thought&quot; he does go on to
</em><br />
<em class="quotelev1">&gt; argue (as the chapter title suggest) that this proposition G justifies the
</em><br />
<em class="quotelev1">&gt; claim that human reasoning must be non-computable. In discussing objections
</em><br />
<em class="quotelev1">&gt; to this argument, he dismisses the possibility that G might be correct but
</em><br />
<em class="quotelev1">&gt; that humans are using an unknowable algorithm, or an unsound algorithm, but
</em><br />
<em class="quotelev1">&gt; as far as I can see he never discusses the possibility I have been
</em><br />
<em class="quotelev1">&gt; suggesting, that an algorithm that faithfully simulated the reasoning of a
</em><br />
<em class="quotelev1">&gt; human mathematician (or community of mathematicians) might be both knowable
</em><br />
<em class="quotelev1">&gt; (in the sense that the beings in the simulation are free to examine their
</em><br />
<em class="quotelev1">&gt; own algorithm) and sound (meaning that if the simulation is run forever,
</em><br />
<em class="quotelev1">&gt; they never output a false statement about arithmetic), but just not knowably
</em><br />
<em class="quotelev1">&gt; sound (meaning that neither they nor us can find a *proof* that will tell us
</em><br />
<em class="quotelev1">&gt; in advance that the simulation will never output a false statement, the only
</em><br />
<em class="quotelev1">&gt; way to check is to run it forever and see).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;And the impossibility has to be a logical impossibility, not merely a
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;technical or physical one since it depends on Gödel's theorem. That's
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;a bit odd, isn't it?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; No, I don't see anything very odd about the idea that human mathematical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; abilities can't be a knowably sound algorithm--it is no more odd than
</em><br />
<em class="quotelev2">&gt; &gt;the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; idea that there are some cellular automata where there is no shortcut to
</em><br />
<em class="quotelev3">&gt; &gt; &gt; knowing whether they'll reach a certain state or not other than actually
</em><br />
<em class="quotelev3">&gt; &gt; &gt; simulating them, as Wolfram suggests in &quot;A New Kind of Science&quot;.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;The point is that the axioms are exactly our axioms!
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Again, the &quot;axioms&quot; would be detailed statements about the initial
</em><br />
<em class="quotelev1">&gt; conditions and behavior of the most basic elements of the simulation--the
</em><br />
<em class="quotelev1">&gt; initial position and velocity of each simulated molecule along with rules
</em><br />
<em class="quotelev1">&gt; for the molecules' behavior, perhaps--not the sort of high-level conceptual
</em><br />
<em class="quotelev1">&gt; axioms we use in our minds when thinking about mathematics. If we can't even
</em><br />
<em class="quotelev1">&gt; predict whether some very simple cellular automata will ever reach a given
</em><br />
<em class="quotelev1">&gt; state, I don't see why it should be surprising that we can't predict whether
</em><br />
<em class="quotelev1">&gt; some very complex physical simulation of an immortal brain and its
</em><br />
<em class="quotelev1">&gt; environment will ever reach a given state (the state in which it decides to
</em><br />
<em class="quotelev1">&gt; output the system's Godel statement, whether because of incorrect reasoning
</em><br />
<em class="quotelev1">&gt; or just out of contrariness).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;In fact I'd
</em><br />
<em class="quotelev3">&gt; &gt; &gt; say it fits nicely with our feeling of &quot;free will&quot;, that there should be
</em><br />
<em class="quotelev2">&gt; &gt;no
</em><br />
<em class="quotelev3">&gt; &gt; &gt; way to be sure in advance that we won't break some rules we have been
</em><br />
<em class="quotelev2">&gt; &gt;told
</em><br />
<em class="quotelev3">&gt; &gt; &gt; to obey, apart from actually &quot;running&quot; us and seeing what we actually
</em><br />
<em class="quotelev2">&gt; &gt;end up
</em><br />
<em class="quotelev3">&gt; &gt; &gt; doing.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;I don't see how to reconcile free will with computationalism either.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I am only talking about the feeling of free will which is perfectly
</em><br />
<em class="quotelev1">&gt; compatible with ultimate determinism (see<a href="http://en.wikipedia.org/wiki/Compatibilism">http://en.wikipedia.org/wiki/Compatibilism</a>), not the philosophical idea of
</em><br />
<em class="quotelev1">&gt; &quot;libertarian free will&quot; (see<a href="http://en.wikipedia.org/wiki/Libertarianism_(metaphysics">http://en.wikipedia.org/wiki/Libertarianism_(metaphysics</a>) ) which requires
</em><br />
<em class="quotelev1">&gt; determinism to be false. If we had some unerring procedure for predicting
</em><br />
<em class="quotelev1">&gt; whether other people or even ourselves would make a certain decision in the
</em><br />
<em class="quotelev1">&gt; future, it's hard to see how we could still have the same subjective sense
</em><br />
<em class="quotelev1">&gt; of making choices whose outcomes aren't certain until we actually make them.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Jesse
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; _________________________________________________________________<a href="http://im.live.com/messenger/im/home/?source=hmtextlinkjuly07">http://im.live.com/messenger/im/home/?source=hmtextlinkjuly07</a>- Hide quoted text -
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; - Show quoted text -
</em><br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Fri Jul 06 2007 - 08:54:24 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13713">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13714.html" title="Next message in the list">LauLuna: "Re: Penrose and algorithms"</a></li>
<li><dfn>Previous message</dfn>: <a href="13712.html" title="Previous message in the list">Jason: "Re: Penrose and algorithms"</a></li>
<li><dfn>In reply to</dfn>: <a href="13710.html" title="Message to which this message replies">Jesse Mazer: "Re: Penrose and algorithms"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13721.html" title="Next message in this discussion thread">Bruno Marchal: "Re: Penrose and algorithms"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="13721.html" title="Message sent in reply to this message">Bruno Marchal: "Re: Penrose and algorithms"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13713" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13713" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13713" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13713" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
