<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Fwd: Implementation/Relativity from Christopher Maloney on 1999-07-29 (everything)</title>
<meta name="Author" content="Christopher Maloney (dude.domain.name.hidden)" />
<meta name="Subject" content="Re: Fwd: Implementation/Relativity" />
<meta name="Date" content="1999-07-29" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Fwd: Implementation/Relativity</h1>
<!-- received="Thu Jul 29 05:26:10 1999" -->
<!-- isoreceived="19990729122610" -->
<!-- sent="Thu, 29 Jul 1999 08:15:41 -0400" -->
<!-- isosent="19990729121541" -->
<!-- name="Christopher Maloney" -->
<!-- email="dude.domain.name.hidden" -->
<!-- subject="Re: Fwd: Implementation/Relativity" -->
<!-- id="37A045EC.60AFD830.domain.name.hidden" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="379FC03F.CF9CE2CD.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start1047" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1048.html" accesskey="d" title="Hans Moravec: &quot;Re: Fwd: Implementation/Relativity&quot;">Next message</a> ]
[ <a href="1046.html" title="Higgo James: &quot;RE: Fwd: Implementation/Relativity&quot;">Previous message</a> ]
[ <a href="1037.html" title="Hans Moravec: &quot;Re: Fwd: Implementation/Relativity&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1038.html" accesskey="t" title="hal.domain.name.hidden: &quot;Re: Fwd: Implementation/Relativity&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1047" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1047" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1047" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1047" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Christopher Maloney &lt;<a href="mailto:dude.domain.name.hidden?Subject=Re%3A%20Fwd%3A%20Implementation%2FRelativity">dude.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu, 29 Jul 1999 08:15:41 -0400</span><br />
</address>
<br />
Hans Moravec wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Russell Standish &lt;R.Standish.domain.name.hidden&gt;:
</em><br />
<em class="quotelev2">&gt; &gt; I don't think we ever discussed the concept of attributing
</em><br />
<em class="quotelev2">&gt; &gt; consciousness to inanimate objects before Hans came along.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; But I think you DID agree to attribute consciousness to
</em><br />
<em class="quotelev1">&gt; purely abstract entities, notably mathematically defined
</em><br />
<em class="quotelev1">&gt; universes containing SASes.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I merely pointed out that it is possible, even natural
</em><br />
<em class="quotelev1">&gt; and common, to map such abstractions containing
</em><br />
<em class="quotelev1">&gt; self-aware systems onto many things we commonly encounter.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; This violates some reflexive assumptions you carry, many
</em><br />
<em class="quotelev1">&gt; instilled by a western education.
</em><br />
<em class="quotelev1">&gt; Those assumptions badly need to be violated.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; They may have been good during our recent naive materialist
</em><br />
<em class="quotelev1">&gt; phase of development, but that phase is ending.
</em><br />
<em class="quotelev1">&gt; This list's discussion topic is one symptom of that end, as
</em><br />
<em class="quotelev1">&gt; are looming questions about conscious machines.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Other traditions have no problem seeing minds in
</em><br />
<em class="quotelev1">&gt; inanimate objects, when such interpretation facilitates
</em><br />
<em class="quotelev1">&gt; interaction.  That acceptance has much to do with the
</em><br />
<em class="quotelev1">&gt; Japanese comfortable acceptance of robots.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Western stinginess in attributing minds, on the other
</em><br />
<em class="quotelev1">&gt; hand, is becoming a Luddite-rousing impediment to progress.
</em><br />
<br />I believe this is what's called &quot;idolatry&quot;.  To claim that this
<br />
is a new, exciting concept in science and/or philosophy is 
<br />
preposterous.  Also, the claim that somehow western philosophy
<br />
is less idolatrous, and therefore flawed, is utterly ludicrous.
<br />
<br />Hans, you should try to back up some of your claims a little,
<br />
instead of declaring them with certainty, and deriding us for
<br />
not seeing the obvious.  I don't like being called pedestrian.
<br />
And you're idea of attributing consciousness to a teddy bear
<br />
is not as novel as you'd like to think.  Of course I've 
<br />
considered that novels are &quot;windows&quot; into other universes, and
<br />
I'd be surprised if most of the members of this list hadn't,
<br />
also.
<br />
<br />But the problem, which makes such a point of view useless, was 
<br />
pointed out by Hal.  Fictional scenarios are lawless.  In our
<br />
world, we invariably see that some sort of order and persistence
<br />
manifests itself.  But in fiction, I, or any author, is free to
<br />
make up whatever he or she wants, almost without constraint.
<br />
<br /><br />Hans Moravec wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Christopher Maloney &lt;dude.domain.name.hidden&gt;:
</em><br />
<em class="quotelev2">&gt; &gt; I'm sure that there are ... universes in which a detective named
</em><br />
<em class="quotelev2">&gt; &gt; Sherlock Holmes actually exists, fitting all the right descriptions.
</em><br />
<em class="quotelev2">&gt; &gt; ... but they are not accessible by us.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The Connan-Doyle books are an access to such universes! Like a spycam
</em><br />
<em class="quotelev1">&gt; peeking into them.  Universes are, after all, abstractions, exactly as
</em><br />
<em class="quotelev1">&gt; are fictional scenarios. Simulations, whether in computers or authors'
</em><br />
<em class="quotelev1">&gt; and readers' imaginations, connect alternative worlds to us.
</em><br />
<br />I don't believe that universes are absolute abstractions.  I believe
<br />
in the &quot;all-universe hypothesis&quot;, but I also believe that it must
<br />
be possible to establish some kind of measure over the universes,
<br />
that gives rise to the physical laws we witness.  So, in some sense,
<br />
they are &quot;real&quot;.  If you disagree with this, kindly define what you
<br />
mean by &quot;abstractions&quot;.
<br />
<br />Also, I'm curious about how you react to Descartes &quot;I think, therefore
<br />
I am&quot;.  When you say that each of us is just an abstraction, what do
<br />
you mean?  I would agree with Descarte that my own existence is the
<br />
only thing I can be really sure of.  And dammit, I do seem to be 
<br />
trapped inside some sort of universe that I never made, and that obeys
<br />
physical laws.  How do you explain that?
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; I think, deep down, you harbor the conventional illusion that our
</em><br />
<em class="quotelev1">&gt; physical world is somehow more real than other possible worlds.  You
</em><br />
<em class="quotelev1">&gt; should try to liberate yourself from that notion.
</em><br />
<br />Please refrain from psycho-analyzing me.  I don't agree.  I *do* 
<br />
believe that there must be some sort of measure.  I would put it
<br />
either:
<br />
&nbsp;&nbsp;Sup-phys perspective:  some mathematical structures have a smaller
<br />
&nbsp;&nbsp;measure than others, and are thus less likely to be observed by
<br />
&nbsp;&nbsp;me (I'm less likely to find myself in those).
<br />
<br />&nbsp;&nbsp;Comp perspective:  Out of the entire ensemble of possible next
<br />
&nbsp;&nbsp;inputs to my computational structure(s) (plural because as Bruno
<br />
&nbsp;&nbsp;has pointed out, I cannot be sure of exactly which program I am)
<br />
&nbsp;&nbsp;there is a measure of likelihood, which makes certain sets of
<br />
&nbsp;&nbsp;inputs much more likely than others.
<br />
<br />I would never say &quot;more real&quot;.  I often say things like &quot;less 
<br />
likely&quot;.
<br />
&nbsp;
<br />
<em class="quotelev1">&gt; As an exercise to make Sherlock' reality more apparent, imagine the
</em><br />
<em class="quotelev1">&gt; following progression of alternate implementations:
</em><br />
<br />Okay.
<br />
&nbsp;
<br />
<em class="quotelev1">&gt; The adventures of Sherlock Holmes described in a book (as you read it,
</em><br />
<em class="quotelev1">&gt; a simulation of Sherlock's world is created in your head, but you
</em><br />
<em class="quotelev1">&gt; (mistakenly) discount that as not real)
</em><br />
<br />I never discounted the simulation of Sherlock's world in my head as
<br />
not real.  But I assume you'd agree that the simulation is of 
<br />
extremely low fidelity.  Now, if you work with simulators, you must
<br />
know that the lower the fidelity of the simulation, the less useful
<br />
it is (in general).
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; The same stories portrayed by Jeremy Brett and other actors.  There is
</em><br />
<em class="quotelev1">&gt; now a lot more specific detail, including visual.  Sherlock Holmes
</em><br />
<em class="quotelev1">&gt; really exists as an interpretation of the behavior of Jeremy Brett
</em><br />
<em class="quotelev1">&gt; (there is another interpretation in which Brett is an actor portraying
</em><br />
<em class="quotelev1">&gt; Holmes, but that is interesting mainly to acting students).
</em><br />
<br />Also extremely low fidelity.  
<br />
<br />At this point, Hans, I'd like to say 
<br />
that I am entirely with you in interpreting a simulation as reality
<br />
in many cases.  For example, in a weather simulator, if it's of 
<br />
high enough fidelity, I'd say that weather really is happening in
<br />
there.  But within any simulation, there is an imposition of new
<br />
physical laws.  Also, the structures therein have a certain specifiable
<br />
complexity and behavior.
<br />
<br />The simulation of a fictional character inside someone's head is a far
<br />
cry, I'd say, from another human being.  It's just not even remotely
<br />
similar.  It obeys different laws of emotion - which are probably some
<br />
sort of bastardized subset of the actor's.  It can't have any memories
<br />
that are not from the actor, etc.
<br />
<br />I just don't believe in magic.  As I said in my earlier post, I could
<br />
cut open a persons head, and see all kinds of gunk in there that I 
<br />
could use to explain that person's behavior.  But how would I explain
<br />
the behavior of a fictional character? 
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; The same stories embedded into interactive video game.  You can now
</em><br />
<em class="quotelev1">&gt; not only watch Sherlock, but interact and he will respond to you.
</em><br />
<em class="quotelev1">&gt; When game AI is sufficiently advanced, you can have long, insightful
</em><br />
<em class="quotelev1">&gt; conversations with him.
</em><br />
<br />Then, and only then, does he become an implementation of a conscious
<br />
structure.  When the computational structure is complex enough to 
<br />
pass a Turing test, then you have something.
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; The same AI programs that control the virtual characters installed in
</em><br />
<em class="quotelev1">&gt; full-size robot bodies.  Not only can you talk with him, you can run
</em><br />
<em class="quotelev1">&gt; with him across the moors, and when the story is over, take him out
</em><br />
<em class="quotelev1">&gt; and introduce him to your friends, as real a part of the particular
</em><br />
<em class="quotelev1">&gt; fantasy we call physical reality as you or I.
</em><br />
<br />I, for one, find your emphasis on robots somewhat pedestrian.  Why
<br />
should the AI need a body?
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; (I thought the Star Trek TNG explorations of these kind of ideas
</em><br />
<em class="quotelev1">&gt; via holodeck virtual reality was pretty good, and much better than
</em><br />
<em class="quotelev1">&gt; some of the pedestrian sentiments I've seen on this list recently.)
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; If our tools were sophisticated enough, we could figure out what
</em><br />
<em class="quotelev2">&gt; &gt; that creature was experiencing at that moment, independent of his or
</em><br />
<em class="quotelev2">&gt; &gt; her report.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; NO!  We may determine the full physical structure of an organism well
</em><br />
<em class="quotelev1">&gt; enough to simulate it faithfully as a purely physical object.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; However, any experiences we impute to it will remain a subjective
</em><br />
<em class="quotelev1">&gt; matter with different answers for different observers.  Some observers
</em><br />
<em class="quotelev1">&gt; will be content to say there are no experiences in any case, including
</em><br />
<em class="quotelev1">&gt; when they simulate you or me.
</em><br />
<br />And I would say that they are wrong.  But that would be a matter of
<br />
definition among those super-beings, and there would be no 
<br />
ambiguity.  It's not magic.  Sometimes it sounds as though you have
<br />
a weird dualist perspective.
<br />
<br />Let me say it again, there would be no ambiguity.  They would make 
<br />
the definitions, and then be able to discern and answer questions
<br />
with (supposedly) perfect detail about what it is like to be me.
<br />
Once they define &quot;subjective experience&quot;, they would be able to
<br />
tell what it was that I was subjectively experience at a given 
<br />
moment, with greater accuracy than I'd be able to report it.
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Physical measurements don't objectively reveal experiences, because
</em><br />
<em class="quotelev1">&gt; experiences are not physical properties.  Pain, pleasure, belief and
</em><br />
<em class="quotelev1">&gt; the other psychological components of consciousness are abstractions
</em><br />
<em class="quotelev1">&gt; that can be mapped onto physical structures, but not in a unique way.
</em><br />
<br />Then they become useless.  I would suggest that there are (or could
<br />
be) definitions of those concepts that could apply, perhaps statistically,
<br />
across a broad range of complex organisms (or computer programs).  The
<br />
ambiguity exists now because we can't grasp the entire structure.  We
<br />
know so little about the workings of the brain.
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; Some mappings are useful for particular purposes.  Psychological
</em><br />
<em class="quotelev1">&gt; mappings surely evolved so we could coordinate better in social
</em><br />
<em class="quotelev1">&gt; groups.  It helps me (read &quot;me&quot;) act effectively to classify your
</em><br />
<em class="quotelev1">&gt; state as hungry or sad or in pain, or liking or disliking me.
</em><br />
<br />This is correct.  But when we move into the realm of science, we
<br />
need to make our definitions precise.
<br />
&nbsp;
<br />
<em class="quotelev1">&gt; It also helps me plan my own activities to similarly classify my own
</em><br />
<em class="quotelev1">&gt; state, and a richer classification is possible because I have
</em><br />
<em class="quotelev1">&gt; privileged access to all sorts of internal variables like signals
</em><br />
<em class="quotelev1">&gt; from my peripheral and visceral nerves and brain systems, hormone
</em><br />
<em class="quotelev1">&gt; concentrations and so on.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The resulting abstract psychological self-interpretation (our internal
</em><br />
<em class="quotelev1">&gt; sense of consciousness) is so tightly integrated to our physical
</em><br />
<em class="quotelev1">&gt; functioning that it may seem absolute and inevitable, but it's not.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The standard self-interpretation is replaced by other interpretations,
</em><br />
<em class="quotelev1">&gt; for instance when we sleep, become unconscious, are hypnotized or
</em><br />
<em class="quotelev1">&gt; otherwise influenced by compelling suggestions or go into meditative
</em><br />
<em class="quotelev1">&gt; trances (even as we perform tasks excellently).  In many such cases
</em><br />
<em class="quotelev1">&gt; seemingly absolute sensations like intense pain simply vanish, no
</em><br />
<em class="quotelev1">&gt; longer part of our self-interpretation.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Multiple-personality syndrome also seems to be an example of a body
</em><br />
<em class="quotelev1">&gt; and brain interpreting itself differently at different times.
</em><br />
<br />I fail to see the point of any of these examples.  You started out
<br />
by saying &quot;the resulting ... self-interpretation ... may seem absolute
<br />
and inevitable, but it's not.&quot;  But you have only shown that the
<br />
self-interpretation is a function of physical and emotional state.
<br />
So, it's another set of variables, what's the problem?
<br />
&nbsp;
<br />
<em class="quotelev1">&gt; Western philosophy of mind, influenced by soulist religious ideas, has
</em><br />
<em class="quotelev1">&gt; hyperinflated the significance of our own mutable self-interpretations
</em><br />
<em class="quotelev1">&gt; into absolute immutable bedrocks of existence.  But that idea just
</em><br />
<em class="quotelev1">&gt; doesn't work, it only befuddles its holders.
</em><br />
<br />I don't know, I don't feel befuddled.  Are you saying I'm wrong,
<br />
that you somehow have access to my mental state, and my self-
<br />
interpretation is questionable?
<br />
<br /><br /><pre>
-- 
Chris Maloney
<a href="http://www.chrismaloney.com">http://www.chrismaloney.com</a>
&quot;Donuts are so sweet and tasty.&quot;
-- Homer Simpson
</pre>
<span id="received"><dfn>Received on</dfn> Thu Jul 29 1999 - 05:26:10 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start1047">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1048.html" title="Next message in the list">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Previous message</dfn>: <a href="1046.html" title="Previous message in the list">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>In reply to</dfn>: <a href="1037.html" title="Message to which this message replies">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1038.html" title="Next message in this discussion thread">hal.domain.name.hidden: "Re: Fwd: Implementation/Relativity"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1047" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1047" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1047" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1047" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
