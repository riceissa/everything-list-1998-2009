<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Implementation from Marchal on 1999-07-23 (everything)</title>
<meta name="Author" content="Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: Implementation" />
<meta name="Date" content="1999-07-23" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Implementation</h1>
<!-- received="Fri Jul 23 05:05:20 1999" -->
<!-- isoreceived="19990723120520" -->
<!-- sent="Fri Jul 23 05:05:20 1999" -->
<!-- isosent="19990723120520" -->
<!-- name="Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: Implementation" -->
<!-- id="199907231047.MAA01339.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="Implementation" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start987" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="0988.html" accesskey="d" title="Christopher Maloney: &quot;Re: Implementation&quot;">Next message</a> ]
[ <a href="0986.html" title="Christopher Maloney: &quot;Re: Implementation&quot;">Previous message</a> ]
[ <a href="0981.html" title="Christopher Maloney: &quot;Re: Implementation&quot;">Maybe in reply to</a> ]
<!-- unextthread="start" -->
[ <a href="0986.html" accesskey="t" title="Christopher Maloney: &quot;Re: Implementation&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg987" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg987" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg987" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg987" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20Implementation">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri Jul 23 05:05:20 1999</span><br />
</address>
<br />
Chris wrote:
<br />
<br /><em class="quotelev1">&gt;I've concluded that
</em><br />
<em class="quotelev1">&gt;Maudlin's proof of the incompatibility between physical supervenience
</em><br />
<em class="quotelev1">&gt;and a computational theory of consciousness, is without merit.
</em><br />
<br />Gosh ...
<br />
<br /><em class="quotelev1">&gt;Maudlin's main error is a subtle one, and the seeds for it can be
</em><br />
<em class="quotelev1">&gt;found in this introduction to the concept of physical supervenience,
</em><br />
<em class="quotelev1">&gt;on page 408:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;    Computational structure supervenes on physical structure, so
</em><br />
<em class="quotelev1">&gt;    physically identical brains are also computationally identical.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Indeed, he defines the _supervenience thesis_ thus:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;    Two physical systems engaged in precisely the same physical
</em><br />
<em class="quotelev1">&gt;    activity through a time will support the same modes of
</em><br />
<em class="quotelev1">&gt;    consciousness (if any) through that time.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;He doesn't provide any evidence to support this conjecture, he
</em><br />
<em class="quotelev1">&gt;assumes it as fairly obvious.  In the case of human brains, it is
</em><br />
<em class="quotelev1">&gt;fairly obvious, and probably true.  But in the case of his final
</em><br />
<em class="quotelev1">&gt;computational machine, Olympia, it is clearly false, as I will show.
</em><br />
<em class="quotelev1">&gt;As a summary: the great lengths that Maudlin goes to in contriving
</em><br />
<em class="quotelev1">&gt;Olympia are precisely those which invalidate the supervenience
</em><br />
<em class="quotelev1">&gt;thesis, as he has defined it.
</em><br />
<br />I'm not sure I understand you because it would mean that 
<br />
Maudlin'argumentation succeed.
<br />
<br /><em class="quotelev1">&gt;Maudlin elaborates on his definition, as Hal pointed out in his post:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;    If we introduce into the vicinity of the system an entirely inert
</em><br />
<em class="quotelev1">&gt;    object that has absolutely no causal or physical interaction with
</em><br />
<em class="quotelev1">&gt;    the system, then the same activity will still support the same
</em><br />
<em class="quotelev1">&gt;    mode of consciousness.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;But this is clearly incorrect, as a moment's reflection will verify.
</em><br />
<em class="quotelev1">&gt;Computation supervenes on physical processes precisely to the extent
</em><br />
<em class="quotelev1">&gt;that, to put it simply, the outputs depend on the inputs.  As Maudlin
</em><br />
<em class="quotelev1">&gt;(and everyone on this group) accepts, correct handling of some set
</em><br />
<em class="quotelev1">&gt;of counterfactuals are essential to be able to call an implementation
</em><br />
<em class="quotelev1">&gt;an instantiation of a computation (say _that_ three times fast!)  So
</em><br />
<em class="quotelev1">&gt;this definition of physical supervenience is where the error lies.
</em><br />
<br />OK. You just don't believe in the physical supervenience thesis.
<br />
That is great !
<br />
But you will be obliged to explain why you still believe that
<br />
consciousness supervenes on the brain's activity (don't you ?).
<br />
In fact you will have to solve Mallah's implementation problem.
<br />
This is still more clear when you add:
<br />
<br /><em class="quotelev1">&gt;In fact, &quot;objects that have absolutely no causal or physical
</em><br />
<em class="quotelev1">&gt;interaction&quot; could affect the ability of the mechanism to deal with
</em><br />
<em class="quotelev1">&gt;counterfactuals, and so they would change the nature of the
</em><br />
<em class="quotelev1">&gt;computational device.
</em><br />
<br />All right. This is coherent with your suspicion against sup-phys.
<br />
Like Jacques M Mallah (and also like anyone who agree with both sup-phys 
<br />
and comp, you make &quot;inactive physical piece&quot; having a role for 
<br />
consciousness. 
<br />
<br /><br /><em class="quotelev1">&gt;To put it simply, as Jacques Mallah has pointed out many times, you
</em><br />
<em class="quotelev1">&gt;must consider the entire physical system whenever you are talking
</em><br />
<em class="quotelev1">&gt;about exactly what computation is instantiated.  The parts of the
</em><br />
<em class="quotelev1">&gt;system that don't happen to interact with other parts during a
</em><br />
<em class="quotelev1">&gt;particular run are still part of the system, and thus still have an
</em><br />
<em class="quotelev1">&gt;affect on which program is actually being run.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;I enjoyed Maudlins discussion, on pages 413ff, of &quot;the ploy of funny
</em><br />
<em class="quotelev1">&gt;instantiation&quot;, and other arguments, including Searle's &quot;Chinese
</em><br />
<em class="quotelev1">&gt;Room&quot;.  I agree with his assessments of these arguments as basically
</em><br />
<em class="quotelev1">&gt;non-substantive.  So it's ironic (to me, anyway) that I've reached
</em><br />
<em class="quotelev1">&gt;the conclusion that his argument falls into exactly this same class.
</em><br />
<br />Like Jacques M Mallah. See my preeceeding &quot;re-implementation&quot; post
<br />
(responding to Jacques M Mallah) for my feeling about that.
<br />
<br />But do you realise, Chris, that, like Nathanael, you will make
<br />
Olympia a Zombie ! (I know you aversion of the concept). Just remember
<br />
that Olympia just talk and behave like us.
<br />
<br /><em class="quotelev1">&gt;In particular, he mentions, on p. 416, a trick that can be played
</em><br />
<em class="quotelev1">&gt;when discussing a proposed computational system:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;    Someone might suggest that no activity is needed.  Let a rock
</em><br />
<em class="quotelev1">&gt;    sitting on a table be the machine.  Now let Si be:  sitting on
</em><br />
<em class="quotelev1">&gt;    the table from 12:00 to 12:01.  Let Sj be:  sitting on the table
</em><br />
<em class="quotelev1">&gt;    from 12:01 to 12:02.  The machine will effect a transition
</em><br />
<em class="quotelev1">&gt;    between the two states without undergoing any physical change at
</em><br />
<em class="quotelev1">&gt;    all.  I shall take such tricks to be inadmissable.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;But the trick he makes in defining Olympia is of exactly this
</em><br />
<em class="quotelev1">&gt;variety!  It doesn't go quite as far, but it is the same in that it
</em><br />
<em class="quotelev1">&gt;encodes information about a _particular run of the device_ into the
</em><br />
<em class="quotelev1">&gt;definition, or structure, of the device itself.
</em><br />
<br />Any program which is able to remember its activity do something like
<br />
that. This is just memorising. Frankly I don't see the difference.
<br />
The rock has no counterfactual abilities. Olympia does.
<br />
The only bizare feature of Olympia is that the memories and the
<br />
counterfactual are implemented in a way to be inactive during a 
<br />
particular run. If that would affect consciousness, I would
<br />
prefer to abandon computationalism.
<br />
<br /><em class="quotelev1">&gt;It should be obvious how this trick is of the same sort as the rock
</em><br />
<em class="quotelev1">&gt;trick above.  In the original machine, the order of the troughs had a
</em><br />
<em class="quotelev1">&gt;particular significance.  He has then redefined the significance of
</em><br />
<em class="quotelev1">&gt;the order of the troughs, ad hoc, to have a new significance which
</em><br />
<em class="quotelev1">&gt;relates directly to information from the reference run of the device.
</em><br />
<br />Here I would agree for a purely formal reason, and I see it as a 
<br />
pedagogical weakness of Maudlin's presentation of his argument.
<br />
But it is not to difficult to eliminate this difficulty.
<br />
And, at least for me, the fact that counterfactual will be well managed is
<br />
enough. I don't believe in zombie ! 
<br />
<br /><em class="quotelev1">&gt;Then he makes &quot;Maudlin's move&quot;.  He contrives a mechanism such that
</em><br />
<em class="quotelev1">&gt;if any of the troughs are not in the initial states that they were in
</em><br />
<em class="quotelev1">&gt;at the begining of the reference run, then an external device will
</em><br />
<em class="quotelev1">&gt;intervene and cause the counterfactual to be correctly implemented.
</em><br />
<em class="quotelev1">&gt;At this point, then, we must say that the computation is
</em><br />
<em class="quotelev1">&gt;instantiated, and that Olympia is now conscious.  We must admit, he
</em><br />
<em class="quotelev1">&gt;argues, that she is conscious even though none of the counterfactuals
</em><br />
<em class="quotelev1">&gt;ever actually occurs.  Thus, in the previous example and in this,
</em><br />
<em class="quotelev1">&gt;there existed the identical physical activity, but in that case, the
</em><br />
<em class="quotelev1">&gt;mechanism was not conscious, and this case, it is.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;The hole in this argument is rather glaring:  as mentioned above,
</em><br />
<em class="quotelev1">&gt;whenever considering the physical instantiation of a computation, the
</em><br />
<em class="quotelev1">&gt;complete system must be taken into account, and translated as a whole
</em><br />
<em class="quotelev1">&gt;into the computer program which is being instantiated.  The presence
</em><br />
<em class="quotelev1">&gt;or absence of parts which happen to play no role in a particular run
</em><br />
<em class="quotelev1">&gt;of the program, nevertheless can, and obviously do, change the nature
</em><br />
<em class="quotelev1">&gt;of the program itself.  The error is in assuming that identical
</em><br />
<em class="quotelev1">&gt;physical activity necessarily means that the same computation is
</em><br />
<em class="quotelev1">&gt;instantiated.
</em><br />
<br /><br />It is not an error. It is a refutation of sup-phys. It seems you
<br />
don't believe in sup-phys at the start.
<br />
In case you still believe that consciousness supervenes on the activity
<br />
of a &quot;normal brain&quot; you should explain why ? 
<br />
You definitely should work with Jacques M Mallah on his implementation
<br />
problem.
<br />
<br /><em class="quotelev1">&gt;Other examples brought up during discussion on this list have the
</em><br />
<em class="quotelev1">&gt;same flaw.  For example, Bruno's brain that breaks, and gets fed by
</em><br />
<em class="quotelev1">&gt;cosmic rays during the down-time.  When he applied Maudlin's move in
</em><br />
<em class="quotelev1">&gt;this scenario, he once again assumed a device which had, already
</em><br />
<em class="quotelev1">&gt;encoded into it, significant information about a reference run.
</em><br />
<br />I totaly agree with this. It is coherent with my abandon of sup-phys.
<br />
Of ANY sup-phys ! (unlike you, it seems).
<br />
<br /><em class="quotelev1">&gt;The same argument also applies when Maudlin discusses his &quot;second
</em><br />
<em class="quotelev1">&gt;block&quot;, which causes the gears to jam if ever the counterfactual is
</em><br />
<em class="quotelev1">&gt;encountered.  Again, this changes the overall structure of the
</em><br />
<em class="quotelev1">&gt;device, and thus changes the program which is instantiated.
</em><br />
<br />But any physical instantiation of a conditional instruction like
<br />
<br />&nbsp;&nbsp;IF M = O THEN RUN &lt;this part of the device&gt;
<br />
&nbsp;&nbsp;ELSE do nothing
<br />
<br />do precisely this.
<br />
<br /><em class="quotelev1">&gt;My point is that it is meaningless to talk of whether any of these
</em><br />
<em class="quotelev1">&gt;instantiations is &quot;conscious&quot;.  As many have pointed out recently,
</em><br />
<em class="quotelev1">&gt;consciousness is a subjective phenomenon.  We can study it from the
</em><br />
<em class="quotelev1">&gt;outside, just like we can study a computer program, but the actual
</em><br />
<em class="quotelev1">&gt;conscious entity experiencing the experiences will not be sensitive
</em><br />
<em class="quotelev1">&gt;to whether the machine breaks.
</em><br />
<br />I clearly agree with you if you include the normal brain in 'these
<br />
instantiations'. That was the point to be prove.
<br />
If we keep &quot;comp&quot; we must abandon sup-phys. 
<br />
Even on 'normal brain activity'. Is that your move ? I am not sure.
<br />
<br /><br /><em class="quotelev1">&gt;And one final note, which I think is the most powerful argument yet:
</em><br />
<em class="quotelev1">&gt;to make this conjecture stand, you'd have to show that physical
</em><br />
<em class="quotelev1">&gt;processes are incapable of instantiating a computation, ever.  I
</em><br />
<em class="quotelev1">&gt;don't think Maudlin attempted this.  The reason is clear:  if you
</em><br />
<em class="quotelev1">&gt;agree that consciousness is computational, and you agree that
</em><br />
<em class="quotelev1">&gt;physical processes can instantiate computations, then it follows that
</em><br />
<em class="quotelev1">&gt;physical processes can instantiate consciousnesses.  I don't know how
</em><br />
<em class="quotelev1">&gt;Maudlin would address this.  Would he say that conscious computations
</em><br />
<em class="quotelev1">&gt;are of a high enough order of complexity that they fall apart?  Just
</em><br />
<em class="quotelev1">&gt;hand-waving about a whether a particular contrived instantiation is
</em><br />
<em class="quotelev1">&gt;conscious or not cannot lead you to any conclusions about the general
</em><br />
<em class="quotelev1">&gt;case.
</em><br />
<br />Maudlin abandon computationalism.
<br />
I abandon sup-phys and the wole idea that consciousness is emergent
<br />
or secondary with respect to physical laws.
<br />
And I show it is quite consistent that the physical laws emerges
<br />
from the possible (arithmetical) discourse of consistent machines
<br />
infering their own (relative) consistency.
<br />
The role of an 'apparent brain' is not the producing of consciousness.
<br />
The role of such a brain is only to make possible for a (conscious) 
<br />
computation to manifest itself relatively to his more probable (measure 1)
<br />
computational neighborhood.
<br />
Is that a too big leap ?
<br />
<br />I am still not sure you abandon sup-phys. You cannot abandon it for 
<br />
Olympia and not for the 'normal brain'. At least not without giving us a
<br />
&quot;physical&quot; definition of &quot;correct&quot; implementation (like JMM).
<br />
But the end of your post seems to me going in the direction of total
<br />
abandon of sup-phys.
<br />
<br />So, I ask you again, is Olympia a zombie ?
<br />
(From your conversation with Steve Price, I am aware of the
<br />
high provocation here !). I just try to have a better 
<br />
understanding of your post.
<br />
<br />Bruno
<br />
<span id="received"><dfn>Received on</dfn> Fri Jul 23 1999 - 05:05:20 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start987">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="0988.html" title="Next message in the list">Christopher Maloney: "Re: Implementation"</a></li>
<li><dfn>Previous message</dfn>: <a href="0986.html" title="Previous message in the list">Christopher Maloney: "Re: Implementation"</a></li>
<li><dfn>Maybe in reply to</dfn>: <a href="0981.html" title="Message to which this message replies">Christopher Maloney: "Re: Implementation"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="0986.html" title="Next message in this discussion thread">Christopher Maloney: "Re: Implementation"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="0986.html" title="Message sent in reply to this message">Christopher Maloney: "Re: Implementation"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg987" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg987" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg987" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg987" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
