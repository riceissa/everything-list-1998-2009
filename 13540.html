<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: How would a computer know if it were conscious? from Colin Hales on 2007-06-13 (everything)</title>
<meta name="Author" content="Colin Hales (c.hales.domain.name.hidden)" />
<meta name="Subject" content="Re: How would a computer know if it were conscious?" />
<meta name="Date" content="2007-06-13" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: How would a computer know if it were conscious?</h1>
<!-- received="Wed Jun 13 22:48:16 2007" -->
<!-- isoreceived="20070614054816" -->
<!-- sent="Thu, 14 Jun 2007 12:47:58 +1000 (EST)" -->
<!-- isosent="20070614024758" -->
<!-- name="Colin Hales" -->
<!-- email="c.hales.domain.name.hidden" -->
<!-- subject="Re: How would a computer know if it were conscious?" -->
<!-- id="62863.128.250.80.15.1181789278.squirrel.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13540" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13541.html" accesskey="d" title="Stathis Papaioannou: &quot;Re: How would a computer know if it were conscious?&quot;">Next message</a> ]
[ <a href="13539.html" title="Colin Hales: &quot;Re: How would a computer know if it were conscious?&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="13542.html" accesskey="t" title="Russell Standish: &quot;Re: How would a computer know if it were conscious?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13540" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13540" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13540" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13540" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Colin Hales &lt;<a href="mailto:c.hales.domain.name.hidden?Subject=Re%3A%20How%20would%20a%20computer%20know%20if%20it%20were%20conscious%3F">c.hales.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu, 14 Jun 2007 12:47:58 +1000 (EST)</span><br />
</address>
<br />
Hi,
<br />
<br /><em class="quotelev2">&gt;&gt; COLIN
</em><br />
<em class="quotelev2">&gt;&gt; I don't think we need a new word....I'll stick to the far less
</em><br />
ambiguous
<br />
<em class="quotelev2">&gt;&gt; term 'organisational complexity', I think. the word creativity is so
</em><br />
loaded that its use in general discourse is bound to be prone to
<br />
misconstrual, especially in any discussion which purports to be
<br />
assessing
<br />
<em class="quotelev2">&gt;&gt; the relationship between 'organisational complexity' and consciousness.
</em><br />
<br />RUSSEL
<br />
<em class="quotelev1">&gt; What sort of misconstruals do you mean? I'm interested...
</em><br />
<em class="quotelev1">&gt; 'organisational complexity' does not capture the concept I'm after.
</em><br />
<br />COLIN
<br />
1) Those associated with religious 'creation' myths - the creativity
<br />
ascribed to an omniscient/omnipotent entity.
<br />
2) The creativity ascribed to the act of procreation.
<br />
3) The pseudo-magical aspects of human creativity (the scientific ah-ha
<br />
moment and the artistic gestalt moment).
<br />
and pehaps...
<br />
4) Belief in 'magical emergence' .... qualitative novelty of a kind
<br />
utterly unrelated to the componentry.
<br />
<br />These are all slippery slopes leading from the usage of the word
<br />
'creativity' which could unexpectedly undermine the specificity of a
<br />
technical discourse aimed at a wider (multi-disciplinary) audience.
<br />
<br />Whatever word you dream up... let me know!
<br />
<br /><em class="quotelev2">&gt;&gt; COLIN
</em><br />
<em class="quotelev2">&gt;&gt; The question-begging loop at this epistemic boundary is a minefield.
</em><br />
[[engage tiptoe mode]]
<br />
<em class="quotelev2">&gt;&gt; I would say:
</em><br />
<em class="quotelev2">&gt;&gt; (1) The evolutionary algorithms are not 'doing science' on the natural
</em><br />
world. They are doing science on abstract entities whose relationship with
<br />
<em class="quotelev2">&gt;&gt; the natural world is only in the mind(consciousness) of their grounder
</em><br />
-
<br />
<em class="quotelev2">&gt;&gt; the human programmer. The science done by the artefact can be the
</em><br />
perfectly good science of abstractions, but simply wrong or irrelevant
<br />
insofar as it bears any ability to prescribe or verify
<br />
claims/propositions
<br />
<em class="quotelev2">&gt;&gt; about the natural world (about which it has no awareness whatever). The
</em><br />
usefulness of the outcome (patents) took human involvement. The
<br />
inventor
<br />
<em class="quotelev2">&gt;&gt; (software) doesn't even know it's in a universe, let alone that it
</em><br />
participated in an invention process.
<br />
<br />RUSSEL
<br />
<em class="quotelev1">&gt; This objection is easily countered in theory. Hook up your
</em><br />
<em class="quotelev1">&gt; evolutionary algorithm to a chemsitry workbench, and let it go with real
</em><br />
chemicals. Practically, its a bit more difficult of course, most likely
<br />
leading to the lab being destroyed in some explosion.
<br />
<br />COLIN
<br />
Lots o'fun! But it might actually create its own undoing in the words
<br />
'evolutionary algorithm'. The self-modification strategy was preprogrammed
<br />
by a human, along with the initial values. Then there is the matter of
<br />
interpresting measurements of the output of the chemistry set...
<br />
<br />The system (a) automatically prescibes certain trajectories and (b)
<br />
assumes that the theroem space natural world are the same space and
<br />
equivalently accessed. The assumption is that hooking up a chemistry set
<br />
replicates the 'wild-type' theorem prover that is the natural world. If
<br />
you could do that then you already know everything there is to know (about
<br />
the natural world) and there'd be no need do it in the first place. This
<br />
is the all-time ultimate question-begger...
<br />
<br /><em class="quotelev1">&gt; Theoretical scientists, do not have laboratories to interface to,
</em><br />
though, only online repositories of datasets and papers. A theoretical
<br />
algorithmic scientist is a more likely proposition.
<br />
<br />A belief that an algorithmic scientist is doing valid science on the
<br />
natural world (independent of any human) is problematic in that it assumes
<br />
that human cortical qualia play no part in the scientific process in the
<br />
face of easily available evidence to the contrary, and then doubly assumes
<br />
that the algorithmic scientist (with a novelty exploration -theorem
<br />
proving strategy-programmed by a human) somehow naturally replicates the
<br />
neglected functionality (role of cortical qualia).
<br />
<br /><em class="quotelev2">&gt;&gt; (2) &quot;Is this evolutionary algorithm conscious then?&quot;.
</em><br />
<em class="quotelev2">&gt;&gt; In the sense that we are conscious of the natural world around us? Most
</em><br />
definitely no. Nowhere in the computer are any processes that include all
<br />
<em class="quotelev2">&gt;&gt; aspects of the physics of human cortical matter.
</em><br />
<em class="quotelev1">&gt; ...
</em><br />
<em class="quotelev2">&gt;&gt; Based on this, of the 2 following positions, which is less vulnerable
</em><br />
to
<br />
<em class="quotelev2">&gt;&gt; critical attack?
</em><br />
<em class="quotelev2">&gt;&gt; A) Information processing (function) begets consciousness, regardless
</em><br />
of
<br />
<em class="quotelev2">&gt;&gt; the behaviour of the matter doing the information processing (form).
</em><br />
Computers process information. Therefore I believe the computer is conscious.
<br />
<em class="quotelev2">&gt;&gt; B) Human cortical qualia are a necessary condition for the scientific
</em><br />
behaviour and unless the complete suite of the physics involved in that
<br />
process is included in the computer, the computer is not conscious. Which
<br />
form of question-begging gets the most solid points as science?  (B)
<br />
<em class="quotelev2">&gt;&gt; of course. (B) is science and has an empirical future. Belief (A) is
</em><br />
religion, not science.
<br />
<em class="quotelev2">&gt;&gt; Bit of a no-brainer, eh?
</em><br />
<br /><br /><em class="quotelev1">&gt; I think you're showing clear signs of carbon-lifeform-ism here. Whilst I
</em><br />
can say fairly clearly that I believe my fellow humans are
<br />
<em class="quotelev1">&gt; conscious, and that I beleive John Koza's evolutionary programs
</em><br />
<em class="quotelev1">&gt; aren't, I do not have a clear-cut operational test of
</em><br />
<em class="quotelev1">&gt; consciousness. Its like the test for pornography - we know it when we
</em><br />
see it.
<br />
<br />This is touching the flame - right there - where i claim this is not the
<br />
case. Everything we are is mediated through cortical qualia. In the one
<br />
and only case - the act of doing science - this argument is not valid.
<br />
Science evidences qualia (it does not say what they are, merely that they
<br />
exist)
<br />
<br />This is the cultural blind we inhabit. Cortical qualia are all and ONLY
<br />
evidence of _everything_ and is subjectively delivered. We cannot have it
<br />
both ways. We cannot live and do science using it for all evidence and
<br />
then either (a) deny it or (b) claim it present in another person/artifact
<br />
with the same ability as we declare something pornography (an arbitrary
<br />
belief). Let the object itself demonstrate science. be scientific about
<br />
it. This is the only place any consistency can be invoked and the major
<br />
source of inconsistency in our own behaviour as scientists.
<br />
<br />Like I said earlier: everything is evidence of something and scientists
<br />
are no exception - they are evidence of something and that something is
<br />
cortical qualia.
<br />
<br />The scientific act and the existence of scientists is the slim crack in
<br />
the cultural blind through which we can end the chronic failure.
<br />
<br /><em class="quotelev1">&gt;It is therefore not at all clear to me that some n-th
</em><br />
generational
<br />
<em class="quotelev1">&gt; improvement on an evolutionary algorithm won't be considered conscious
</em><br />
at some time in the future. It is not at all clear which aspects of human
<br />
cortical systems are required for consciousness.
<br />
<br />You are not alone. This is an epidemic.
<br />
<br />My scientific claim is that the electromagnetic field structure literally
<br />
the third person view of qualia. This is not new. What is new is
<br />
understanding the kind of universe we inhabit in which that is necessarily
<br />
the case. It's right there, in the cells. Just ask the right question of
<br />
them. There's nothing else there but space (mostly), charge and mass - all
<br />
things delineated and described by consciousness as how they appear to it
<br />
- and all such descriptions are logically necessarily impotent in
<br />
prescribing why that very consciousness exists at all.
<br />
<br />Wigner got this in 1960something.... time to catch up.
<br />
<br />gotta go....
<br />
<br />cheers
<br />
colin hales
<br />
<br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Wed Jun 13 2007 - 22:48:16 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13540">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13541.html" title="Next message in the list">Stathis Papaioannou: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13539.html" title="Previous message in the list">Colin Hales: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13542.html" title="Next message in this discussion thread">Russell Standish: "Re: How would a computer know if it were conscious?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="13542.html" title="Message sent in reply to this message">Russell Standish: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Reply</dfn>: <a href="13548.html" title="Message sent in reply to this message">David Nyman: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13540" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13540" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13540" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13540" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
