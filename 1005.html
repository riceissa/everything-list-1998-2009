<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Implementation from Russell Standish on 1999-07-26 (everything)</title>
<meta name="Author" content="Russell Standish (R.Standish.domain.name.hidden)" />
<meta name="Subject" content="Re: Implementation" />
<meta name="Date" content="1999-07-26" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Implementation</h1>
<!-- received="Mon Jul 26 19:59:36 1999" -->
<!-- isoreceived="19990727025936" -->
<!-- sent="Tue, 27 Jul 1999 12:49:57 +1000 (EST)" -->
<!-- isosent="19990727024957" -->
<!-- name="Russell Standish" -->
<!-- email="R.Standish.domain.name.hidden" -->
<!-- subject="Re: Implementation" -->
<!-- id="199907270249.MAA10141.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="199907261627.JAA04259.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start1005" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1006.html" accesskey="d" title="Higgo James: &quot;differences with MWI&quot;">Next message</a> ]
[ <a href="1004.html" title="Jacques M Mallah: &quot;Re: Implementation&quot;">Previous message</a> ]
[ <a href="1000.html" title="hal.domain.name.hidden: &quot;Re: Implementation&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1001.html" accesskey="t" title="GSLevy.domain.name.hidden: &quot;Re: Implementation&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1005" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1005" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1005" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1005" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Russell Standish &lt;<a href="mailto:R.Standish.domain.name.hidden?Subject=Re%3A%20Implementation">R.Standish.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 27 Jul 1999 12:49:57 +1000 (EST)</span><br />
</address>
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Russell Standish, &lt;R.Standish.domain.name.hidden&gt;, writes, quoting hal:
</em><br />
<em class="quotelev3">&gt; &gt; &gt; If we agree with this argument, we can have both supervenience and
</em><br />
<em class="quotelev3">&gt; &gt; &gt; computationalism, it seems to me.  We agree that Maudlin's machine changes
</em><br />
<em class="quotelev3">&gt; &gt; &gt; the program which is instantiated, but we claim that the new program
</em><br />
<em class="quotelev3">&gt; &gt; &gt; is also conscious.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Hal
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Nice try, but I think a brain in a resting state listening to music is
</em><br />
<em class="quotelev2">&gt; &gt; so much more complex in its processing of &quot;counterfactuals&quot; than the
</em><br />
<em class="quotelev2">&gt; &gt; Olympia example. There must be a dividing line somewhere between the
</em><br />
<em class="quotelev2">&gt; &gt; two examples - where the nonconcious entity crosses a threshold to
</em><br />
<em class="quotelev2">&gt; &gt; conciousness.			
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; This is certainly possible, but the point is that my example shows
</em><br />
<em class="quotelev1">&gt; that the conclusion of Maudlin's paper is technically incorrect.  It is
</em><br />
<em class="quotelev1">&gt; possible to have both physical supervenience (where consciousness depends
</em><br />
<em class="quotelev1">&gt; on physical activity) and computationalistm (where consciousness depends
</em><br />
<em class="quotelev1">&gt; on instantiating one of a set of conscious programs).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; And further, I showed that it is plausible that for at least some cases,
</em><br />
<em class="quotelev1">&gt; pruning the counterfactual tree would not eliminate consciousness.
</em><br />
<em class="quotelev1">&gt; By that I mean, if you consider all possible inputs to the program as
</em><br />
<em class="quotelev1">&gt; producing a tree of possibilities (like the familiar many-worlds tree),
</em><br />
<em class="quotelev1">&gt; then when we eliminate some counterfactuals it is like pruning the tree
</em><br />
<em class="quotelev1">&gt; (eliminating some branches).  I argued that it seems unlikely that
</em><br />
<em class="quotelev1">&gt; literally any pruning of any remote part of the tree would eliminate
</em><br />
<em class="quotelev1">&gt; consciousness, hence it can tolerate some amount of pruning.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; As you say, it is possible that &quot;light pruning&quot; would leave consciousness
</em><br />
<em class="quotelev1">&gt; intact, while &quot;heavy pruning&quot; would eliminate it.  But why would
</em><br />
<em class="quotelev1">&gt; you say that?  What motivates your belief that heavy pruning of the
</em><br />
<em class="quotelev1">&gt; counterfactual tree eliminates consciousness?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Our reason for believing that was, I believe, based on an error in
</em><br />
<em class="quotelev1">&gt; understanding Maudlin's argument.  We agreed that the TM was conscious
</em><br />
<em class="quotelev1">&gt; in virtue of running its program.  When the change in counterfactual
</em><br />
<em class="quotelev1">&gt; circumstances made it so that it was no longer running *that* program,
</em><br />
<em class="quotelev1">&gt; we fell into the mistake of believing that made it no longer conscious.
</em><br />
<em class="quotelev1">&gt; What we forgot was that there is more than one program that can make
</em><br />
<em class="quotelev1">&gt; a computer conscious.  Showing that a superficial change makes it stop
</em><br />
<em class="quotelev1">&gt; running one specific program does not imply, as Maudlin suggests, that
</em><br />
<em class="quotelev1">&gt; the change also makes it stop being conscious.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; So it seems to me we need a new argument for why the computer sans
</em><br />
<em class="quotelev1">&gt; counterfactuals should not be considered conscious.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; You suggest that heavy but not light pruning eliminates consciousness,
</em><br />
<em class="quotelev1">&gt; but this faces the problem that Chalmers calls &quot;fading qualia&quot;.  It's one
</em><br />
<em class="quotelev1">&gt; thing to believe in zombies, beings which act conscious but are not,
</em><br />
<em class="quotelev1">&gt; as in a heavily pruned counterfactual tree.  But it's hard when we
</em><br />
<em class="quotelev1">&gt; have a continuous range of cases, from light to heavy pruning, with
</em><br />
<em class="quotelev1">&gt; consciousness at one end and zombiehood (or at least unconsciousness)
</em><br />
<em class="quotelev1">&gt; at the other.  What happens in the intermediate cases?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Either consciousness is lost gradually, with sensations becoming
</em><br />
<em class="quotelev1">&gt; less intense and fading away as we prune more deeply, or it is lost
</em><br />
<em class="quotelev1">&gt; suddenly, and we have a case where one additional &quot;snip&quot;, one additional
</em><br />
<em class="quotelev1">&gt; counterfactual possibility eliminated, eliminates consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The first seems impossible because people never comment on their loss
</em><br />
<em class="quotelev1">&gt; of consciousness.  We have to wonder what it would be like to be &quot;only
</em><br />
<em class="quotelev1">&gt; a little bit conscious&quot; but to continue to behave normally.  If it is
</em><br />
<em class="quotelev1">&gt; possible to be in that state, how would it differ subjectively from
</em><br />
<em class="quotelev1">&gt; our present state?  And why would be unable to comment on the effects?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The second seems unlikely, as one counterfactual possibility is much like
</em><br />
<em class="quotelev1">&gt; another, and with the tree so dense it is hard to imagine that pruning one
</em><br />
<em class="quotelev1">&gt; little possibility from the astronomically numerous branches could make
</em><br />
<em class="quotelev1">&gt; a difference.  Coming up with a theory of which programs are conscious
</em><br />
<em class="quotelev1">&gt; is going to be difficult, but creating one which has this behavior is
</em><br />
<em class="quotelev1">&gt; going to be nearly impossible, especially since there is no hint in
</em><br />
<em class="quotelev1">&gt; the behavior of the computer as to when its consciousness &quot;winks out&quot;.
</em><br />
<em class="quotelev1">&gt; Any theory of consciousness which assumes such phenomena had better have
</em><br />
<em class="quotelev1">&gt; a good reason for believing that pruning must eliminate consciousness
</em><br />
<em class="quotelev1">&gt; eventually, and I'd like to hear what such a reason might be.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Hal
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br />I do believe that light pruning will not affect conciousness, but that
<br />
heavy pruning will. The metaphor here is of a percolation threshold,
<br />
or &quot;when does a network become fully connected&quot;. If you take a densely
<br />
connected network, then removing links does not change the property
<br />
that the network is fully connected, until you remove a critical link
<br />
(&quot;the straw that broke the camel's back&quot;). One cannot say which link
<br />
is the critical link, indeed it will depend on the order in which you
<br />
remove links.  However when you remove all links from the network, the
<br />
network is obviously unconnected. 
<br />
<br />I believe there needs to be sufficient options and indeterminism for
<br />
free will to operate before a system can be considered concious. I
<br />
also believe that this indeterminsm must be supplied internally,
<br />
rather than externally, however, I'm not 100% convinced of this, and
<br />
could be persuaded otherwise.
<br />
<br />As you say, it is very difficult to measure the property of
<br />
conciousness. One can assume conciousness as a useful model of a
<br />
system, and propose a Turing test as a procedure to test how good this
<br />
model is. However, it is always possible to _artificially_ construct a
<br />
system to pass the Turing test that isn't concious. The probability of
<br />
such a system arising naturally, (by evolution say) however must be
<br />
minute.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Cheers
<br />
<br />----------------------------------------------------------------------------
<br />
Dr. Russell Standish            	Director
<br />
High Performance Computing Support Unit,
<br />
University of NSW			Phone 9385 6967
<br />
Sydney 2052				Fax   9385 6965
<br />
Australia                       	R.Standish.domain.name.hidden
<br />
Room 2075, Red Centre			<a href="http://parallel.hpc.unsw.edu.au/rks">http://parallel.hpc.unsw.edu.au/rks</a>
<br />
----------------------------------------------------------------------------
<br />
<span id="received"><dfn>Received on</dfn> Mon Jul 26 1999 - 19:59:36 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start1005">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1006.html" title="Next message in the list">Higgo James: "differences with MWI"</a></li>
<li><dfn>Previous message</dfn>: <a href="1004.html" title="Previous message in the list">Jacques M Mallah: "Re: Implementation"</a></li>
<li><dfn>In reply to</dfn>: <a href="1000.html" title="Message to which this message replies">hal.domain.name.hidden: "Re: Implementation"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1001.html" title="Next message in this discussion thread">GSLevy.domain.name.hidden: "Re: Implementation"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1005" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1005" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1005" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1005" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
