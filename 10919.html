<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: computationalism and supervenience from David Nyman on 2006-09-04 (everything)</title>
<meta name="Author" content="David Nyman (david.nyman.domain.name.hidden)" />
<meta name="Subject" content="Re: computationalism and supervenience" />
<meta name="Date" content="2006-09-04" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: computationalism and supervenience</h1>
<!-- received="Mon Sep  4 10:59:40 2006" -->
<!-- isoreceived="20060904175940" -->
<!-- sent="Mon, 04 Sep 2006 07:57:48 -0700" -->
<!-- isosent="20060904145748" -->
<!-- name="David Nyman" -->
<!-- email="david.nyman.domain.name.hidden" -->
<!-- subject="Re: computationalism and supervenience" -->
<!-- id="1157381868.116092.93910.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="40d50ff9dfa9ff5af987765f9a7f835a&#64;ulb.ac.be" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start10919" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="10920.html" accesskey="d" title="Hal Ruhl: &quot;My model simplified&quot;">Next message</a> ]
[ <a href="10918.html" title="1Z: &quot;Re: R&#0233;p: ROADMAP (well, not yet really...&quot;">Previous message</a> ]
[ <a href="10576.html" title="Stathis Papaioannou: &quot;computationalism and supervenience&quot;">Maybe in reply to</a> ]
<!-- unextthread="start" -->
[ <a href="10922.html" accesskey="t" title="1Z: &quot;Re: computationalism and supervenience&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10919" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10919" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10919" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10919" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: David Nyman &lt;<a href="mailto:david.nyman.domain.name.hidden?Subject=Re%3A%20computationalism%20and%20supervenience">david.nyman.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon, 04 Sep 2006 07:57:48 -0700</span><br />
</address>
<br />
Bruno Marchal wrote:
<br />
<br /><em class="quotelev1">&gt; Either those *specific* physical activities are turing emulable, and we
</em><br />
<em class="quotelev1">&gt; are back to &quot;1)&quot; and &quot;2)&quot;, or they are not, and then comp is false.
</em><br />
<em class="quotelev1">&gt; Recall we assume comp.
</em><br />
<br />I don't follow. I thought Maudlin is proposing a physical machine
<br />
running the consciousness program, not a turing-emulated one. Are you
<br />
saying that if we assume comp, the 'physical activity level' of a
<br />
correctly substituted emulation is posited as equivalent to that of a
<br />
'real' machine (i.e. there is in fact no meaningful distinction)? In
<br />
this case AFAICS the substitution level would need to be below that of
<br />
'registers' etc, which are insufficiently constrained aspects of
<br />
machine architecture.
<br />
<br /><em class="quotelev1">&gt; We would have zombie. Why not. Once comp is false ...
</em><br />
<br />Why talk of zombies? A zombie is a being that is supposedly conceivable
<br />
(though not to me) as being 'unconscious' despite apparently possessing
<br />
the structural/ behavioural prerequisites of consciousness. I was
<br />
referring to the issue that, if the characteristics of consciousness
<br />
are indeed correlated with specific physical activities, then aspects
<br />
of consciousness would necessarily *co-vary* with physical
<br />
instantiation. To avoid this, comp would need to adopt a substitution
<br />
level that preserved the invariance of whatever 'physical activities'
<br />
were deemed relevant to consciousness (as I suggest above).
<br />
<br /><em class="quotelev1">&gt; OK in this situation. But comp makes impossible to distinguish the
</em><br />
<em class="quotelev1">&gt; experience of driving a car, and the experience of driving a virtual
</em><br />
<em class="quotelev1">&gt; car in a virtual environment, done at the right level of substitution
</em><br />
<em class="quotelev1">&gt; (or below). Then the movie-graph or Maudlin's Olympia shows that
</em><br />
<em class="quotelev1">&gt; machines cannot even distinguish a physical virtual environment and a
</em><br />
<em class="quotelev1">&gt; purely arithmetical virtual environment.
</em><br />
<br />So this is all about the level of substitution. Well, as I've
<br />
suggested, I think the level would have to be at or below that at which
<br />
machine architecture differences become indistinguishable. So I don't
<br />
believe that arguments involving registers etc. can be correct, because
<br />
it becomes hard to argue coherently that the necessary invariances are
<br />
preserved at this level. We might debate atom-by-atom, or
<br />
circuit-by-circuit, or does the doctor have some more general principle
<br />
to resolve this?
<br />
<br />BTW I think I see now that most of our original disagreements were
<br />
language based. If comp is in essence an objective idealist model, in
<br />
effect it begins from the assumption that 'objective idealist reality'
<br />
exists 'in the sense that I exist' (although of course not constrained
<br />
solipsistically to my 1st-person pov). That is all I have ever sought
<br />
in terms of '1st-person primacy'.
<br />
<br />David
<br />
<br /><em class="quotelev1">&gt; Le 03-sept.-06, à 17:18, David Nyman a écrit :
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Bruno Marchal wrote:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Maudlin build first a digital machine, let us call it M, which do a
</em><br />
<em class="quotelev3">&gt; &gt;&gt; computation PI (Maudlin's name for it) which we suppose does
</em><br />
<em class="quotelev3">&gt; &gt;&gt; correspond
</em><br />
<em class="quotelev3">&gt; &gt;&gt; to a genuine consciousness experience (for example some remembering of
</em><br />
<em class="quotelev3">&gt; &gt;&gt; the taste of cocoa).
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; At this point we don't know whether the conscious experience is
</em><br />
<em class="quotelev2">&gt; &gt; supposed to:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 1) inhere in the computation independent of physical instantiation
</em><br />
<em class="quotelev2">&gt; &gt;  or
</em><br />
<em class="quotelev2">&gt; &gt; 2) inhere in some subset of the physical activity of the machine that
</em><br />
<em class="quotelev2">&gt; &gt; is supposed to be 'relevant' for the computation
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; It seems that what is intended under 2) must be *any* physical activity
</em><br />
<em class="quotelev2">&gt; &gt; that could be construed as 'implementing' this computation, since
</em><br />
<em class="quotelev2">&gt; &gt; syntactically equivalent hardwares aren't constrained to any particular
</em><br />
<em class="quotelev2">&gt; &gt; set of physical activities.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; All right.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Suppose that during the running of that particular computation PI, the
</em><br />
<em class="quotelev3">&gt; &gt;&gt; register r1, ...r67 are never used. Maudlin argue that if
</em><br />
<em class="quotelev3">&gt; &gt;&gt; consciousness
</em><br />
<em class="quotelev3">&gt; &gt;&gt; is attached to the physical activity relevant for the computation, we
</em><br />
<em class="quotelev3">&gt; &gt;&gt; can retrieve those unused part of the computer, without changing the
</em><br />
<em class="quotelev3">&gt; &gt;&gt; consciousness experience.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; OK, under either assumption 1) or 2) above.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; He shows then that he can managed to build a version of M,
</em><br />
<em class="quotelev3">&gt; &gt;&gt; proto-olympia (say) which has almost no physical activity at all when
</em><br />
<em class="quotelev3">&gt; &gt;&gt; he follows the PI computation.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; But this will only preserve the conscious experience under the prior
</em><br />
<em class="quotelev2">&gt; &gt; assumption of its invariance to physical activity.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Yes. OK.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; If this invariance
</em><br />
<em class="quotelev2">&gt; &gt; is false we have a third possibility:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 3) consciousness inheres in *specific* physical activities (and
</em><br />
<em class="quotelev2">&gt; &gt; consequently physically-instantiated comp is merely 'syntactic
</em><br />
<em class="quotelev2">&gt; &gt; simulation')
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Either those *specific* physical activities are turing emulable, and we
</em><br />
<em class="quotelev1">&gt; are back to &quot;1)&quot; and &quot;2)&quot;, or they are not, and then comp is false.
</em><br />
<em class="quotelev1">&gt; Recall we assume comp.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Under this assumption, changing the physical details of the
</em><br />
<em class="quotelev2">&gt; &gt; implementation might have any arbitrary effect whatsoever on the
</em><br />
<em class="quotelev2">&gt; &gt; original conscious experience.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Proto-olympia  is *physically* accidentally correct for PI, but no
</em><br />
<em class="quotelev3">&gt; &gt;&gt; more
</em><br />
<em class="quotelev3">&gt; &gt;&gt; counterfactually correct.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; We don't know what effect the lack of counterfactuality would have on
</em><br />
<em class="quotelev2">&gt; &gt; the conscious experience. None, if 3) is correct.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; All right (but comp need to be false).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Then Maudlin reintroduces the unused parts, the Klaras, which
</em><br />
<em class="quotelev3">&gt; &gt;&gt; reintroduces the counterfactual correctness, WITHOUT ADDING any comp
</em><br />
<em class="quotelev3">&gt; &gt;&gt; relevant physical activity (if not, it would mean the level is
</em><br />
<em class="quotelev3">&gt; &gt;&gt; incorrect(*)).
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Again, under 3) this wouldn't affect the conscious experience if the
</em><br />
<em class="quotelev2">&gt; &gt; relevant physical invariance is preserved.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; So comp + physical supervenience (phys-sup) would force
</em><br />
<em class="quotelev3">&gt; &gt;&gt; us to associate any consciousness experience to any physical
</em><br />
<em class="quotelev3">&gt; &gt;&gt; processes.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Under 3) it would force us to associate specific conscious experiences
</em><br />
<em class="quotelev2">&gt; &gt; to specific physical processes, at the correct (physical) substitution
</em><br />
<em class="quotelev2">&gt; &gt; level.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; And that would kill comp! So sup-phys -&gt; NOT comp, or equivalently
</em><br />
<em class="quotelev3">&gt; &gt;&gt; comp
</em><br />
<em class="quotelev3">&gt; &gt;&gt; -&gt; NOT sup-phys.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Under 3) it would kill comp as a theory of the invariance of
</em><br />
<em class="quotelev2">&gt; &gt; consciousness to physical activity.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Sure.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; It would be possible for a physical
</em><br />
<em class="quotelev2">&gt; &gt; process that was conscious to be turing-emulable, but for the conscious
</em><br />
<em class="quotelev2">&gt; &gt; experience to be non-invariant to different instantiations of such
</em><br />
<em class="quotelev2">&gt; &gt; emulation.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; We would have zombie. Why not. Once comp is false ...
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; This would follow from the inherence of consciousness in
</em><br />
<em class="quotelev2">&gt; &gt; *specific* physical activities. I'm speaking here of comp as
</em><br />
<em class="quotelev2">&gt; &gt; instantiated in a *physical* machine, and consequently this is no
</em><br />
<em class="quotelev2">&gt; &gt; different to the claim that you can't drive a comp-emulated car down to
</em><br />
<em class="quotelev2">&gt; &gt; the shops (at least not the ones *outside* of the machine). The car you
</em><br />
<em class="quotelev2">&gt; &gt; need for your trip is non-invariant to turing-emulation.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; This is essentially the point I attempted to establish in my original
</em><br />
<em class="quotelev2">&gt; &gt; 'anti-roadmap' post. Assumption 3 claims that 'conscious' activity must
</em><br />
<em class="quotelev2">&gt; &gt; inhere in specific causal sequences seamlessly spanning the machine and
</em><br />
<em class="quotelev2">&gt; &gt; the world outside it. Without this, it is difficult to see how
</em><br />
<em class="quotelev2">&gt; &gt; 'consciousness' could be causally relevant to the intentional
</em><br />
<em class="quotelev2">&gt; &gt; interaction of the machine with its environment.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; As conscious machines ourselves we understand very well the difference
</em><br />
<em class="quotelev2">&gt; &gt; between the car we dream of (the 'emulated' Ferrari) and the one we
</em><br />
<em class="quotelev2">&gt; &gt; actually drive (the VW we causally interact with).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; OK in this situation. But comp makes impossible to distinguish the
</em><br />
<em class="quotelev1">&gt; experience of driving a car, and the experience of driving a virtual
</em><br />
<em class="quotelev1">&gt; car in a virtual environment, done at the right level of substitution
</em><br />
<em class="quotelev1">&gt; (or below). Then the movie-graph or Maudlin's Olympia shows that
</em><br />
<em class="quotelev1">&gt; machines cannot even distinguish a physical virtual environment and a
</em><br />
<em class="quotelev1">&gt; purely arithmetical virtual environment.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Bruno
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; <a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
</em><br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Mon Sep 04 2006 - 10:59:40 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start10919">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="10920.html" title="Next message in the list">Hal Ruhl: "My model simplified"</a></li>
<li><dfn>Previous message</dfn>: <a href="10918.html" title="Previous message in the list">1Z: "Re: R&#0233;p: ROADMAP (well, not yet really..."</a></li>
<li><dfn>Maybe in reply to</dfn>: <a href="10576.html" title="Message to which this message replies">Stathis Papaioannou: "computationalism and supervenience"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="10922.html" title="Next message in this discussion thread">1Z: "Re: computationalism and supervenience"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="10922.html" title="Message sent in reply to this message">1Z: "Re: computationalism and supervenience"</a></li>
<li><dfn>Reply</dfn>: <a href="10950.html" title="Message sent in reply to this message">Bruno Marchal: "Re: computationalism and supervenience"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10919" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10919" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10919" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10919" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
