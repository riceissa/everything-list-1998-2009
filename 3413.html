<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Predictions &amp; duplications from Russell Standish on 2001-10-29 (everything)</title>
<meta name="Author" content="Russell Standish (R.Standish.domain.name.hidden)" />
<meta name="Subject" content="Re: Predictions &amp; duplications" />
<meta name="Date" content="2001-10-29" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Predictions &amp; duplications</h1>
<!-- received="Mon Oct 29 15:24:42 2001" -->
<!-- isoreceived="20011029232442" -->
<!-- sent="Tue, 30 Oct 2001 10:06:08 +1100 (EST)" -->
<!-- isosent="20011029230608" -->
<!-- name="Russell Standish" -->
<!-- email="R.Standish.domain.name.hidden" -->
<!-- subject="Re: Predictions &amp; duplications" -->
<!-- id="200110292306.f9TN69Y07639.domain.name.hidden" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="3BDD46FC.A2FE9793.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start3413" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="3414.html" accesskey="d" title="Marchal: &quot;Re: Predictions &#0038; duplications&quot;">Next message</a> ]
[ <a href="3412.html" title="Juergen Schmidhuber: &quot;Re: Predictions &#0038; duplications&quot;">Previous message</a> ]
[ <a href="3412.html" title="Juergen Schmidhuber: &quot;Re: Predictions &#0038; duplications&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="3349.html" accesskey="t" title="juergen.domain.name.hidden: &quot;Re: Predictions &#0038; duplications&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg3413" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg3413" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg3413" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg3413" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Russell Standish &lt;<a href="mailto:R.Standish.domain.name.hidden?Subject=Re%3A%20Predictions%20%26%20duplications">R.Standish.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 30 Oct 2001 10:06:08 +1100 (EST)</span><br />
</address>
<br />
Juergen Schmidhuber wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; From: Russell Standish &lt;R.Standish.domain.name.hidden&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; The only reason for not accepting the simplest thing is if it can be
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; shown to be logically inconsistent. This far, you have shown no such
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; thing, but rather demonstrated an enormous confusion between measure
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; and probability distribution.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Russell, this is really too much; please read any intro to measure
</em><br />
<em class="quotelev3">&gt; &gt; &gt; theory,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; e.g., the one by Halmos.  Measures in general are _not_ probability
</em><br />
<em class="quotelev3">&gt; &gt; &gt; distributions.  They are more than that; you can view them as _sets_ of
</em><br />
<em class="quotelev3">&gt; &gt; &gt; probability distributions on sets that are related to each other in a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; specific way. Probability density functions define measures and
</em><br />
<em class="quotelev3">&gt; &gt; &gt; therefore
</em><br />
<em class="quotelev3">&gt; &gt; &gt; in general aren't probability distributions either. The uniform PDF on
</em><br />
<em class="quotelev3">&gt; &gt; &gt; [0..1] yields the perfect trivial example; that's exactly why I used it
</em><br />
<em class="quotelev3">&gt; &gt; &gt; before.  In the computability context, compare LI/Vitanyi 1997, chapters
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 4.3 (discrete sample space with (semi)distribution m(x)) vs chapter 4.5
</em><br />
<em class="quotelev3">&gt; &gt; &gt; (continuous sample space with (semi)measure M(x)).
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; This is an excellent reference, thank you. Example 4.2.1 gives the
</em><br />
<em class="quotelev2">&gt; &gt; construction of the uniform measure over the set of strings, precisely
</em><br />
<em class="quotelev2">&gt; &gt; what you claim didn't exist when we started this discussion.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; You just want to annoy me, don't you?  For the last time: There is a
</em><br />
<em class="quotelev1">&gt; uniform *measure* on the strings, but no uniform probability
</em><br />
<em class="quotelev1">&gt; distribution.
</em><br />
<br />Who is annoying who? I never claimed a uniform probability density (I
<br />
actually looked up the difference between probability density and
<br />
probability distribution yesterday in Li and Vitanyi) - only a uniform
<br />
measure. In fact, my first comment to you was &quot;Why do you insist on it
<br />
being a PDF?&quot;. Remember?
<br />
<br />The simplest prior is the uniform measure on infinite strings. 
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; 1) Halting theorem implies the set of halting programs is of measure
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; zero within the set of all programs
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; You mean, given a uniform measure? But why should you need the halting
</em><br />
<em class="quotelev3">&gt; &gt; &gt; theorem for this trivial statement?  In fact, what exactly do you mean
</em><br />
<em class="quotelev3">&gt; &gt; &gt; by
</em><br />
<em class="quotelev3">&gt; &gt; &gt; halting theorem?  (Schoenfield's book provides a good intro to
</em><br />
<em class="quotelev3">&gt; &gt; &gt; mathematical
</em><br />
<em class="quotelev3">&gt; &gt; &gt; logic and computability theory.)
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; The halting theorem is that there is no algorithm for predicting
</em><br />
<em class="quotelev2">&gt; &gt; whether any program will halt. Of course, the result I was referring
</em><br />
<em class="quotelev2">&gt; &gt; to is that the set of compressible strings is of measure zero. The set
</em><br />
<em class="quotelev2">&gt; &gt; of halting programs actually has finite measure, since \Omega &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 0. However, there is still finite probability of an input string
</em><br />
<em class="quotelev2">&gt; &gt; being nonhalting, and indeed the probability seems to be greater than
</em><br />
<em class="quotelev2">&gt; &gt; 0.7 (ie \Omega &lt;0.217643 - see pg 218 Li and Vitanyi), so this still
</em><br />
<em class="quotelev2">&gt; &gt; presents a problem for computationalism.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; This is mixing up everything, in particular, different measures.
</em><br />
<em class="quotelev1">&gt; 1) Infinite strings with finite program have *nonzero* measure, given
</em><br />
<em class="quotelev1">&gt; the *universal* measure (Omega is a number derived from the universal
</em><br />
<em class="quotelev1">&gt; measure).  2) They have measure zero, given the *uniform* measure (Omega
</em><br />
<em class="quotelev1">&gt; has nothing to do with it). 
</em><br />
<br />The uniform measure and the universal measure are related. The uniform
<br />
prior is on the set of input strings to a UTM, the universal measure
<br />
is the induced measure on the output strings.
<br />
<br />No. 1) here is the relevant statement, not 2).
<br />
<br />&nbsp;3) To see 2) we do not need the halting
<br />
<em class="quotelev1">&gt; theorem - we just compare the finite programs (countably many) to all
</em><br />
<em class="quotelev1">&gt; strings (uncountably many) and we are done. 4) The halting theorem is
</em><br />
<em class="quotelev1">&gt; no problem whatsoever when it comes to computable universes.  Why care
</em><br />
<em class="quotelev1">&gt; whether some computable universe stops or not?  If it does, it does,
</em><br />
<em class="quotelev1">&gt; otherwise it does not. In both cases we can compute it in the limit.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; The GP program (aka Universal Dovetailer) is not the simplest
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; thing. The simplest describable thing is the set of all descriptions,
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; that simply exist without being generated. That has precisely zero
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; information or complexity, whereas the UD has some complexity of the
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; order of a few 100 bits. The simplest prior is the uniform one, ie
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; there is no bias whatsoever in the selection.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Exist without being generated?  Precisely zero information or
</em><br />
<em class="quotelev3">&gt; &gt; &gt; complexity? But with respect to what?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; With respect to the observer. With the respect to anything in
</em><br />
<em class="quotelev2">&gt; &gt; fact. The set of all possible descriptions has precisely zero
</em><br />
<em class="quotelev2">&gt; &gt; information, by definition, regardless of what observer or context you
</em><br />
<em class="quotelev2">&gt; &gt; employ.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; This is a vague informal statement, not a definition. Which are the
</em><br />
<em class="quotelev1">&gt; possible descriptions? What's the formal difference between a
</em><br />
<em class="quotelev1">&gt; description
</em><br />
<em class="quotelev1">&gt; and a non-description?  What is your &quot;anything&quot; if there is no device
</em><br />
<em class="quotelev1">&gt; for describing it formally? If &quot;anything&quot; does not convey any bit of
</em><br />
<em class="quotelev1">&gt; info then what exactly is it that conveys one bit? Or two?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br />Choose an alphabet (a finite set of symbols). The set of all
<br />
descriptions is the set of all infinite length strings constructed
<br />
from that alphabet. I would suggest the notation A*, where A is the
<br />
alphabet, but I think this usually refers to the set of finite length
<br />
strings.
<br />
<br />Now to measure the information content of any particular string, you
<br />
need to define an interpreter (or observer) which is simply a map o(x)
<br />
from the set of all descriptions to a set of equivalence classes
<br />
(which can be identified as a subset of the whole numbers N).
<br />
<br />If that map is partially recursive, then the interpreter can be
<br />
replaced by a Turing machine. But the map need not be partially
<br />
recursive, and I believe it is possible to do this with stochastic
<br />
maps (ie a map with an additional input connected to a random oracle).
<br />
<br />The information of a string s is simply given by:
<br />
<br />I(s) = -log m(o^{-1}(o(s)))/m(Omega)
<br />
<br />where Omega is the set of all descriptions, m the uniform measure, and
<br />
o^{-1}(o(s)) is the equivalence class equivalent to s. The ratio above
<br />
exists, in appropriate limits, even if the value m(Omega) is infinite.
<br />
<br />Nevertheless, regardless of what map is chosen, the set of all
<br />
descriptions has zero information content, as log 1 = 0.
<br />
<br /><em class="quotelev2">&gt; &gt;  Any traditional definition of
</em><br />
<em class="quotelev3">&gt; &gt; &gt; information/simplicity requires the specification of a formal
</em><br />
<em class="quotelev3">&gt; &gt; &gt; description
</em><br />
<em class="quotelev3">&gt; &gt; &gt; method, such as a Turing machine. You don't need one? Then how do you
</em><br />
<em class="quotelev3">&gt; &gt; &gt; define information or complexity? How exactly do you define &quot;simple&quot; ?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Actually, all it needs is an equivalencing procedure. See my &quot;On
</em><br />
<em class="quotelev2">&gt; &gt; Complexity and Emergence&quot; paper. A Turing machine will do the job for
</em><br />
<em class="quotelev2">&gt; &gt; you, but so will a neural network or an &quot;expert system&quot; following
</em><br />
<em class="quotelev2">&gt; &gt; heuristic rules.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; So you have to write down formally this equivalencing procedure, right?
</em><br />
<em class="quotelev1">&gt; Why should this be different in principle from writing down the formal
</em><br />
<em class="quotelev1">&gt; rules for a Turing machine? Why is a simplicity measure that depends on
</em><br />
<em class="quotelev1">&gt; your equivalencing procedure superior to a simplicity measure depending
</em><br />
<em class="quotelev1">&gt; on a Turing machine?  (The TM procedure includes yours - because it
</em><br />
<em class="quotelev1">&gt; includes all procedures - but not the other way round.)
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br />I think I've answered this already.
<br />
<br />----------------------------------------------------------------------------
<br />
Dr. Russell Standish            	 Director
<br />
High Performance Computing Support Unit, Phone 9385 6967, 8308 3119 (mobile)
<br />
UNSW SYDNEY 2052                     	 Fax   9385 6965, 0425 253119 (&quot;)
<br />
Australia            			 R.Standish.domain.name.hidden             
<br />
Room 2075, Red Centre                    <a href="http://parallel.hpc.unsw.edu.au/rks">http://parallel.hpc.unsw.edu.au/rks</a>
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;International prefix  +612, Interstate prefix 02
<br />
----------------------------------------------------------------------------
<br />
<span id="received"><dfn>Received on</dfn> Mon Oct 29 2001 - 15:24:42 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start3413">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="3414.html" title="Next message in the list">Marchal: "Re: Predictions &#0038; duplications"</a></li>
<li><dfn>Previous message</dfn>: <a href="3412.html" title="Previous message in the list">Juergen Schmidhuber: "Re: Predictions &#0038; duplications"</a></li>
<li><dfn>In reply to</dfn>: <a href="3412.html" title="Message to which this message replies">Juergen Schmidhuber: "Re: Predictions &#0038; duplications"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="3349.html" title="Next message in this discussion thread">juergen.domain.name.hidden: "Re: Predictions &#0038; duplications"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg3413" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg3413" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg3413" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg3413" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:07 PST
</em></small></p>
</body>
</html>
