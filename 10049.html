<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: COMP &amp; Self-awareness from Colin Geoffrey Hales on 2006-07-25 (everything)</title>
<meta name="Author" content="Colin Geoffrey Hales (c.hales.domain.name.hidden)" />
<meta name="Subject" content="Re: COMP &amp; Self-awareness" />
<meta name="Date" content="2006-07-25" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: COMP &amp; Self-awareness</h1>
<!-- received="Wed Jul 26 02:41:55 2006" -->
<!-- isoreceived="20060726094155" -->
<!-- sent="Wed, 26 Jul 2006 16:39:39 +1000 (EST)" -->
<!-- isosent="20060726063939" -->
<!-- name="Colin Geoffrey Hales" -->
<!-- email="c.hales.domain.name.hidden" -->
<!-- subject="Re: COMP &amp; Self-awareness" -->
<!-- id="2927.60.230.102.36.1153895979.squirrel.domain.name.hidden" -->
<!-- charset="UTF-8" -->
<!-- inreplyto="44C6E5DE.9060203.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start10049" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="10050.html" accesskey="d" title="Hal Finney: &quot;Re: Interested in thoughts on this excerpt from Martin Rees&quot;">Next message</a> ]
[ <a href="10048.html" title="Stathis Papaioannou: &quot;RE: Bruno&#0039;s argument&quot;">Previous message</a> ]
[ <a href="10046.html" title="Brent Meeker: &quot;Re: COMP &#0038; Self-awareness&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="10051.html" accesskey="t" title="Bruno Marchal: &quot;Re: COMP &#0038; Self-awareness&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10049" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10049" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10049" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10049" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Colin Geoffrey Hales &lt;<a href="mailto:c.hales.domain.name.hidden?Subject=Re%3A%20COMP%20%26%20Self-awareness">c.hales.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Wed, 26 Jul 2006 16:39:39 +1000 (EST)</span><br />
</address>
<br />
&lt;mega snip&gt;
<br />
(a) Phenomenal awareness (experience inclusive of a self model)
<br />
And
<br />
(b) Psychological awareness (knowledge inclusive of a self model)
<br />
&lt;more snip&gt;
<br />
<br /><br />Brent Meeker wrote:
<br />
<em class="quotelev1">&gt; Maybe...with some more explication.  You're saying that phenomenal
</em><br />
awareness (a) is perception that
<br />
<em class="quotelev1">&gt; includes a model of oneself as the percipient.
</em><br />
<br />(a) _may_ include phenomenal depiction of self. 'Self' is also implicit in
<br />
the location of the experiencer within the phenomenal depiction  - eg your
<br />
vision feels like it's generated by your eyes - in reality you're 'being'
<br />
an occipital lobe persiscope. The periscope effect centres the visual
<br />
field apparent locus at your eyeballs. Imagine your own visual field
<br />
depicting you from your dog's perspective. Imagine your own visual field
<br />
with everything in it except your own body (look in a mirror - you are not
<br />
there are you a vampire? :-) ).
<br />
<br />These 'self' aspects are optional implicit/explicit constructs in your
<br />
visual phenomenal life. They are, in effect, collections of intrinsic
<br />
knowledge... knowledge that is 'known' through the act of experiencing it.
<br />
The presence or absence of 'self' in this knowledge is moot.
<br />
<br /><em class="quotelev1">&gt;But I don't see what (b) is?...knowing you're six foot tall and live in
</em><br />
California?
<br />
<br />Yes... but in the way that you 'know' an old phone number... no experience
<br />
until recall, and an ability to use the number on recall - to behave in
<br />
response to the holding of that knowledge.
<br />
<br /><em class="quotelev1">&gt; Have you read any of John McCarthy's
</em><br />
<em class="quotelev1">&gt; essays (see his website) on making a conscious robot?
</em><br />
<br />My main goal in life is Artifical General Intelligence. Making a concious
<br />
robot is entirely what I am about. I know John McCarthy's stuff. He's one
<br />
of my AI heroes. BUT....He has the traditional
<br />
computationalist/functionalist/eliminativist views &quot;if it look like an X,
<br />
acts like an X then it must be experiencing what X's experience&quot;. WRONG.
<br />
<br />Like all computer scientists J McC forgets that the physics of phenomenal
<br />
consciousness (a) does not exist as a body of knowledge. Nobody can make a
<br />
scientifically justified statement as to the causal basis or predict the
<br />
actual experiential life of a rock, computer, scientist, the internet or
<br />
anything else. Computer science is particularly deluded that real
<br />
artifical general intelligence (AGI) can arise without the role of the
<br />
AGI's phenomenal life being sorted definitively.
<br />
<br /><em class="quotelev1">&gt; If a robot knows where it is (say via GPS) and
</em><br />
<em class="quotelev1">&gt; senses its surroundigs
</em><br />
<em class="quotelev1">&gt; (say by IR cameras) then it's got consciousness (a).
</em><br />
<br />No. There is no phenomenal (visual) field here. There are photons hitting
<br />
a semiconductor array. Outer electron shells being perturbed, causing a
<br />
cascade of electronic causality within which a deductive electronic
<br />
analysis is enacted based on a-priori rules. Similarly, in a real retina
<br />
the photons cause a protein isomerisation and a different electrical
<br />
causality cascade (an action potential pulse train)...this too has nothing
<br />
directly to do with the generation of the visual experience - which
<br />
happens elsewhere in cortex.
<br />
<br />Whatever the physics of biology has that generates a visual experience in
<br />
brain material - that physics is justifyably proven absent in the
<br />
discussed robot electronics. Not even close! There may be experiential
<br />
content, but whether this is even remotely like a visual experience
<br />
science cannot say. It could be the experience of a hot silicon rock. If
<br />
not, why not? If so, why so?
<br />
<br /><em class="quotelev1">&gt; If it also knows it weighs 5000lbs and has
</em><br />
<em class="quotelev1">&gt; enough fuel to go 200miles it's got consciousness (b)
</em><br />
<br />Side note: I'd say (b) was not consciousness at all. Nevertheless....
<br />
Experiencing something proportional to weight is (a)
<br />
_but_
<br />
Behaving because you have data corresponding to weight is (b)
<br />
<br /><em class="quotelev1">&gt; (I'm not just making these up - they're things
</em><br />
<em class="quotelev1">&gt; a vehicle in the DARPA challenge would have).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Now suppose that it also has a memory of what obstacles it crossed in
</em><br />
the past and which ones it
<br />
<em class="quotelev1">&gt; failed to cross; and when it detects a new obstacle it uses this memory
</em><br />
to decide whether to go around or not.
<br />
<em class="quotelev1">&gt; What kind of consciousness is that?
</em><br />
<br />(b) = it's just a bunch of learning rules installed based on the a-priori
<br />
knowledge of beings who used phenomenal experience (a) to create the
<br />
rules, abstract them and make a type (b) zombie-critter live by them.
<br />
<br />&nbsp;---------------
<br />
<br />The existence and use of phenomenal fields is no natural and omnipresent
<br />
in humans it's hard to see them even though it's all there is to see. They
<br />
are seeing! Close your eyes. Your visual phenomenal field is radically
<br />
altered (assuming you have eyelids!). Imagine you had 'eyelids' on your
<br />
entire body surface touch-field (this field is actually generated in your
<br />
anterior parietal lobe or was it posterior frontal...no matter).... You
<br />
would go numb all over when you 'closed' them.
<br />
<br />The subtlety with (a) consciousness is, I think, it's actual role in 
<br />
biological critters that combine (a) and (b) or more specifically use (a)
<br />
to generate (b). (a) was clearly found necessary by evolution or we
<br />
wouldn't have it. So what role has it got? My guess is that in providing
<br />
the source of all derived knowledge (b), it actually serves the purpose of
<br />
handling novelty. Generate all the rules you want... unless you have rules
<br />
for handling arbitrary levels of novelty your critter is going to
<br />
eventually crash and burn. Symbolic grounding... that's why I think (a)
<br />
was found so compelling by evolution.
<br />
<br />No amount of abstracted (as-if) computation can replicate the 'natural
<br />
world' computation of (a) consciousness. IMO (a) consciousness is raw
<br />
physics-as-computation and it's application in the construction of 'self'
<br />
is just an option commensurate to its need. You only need a model of self
<br />
to behave intelligently in relation to self - a survival imperative. I can
<br />
imagine a servile AGI that had a radically complex phenomenal life (say
<br />
one that experiences neutrinos directly) but almost no explicit self
<br />
model. I'm not sure how useful it would be, but it seems very possible.
<br />
<br />cheers
<br />
colin hales
<br />
<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Wed Jul 26 2006 - 02:41:55 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start10049">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="10050.html" title="Next message in the list">Hal Finney: "Re: Interested in thoughts on this excerpt from Martin Rees"</a></li>
<li><dfn>Previous message</dfn>: <a href="10048.html" title="Previous message in the list">Stathis Papaioannou: "RE: Bruno&#0039;s argument"</a></li>
<li><dfn>In reply to</dfn>: <a href="10046.html" title="Message to which this message replies">Brent Meeker: "Re: COMP &#0038; Self-awareness"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="10051.html" title="Next message in this discussion thread">Bruno Marchal: "Re: COMP &#0038; Self-awareness"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10049" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10049" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10049" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10049" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:11 PST
</em></small></p>
</body>
</html>
