<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>RE: The Meaning of Life from Stathis Papaioannou on 2007-01-08 (everything)</title>
<meta name="Author" content="Stathis Papaioannou (stathispapaioannou.domain.name.hidden)" />
<meta name="Subject" content="RE: The Meaning of Life" />
<meta name="Date" content="2007-01-08" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>RE: The Meaning of Life</h1>
<!-- received="Mon Jan  8 17:36:44 2007" -->
<!-- isoreceived="20070109013644" -->
<!-- sent="Tue, 9 Jan 2007 09:36:26 +1100" -->
<!-- isosent="20070108223626" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathispapaioannou.domain.name.hidden" -->
<!-- subject="RE: The Meaning of Life" -->
<!-- id="BAY124-W197F66655F01FF8C59CAF2D2BC0.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="The Meaning of Life" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start12500" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="12501.html" accesskey="d" title="Stathis Papaioannou: &quot;RE: Evil ? (was: Hypostases (was: Natural Order &#0038; Belief)&quot;">Next message</a> ]
[ <a href="12499.html" title="Mark Peaty: &quot;Re: The Meaning of [your] Life&quot;">Previous message</a> ]
[ <a href="12379.html" title="Tom Caylor: &quot;The Meaning of Life&quot;">Maybe in reply to</a> ]
<!-- unextthread="start" -->
[ <a href="12507.html" accesskey="t" title="Bruno Marchal: &quot;Re: The Meaning of Life&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg12500" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg12500" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg12500" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg12500" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Stathis Papaioannou &lt;<a href="mailto:stathispapaioannou.domain.name.hidden?Subject=RE%3A%20The%20Meaning%20of%20Life">stathispapaioannou.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 9 Jan 2007 09:36:26 +1100</span><br />
</address>
<br />
Bruno Marchal writes:
<br />
<br /><em class="quotelev3">&gt; &gt;&gt; Le 07-janv.-07, à 19:21, Brent Meeker a écrit :
</em><br />
<em class="quotelev4">&gt; &gt;&gt; &gt; And does it even have to be very good?  Suppose it made a sloppy 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; copy &gt; of me that left out 90% of my memories - would it still be 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; &quot;me&quot;?  How &gt; much fidelity is required for Bruno's argument?  I think 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; not much.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; The argument does not depend at all of the level of fidelity. Indeed 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; I make clear (as much as possible) that comp is equivalent to the 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; belief there is a level of substitution of myself (3-person) such 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; that I (1-person) survive a functional substitution done at that 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; level. Then I show no machine can know what is her level of 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; substitution (and thus has to bet or guess about it).
</em><br />
<em class="quotelev3">&gt; &gt;&gt; This is also the reason why comp is not jeopardized by the idea that 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; the environment is needed: just put the environment in the definition 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; of my &quot;generalized brain&quot;.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Imagine someone who say that his brain is the entire galaxy, 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; described at the level of all interacting quantum strings. This can 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; be captured by giant (to say the least) but finite, rational complex 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; matrices. Of course the thought experiment with the &quot;yes doctor&quot; will 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; look very non-realist, but *in fine*, all what is needed (for the 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; reversal) is that the Universal Dovetailer get through the state of 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; my generalized brain, and the UD will get it even if my &quot;state&quot; is 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; the state of the whole galaxy, or more.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; If it happens that my state is the galaxy state AND that the galaxy 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; state cannot be captured in a finite ('even giant) way(*), then we 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; are just out of the scope of the comp- reasoning. This is possible 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; because comp may be wrong.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; This is right, and it is perhaps a consequence of comp that 
</em><br />
<em class="quotelev2">&gt; &gt; computationalists did not brgain on. If the functional equivalent of 
</em><br />
<em class="quotelev2">&gt; &gt; my brain has to interact with the environment in the same way that I 
</em><br />
<em class="quotelev2">&gt; &gt; do then that puts a constraint what sort of machine it can be, as well 
</em><br />
<em class="quotelev2">&gt; &gt; as necessitating of course that it be an actual physical machine. For 
</em><br />
<em class="quotelev2">&gt; &gt; example, if as part of asserting my status as a conscious being I 
</em><br />
<em class="quotelev2">&gt; &gt; decide to lift my hand in the air when I see a red ball, then my 
</em><br />
<em class="quotelev2">&gt; &gt; functional replacement must (at least) have photoreceptors which send 
</em><br />
<em class="quotelev2">&gt; &gt; a signal to a central processor which then sends a motor signal to its 
</em><br />
<em class="quotelev2">&gt; &gt; hand. If it fails the red ball test, then it isn't functionally 
</em><br />
<em class="quotelev2">&gt; &gt; equivalent to me.
</em><br />
<em class="quotelev2">&gt; &gt; However, what if you put the red ball, the hand and the whole 
</em><br />
<em class="quotelev2">&gt; &gt; environment inside the central processor? You program in data which 
</em><br />
<em class="quotelev2">&gt; &gt; tells it is seeing a red ball, it sends a signal to what it thinks is 
</em><br />
<em class="quotelev2">&gt; &gt; its hand, and it receives visual and proprioceptive data telling it it 
</em><br />
<em class="quotelev2">&gt; &gt; has successfully raised the hand. Given that this self-contained 
</em><br />
<em class="quotelev2">&gt; &gt; machine was derived from a known computer architecture with known 
</em><br />
<em class="quotelev2">&gt; &gt; sensors and effectors, we would know what it was thinking by 
</em><br />
<em class="quotelev2">&gt; &gt; eavesdropping on its internal processes. But if we didn't have this 
</em><br />
<em class="quotelev2">&gt; &gt; knowledge, is there any way, even in theory, that we could figure it 
</em><br />
<em class="quotelev2">&gt; &gt; out? The answer in general is &quot;no&quot;: without benefit of environmental 
</em><br />
<em class="quotelev2">&gt; &gt; interaction, or an instruction manual, there is no way to assign 
</em><br />
<em class="quotelev2">&gt; &gt; meaning to the workings of a machine and there is no way to know 
</em><br />
<em class="quotelev2">&gt; &gt; anything about its consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Up to here I do agree.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; The corollary of this is that under the right interpretation a machine 
</em><br />
<em class="quotelev2">&gt; &gt; could have any meaning or any consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't think that this corollary follows. Unless you are postulating a 
</em><br />
<em class="quotelev1">&gt; &quot;physical world&quot; having some special property (and then the question 
</em><br />
<em class="quotelev1">&gt; is: what are your axiom for that physical realm, and where does those 
</em><br />
<em class="quotelev1">&gt; axioms come from). Even in classical physics, where a point can move 
</em><br />
<em class="quotelev1">&gt; along &quot;all real numbers&quot;, I don't see any reason such move can 
</em><br />
<em class="quotelev1">&gt; represent any computation. Of course I consider a computation as being 
</em><br />
<em class="quotelev1">&gt; something non physical, and essentially discrete, at the start. The 
</em><br />
<em class="quotelev1">&gt; physical and continuous aspect comes from the fact that any computation 
</em><br />
<em class="quotelev1">&gt; is &quot;embedded&quot; into an infinity of &quot;parallel&quot; computations (those 
</em><br />
<em class="quotelev1">&gt; generated by the UD).
</em><br />
<em class="quotelev1">&gt; Brent says that the &quot;evil problem&quot; is a problem only for those who 
</em><br />
<em class="quotelev1">&gt; postulate an omniscient and omnipotent good god. I believe that somehow 
</em><br />
<em class="quotelev1">&gt; a large part of the &quot;mind/body&quot; problem comes from our (instinctive) 
</em><br />
<em class="quotelev1">&gt; assumption of a basic (primitive) physical reality.
</em><br />
<br />Yes, but you're assuming here that which I (you?) set out to prove. In your UDA 
<br />
you do not explicitly start out with &quot;there is no physical world&quot; but arrive at this 
<br />
as a conclusion. Consider the following steps:
<br />
<br />1. There appears to be a physical world
<br />
2. Some of the substructures in this world appear to be conscious, namely brains
<br />
3. The third person behaviour of these brains can be copied by an appropriate digital 
<br />
computer
<br />
4. The first person experience of these brains would also thereby be copied by 
<br />
such a computer
<br />
5. The first person experience of the computer would remain unchanged if the third 
<br />
person behaviour were made part of the program
<br />
6. But this would mean there is no way to attach meaning or consciousness to the 
<br />
self-contained computer - it could be thinking of a red ball, blue ball, or no ball
<br />
<br />This is an unexpected result, which can be resolved several ways:
<br />
<br />7. (3) is incorrect, and we need not worry about the rest
<br />
8. (4) is incorrect, and we need not worry about the rest
<br />
9. (5) is incorrect, and we need not worry about the rest
<br />
<br />[(7) or (8) would mean that there is something non-computational about the brain; (9) 
<br />
would mean there is something non-computational about a computer interacting with its 
<br />
environment, which seems to me even less plausible.]
<br />
<br />But if (3) to (5) are all correct, that leaves (6) as correct, which implies that consciousness 
<br />
is decoupled from physical activity. This would mean that in those cases where we do 
<br />
associate consciousness with particular physical activity, such as in brains or computers, 
<br />
it is not really the physical activity which is &quot;causing&quot; the consciousness. I think of it as 
<br />
analogous to a computer doing arithmetic: it is not &quot;causing&quot; the arithmetic, but is harnessing 
<br />
a mathematical truth to some physical task.
<br />
<br />If consciousness is decoupled from physical activity, this means that our conscious experience 
<br />
would be unchanged if the apparent physical activity of our brain were not really there. This 
<br />
would make all the evidence of our senses on which we base the existence of a physical world 
<br />
illusory: we would have these same experiences if the physical world suddenly disappeared or 
<br />
never existed in the first place. We can keep (1) and (2) because I qualified them with the word 
<br />
&quot;appears&quot;, but the necessity of a separate physical reality accounting for this appearance goes.
<br />
<br /><em class="quotelev2">&gt; &gt; You can't avoid the above problem without making changes to (standard) 
</em><br />
<em class="quotelev2">&gt; &gt; computationalism. You can drop computationalism altogether and say 
</em><br />
<em class="quotelev2">&gt; &gt; that the brain + environment is not Turing emulable. Or, as Bruno has 
</em><br />
<em class="quotelev2">&gt; &gt; suggested, you can keep computationalism and drop the physical 
</em><br />
<em class="quotelev2">&gt; &gt; supervenience criterion.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I am OK with this ('course).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Bruno
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; <a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
</em><br />
<br />Stathis Papaioannou
<br />
_________________________________________________________________
<br />
Be one of the first to try Windows Live Mail.
<br />
<a href="http://ideas.live.com/programpage.aspx?versionId=5d21c51a-b161-4314-9b0e-4911fb2b2e6d">http://ideas.live.com/programpage.aspx?versionId=5d21c51a-b161-4314-9b0e-4911fb2b2e6d</a>
<br />
--~--~---------~--~----~------------~-------~--~----~
<br />
&nbsp;You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Mon Jan 08 2007 - 17:36:44 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start12500">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="12501.html" title="Next message in the list">Stathis Papaioannou: "RE: Evil ? (was: Hypostases (was: Natural Order &#0038; Belief)"</a></li>
<li><dfn>Previous message</dfn>: <a href="12499.html" title="Previous message in the list">Mark Peaty: "Re: The Meaning of [your] Life"</a></li>
<li><dfn>Maybe in reply to</dfn>: <a href="12379.html" title="Message to which this message replies">Tom Caylor: "The Meaning of Life"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="12507.html" title="Next message in this discussion thread">Bruno Marchal: "Re: The Meaning of Life"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="12507.html" title="Message sent in reply to this message">Bruno Marchal: "Re: The Meaning of Life"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg12500" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg12500" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg12500" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg12500" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:13 PST
</em></small></p>
</body>
</html>
