<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Consciousness is information? from Alberto G.Corona on 2009-05-19 (everything)</title>
<meta name="Author" content="Alberto G.Corona (agocorona.domain.name.hidden)" />
<meta name="Subject" content="Re: Consciousness is information?" />
<meta name="Date" content="2009-05-19" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Consciousness is information?</h1>
<!-- received="Tue May 19 02:37:42 2009" -->
<!-- isoreceived="20090519093742" -->
<!-- sent="Tue, 19 May 2009 02:37:42 -0700 (PDT)" -->
<!-- isosent="20090519093742" -->
<!-- name="Alberto G.Corona" -->
<!-- email="agocorona.domain.name.hidden" -->
<!-- subject="Re: Consciousness is information?" -->
<!-- id="a7501beb-20bf-4650-8702-501695759d7d.domain.name.hidden" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="c8d958e90905171950r4b781e20h31a70f4c60646108.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start16649" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="16650.html" accesskey="d" title="John Mikes: &quot;Re: logic mailing list&quot;">Next message</a> ]
[ <a href="16648.html" title="Kelly Harmon: &quot;Re: Consciousness is information?&quot;">Previous message</a> ]
[ <a href="16634.html" title="Kelly Harmon: &quot;Re: Consciousness is information?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="16655.html" accesskey="t" title="Bruno Marchal: &quot;Re: Consciousness is information?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg16649" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg16649" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg16649" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg16649" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Alberto G.Corona &lt;<a href="mailto:agocorona.domain.name.hidden?Subject=Re%3A%20Consciousness%20is%20information%3F">agocorona.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 19 May 2009 02:37:42 -0700 (PDT)</span><br />
</address>
<br />
That is also my case. I wonder how the materialist hypothesis has
<br />
advanced in a plausible explanation of consciousness, and I think that
<br />
this is the right path, and I follow it. But at the deep level, my
<br />
subjective experience tells me that I must remain dualist.
<br />
<br />I think however that for evolutionary purposes, the consciousness,
<br />
being designed by natural selection for keeping an accurate picture of
<br />
how the others see us, must naturally reject a materialist explanation
<br />
because this is not an accurate picture. The other people do not see
<br />
us as a piece of evolved mechanisms, but as moral beings. An adaptive
<br />
self must be, and is, fiercely dualist, with a strong notion of self
<br />
autonomy and unit of purpose. So all of us feel that way when not
<br />
thinking about that.
<br />
<br />Thus, maybe if ever a robot is made to simulate our behavior must
<br />
incorporate an inner rejection of materialist explanation about the
<br />
nature of his higher level circuits, and a vivid notion of subjective
<br />
experience. That is not difficult at a certain level of technology, to
<br />
create a central “self” module that receives the filtered, relevant
<br />
information, plus information of the commands and actions of other
<br />
decision modules. This self module must be capable of &quot;inventing&quot; (and
<br />
that´s the tricky thing) a self centered, socially plausible, moral
<br />
history that link together such perceptions and such actions. Then,
<br />
when someone ask him &quot;do you have subjective experience, qualia and so
<br />
on&quot; the robot will answer, “of cause, yes, I have a very strong
<br />
sensation of unity of mind, perception and I´m a moral subject capable
<br />
of self determination”.  Otherwise, he will be inconsistent or non
<br />
functional as human simulation.
<br />
<br />By the way, the role of the self process as a creator of self centered
<br />
histories that are credible for the rest of us, that tend to show a
<br />
favorable moral image of the self has been checked in different
<br />
experiments, especially with lobotomized people (that invent two
<br />
different histories of the same perception-action in each hemisphere).
<br />
It also explains many mental disorders: compulsive liars and crazy
<br />
overhyped egos made of fantastic histories (reincarnations of
<br />
Napoleon) for example. It also explains many effects in social life of
<br />
sane people. How hard is to achieve objectivity, for example?
<br />
<br /><br />On May 18, 4:50 am, Kelly Harmon &lt;harmon....domain.name.hidden&gt; wrote:
<br />
<em class="quotelev1">&gt; On Sun, May 17, 2009 at 9:13 PM, Brent Meeker &lt;meeke....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Generally I don't think that what we experience is necessarily caused
</em><br />
<em class="quotelev3">&gt; &gt;&gt; by physical systems.  I think that sometimes physical systems assume
</em><br />
<em class="quotelev3">&gt; &gt;&gt; configurations that &quot;shadow&quot;, or represent, our conscious experience.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; But they don't CAUSE our conscious experience.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; So if we could track the functions of the brain at a fine enough scale,
</em><br />
<em class="quotelev2">&gt; &gt; we'd see physical events that didn't have physical causes (ones that
</em><br />
<em class="quotelev2">&gt; &gt; were caused by mental events?).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; No, no, no.  I'm not saying that at all.  Ultimately I'm saying that
</em><br />
<em class="quotelev1">&gt; if there is a physical world, it's irrelevant to consciousness.
</em><br />
<em class="quotelev1">&gt; Consciousness is information.  Physical systems can be interpreted as
</em><br />
<em class="quotelev1">&gt; representing, or &quot;storing&quot;, information, but that act of &quot;storage&quot;
</em><br />
<em class="quotelev1">&gt; isn't what gives rise to conscious experience.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; You're aware of course that the same things were said about the
</em><br />
<em class="quotelev2">&gt; &gt; physio/chemical bases of life.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; You mentioned that point before, as I recall.  Dennett made a similar
</em><br />
<em class="quotelev1">&gt; argument against Chalmers, to which Chalmers had what I thought was an
</em><br />
<em class="quotelev1">&gt; effective response:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; -------<a href="http://consc.net/papers/moving.html">http://consc.net/papers/moving.html</a>
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Perhaps the most common strategy for a type-A materialist is to
</em><br />
<em class="quotelev1">&gt; deflate the &quot;hard problem&quot; by using analogies to other domains, where
</em><br />
<em class="quotelev1">&gt; talk of such a problem would be misguided. Thus Dennett imagines a
</em><br />
<em class="quotelev1">&gt; vitalist arguing about the hard problem of &quot;life&quot;, or a neuroscientist
</em><br />
<em class="quotelev1">&gt; arguing about the hard problem of &quot;perception&quot;. Similarly, Paul
</em><br />
<em class="quotelev1">&gt; Churchland (1996) imagines a nineteenth century philosopher worrying
</em><br />
<em class="quotelev1">&gt; about the hard problem of &quot;light&quot;, and Patricia Churchland brings up
</em><br />
<em class="quotelev1">&gt; an analogy involving &quot;heat&quot;. In all these cases, we are to suppose,
</em><br />
<em class="quotelev1">&gt; someone might once have thought that more needed explaining than
</em><br />
<em class="quotelev1">&gt; structure and function; but in each case, science has proved them
</em><br />
<em class="quotelev1">&gt; wrong. So perhaps the argument about consciousness is no better.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; This sort of argument cannot bear much weight, however. Pointing out
</em><br />
<em class="quotelev1">&gt; that analogous arguments do not work in other domains is no news: the
</em><br />
<em class="quotelev1">&gt; whole point of anti-reductionist arguments about consciousness is that
</em><br />
<em class="quotelev1">&gt; there is a disanalogy between the problem of consciousness and
</em><br />
<em class="quotelev1">&gt; problems in other domains. As for the claim that analogous arguments
</em><br />
<em class="quotelev1">&gt; in such domains might once have been plausible, this strikes me as
</em><br />
<em class="quotelev1">&gt; something of a convenient myth: in the other domains, it is more or
</em><br />
<em class="quotelev1">&gt; less obvious that structure and function are what need explaining, at
</em><br />
<em class="quotelev1">&gt; least once any experiential aspects are left aside, and one would be
</em><br />
<em class="quotelev1">&gt; hard pressed to find a substantial body of people who ever argued
</em><br />
<em class="quotelev1">&gt; otherwise.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; When it comes to the problem of life, for example, it is just obvious
</em><br />
<em class="quotelev1">&gt; that what needs explaining is structure and function: How does a
</em><br />
<em class="quotelev1">&gt; living system self-organize? How does it adapt to its environment? How
</em><br />
<em class="quotelev1">&gt; does it reproduce? Even the vitalists recognized this central point:
</em><br />
<em class="quotelev1">&gt; their driving question was always &quot;How could a mere physical system
</em><br />
<em class="quotelev1">&gt; perform these complex functions?&quot;, not &quot;Why are these functions
</em><br />
<em class="quotelev1">&gt; accompanied by life?&quot; It is no accident that Dennett's version of a
</em><br />
<em class="quotelev1">&gt; vitalist is &quot;imaginary&quot;. There is no distinct &quot;hard problem&quot; of life,
</em><br />
<em class="quotelev1">&gt; and there never was one, even for vitalists.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; In general, when faced with the challenge &quot;explain X&quot;, we need to ask:
</em><br />
<em class="quotelev1">&gt; what are the phenomena in the vicinity of X that need explaining, and
</em><br />
<em class="quotelev1">&gt; how might we explain them? In the case of life, what cries out for
</em><br />
<em class="quotelev1">&gt; explanation are such phenomena as reproduction, adaptation,
</em><br />
<em class="quotelev1">&gt; metabolism, self-sustenance, and so on: all complex functions. There
</em><br />
<em class="quotelev1">&gt; is not even a plausible candidate for a further sort of property of
</em><br />
<em class="quotelev1">&gt; life that needs explaining (leaving aside consciousness itself), and
</em><br />
<em class="quotelev1">&gt; indeed there never was. In the case of consciousness, on the other
</em><br />
<em class="quotelev1">&gt; hand, the manifest phenomena that need explaining are such things as
</em><br />
<em class="quotelev1">&gt; discrimination, reportability, integration (the functions), and
</em><br />
<em class="quotelev1">&gt; experience. So this analogy does not even get off the ground.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; ------
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; Though it DOES seem plausible/obvious to me that a physical system
</em><br />
<em class="quotelev3">&gt; &gt;&gt; going through a sequence of these representations is what produces
</em><br />
<em class="quotelev3">&gt; &gt;&gt; human behavior.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; So you're saying that a sequence of physical representations is enough
</em><br />
<em class="quotelev2">&gt; &gt; to produce behavior.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Right, observed behavior.  What I'm saying here is that it seems
</em><br />
<em class="quotelev1">&gt; obvious to me that mechanistic computation is sufficient to explain
</em><br />
<em class="quotelev1">&gt; observed human behavior.  If that was the only thing that needed
</em><br />
<em class="quotelev1">&gt; explaining, we'd be done.  Mission accomplished.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; BUT...there's subjective experience that also needs explained, and
</em><br />
<em class="quotelev1">&gt; this is actually the first question that needs answered.  All other
</em><br />
<em class="quotelev1">&gt; answers are suspect until subjective experience has been explained.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; And there must be conscious experience associated
</em><br />
<em class="quotelev2">&gt; &gt; with behavior.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Well, here's where it gets tricky.  Conscious experience is associated
</em><br />
<em class="quotelev1">&gt; with information.  But how information is tied to physical systems is
</em><br />
<em class="quotelev1">&gt; a different question.  Any physical systems can be interpreted as
</em><br />
<em class="quotelev1">&gt; representing all sorts of things (again, back to Putnam and Searle,
</em><br />
<em class="quotelev1">&gt; one-time pads, Maudlin's Olympia example, Bruno's movie graph
</em><br />
<em class="quotelev1">&gt; argument, rocks implementing every FSA, Stathis's birds and trees, and
</em><br />
<em class="quotelev1">&gt; triviality attacks on functionalism).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt; That seems to me to imply that physical representations
</em><br />
<em class="quotelev2">&gt; &gt; are enough to produce consciousness.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The problem is that physical &quot;representations&quot; are everywhere.  The
</em><br />
<em class="quotelev1">&gt; problem is coming up with a non-arbitrary way of deciding when a
</em><br />
<em class="quotelev1">&gt; physical system represents something that's conscious and when it
</em><br />
<em class="quotelev1">&gt; doesn't.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Physical systems are too representationally promiscuous!
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Which leads me to abandon physicalism/materialism for idealism.
</em><br />
--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue May 19 2009 - 02:37:42 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start16649">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="16650.html" title="Next message in the list">John Mikes: "Re: logic mailing list"</a></li>
<li><dfn>Previous message</dfn>: <a href="16648.html" title="Previous message in the list">Kelly Harmon: "Re: Consciousness is information?"</a></li>
<li><dfn>In reply to</dfn>: <a href="16634.html" title="Message to which this message replies">Kelly Harmon: "Re: Consciousness is information?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="16655.html" title="Next message in this discussion thread">Bruno Marchal: "Re: Consciousness is information?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="16655.html" title="Message sent in reply to this message">Bruno Marchal: "Re: Consciousness is information?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg16649" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg16649" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg16649" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg16649" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
