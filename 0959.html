<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re:implementation from Jacques M Mallah on 1999-07-18 (everything)</title>
<meta name="Author" content="Jacques M Mallah (jqm1584.domain.name.hidden)" />
<meta name="Subject" content="Re:implementation" />
<meta name="Date" content="1999-07-18" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re:implementation</h1>
<!-- received="Sun Jul 18 16:04:56 1999" -->
<!-- isoreceived="19990718230456" -->
<!-- sent="Sun, 18 Jul 1999 19:02:36 -0400" -->
<!-- isosent="19990718230236" -->
<!-- name="Jacques M Mallah" -->
<!-- email="jqm1584.domain.name.hidden" -->
<!-- subject="Re:implementation" -->
<!-- id="Pine.SGI.4.10.9907181740060.475825-100000.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="199907161856.LAA03046.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start959" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="0960.html" accesskey="d" title="Russell Standish: &quot;Re: Ramanujan [was:  Raymond Smullyan]&quot;">Next message</a> ]
[ <a href="0958.html" title="Jacques M Mallah: &quot;Re: minimal theory of consciousness&quot;">Previous message</a> ]
[ <a href="0946.html" title="hal.domain.name.hidden: &quot;Re:implementation&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="0955.html" accesskey="t" title="Marchal: &quot;Re:implementation&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg959" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg959" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg959" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg959" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Jacques M Mallah &lt;<a href="mailto:jqm1584.domain.name.hidden?Subject=Re%3Aimplementation">jqm1584.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sun, 18 Jul 1999 19:02:36 -0400</span><br />
</address>
<br />
On Fri, 16 Jul 1999 hal.domain.name.hidden wrote:
<br />
<em class="quotelev1">&gt; Let me restate Marchal's example slightly, to avoid confusing talk of
</em><br />
<em class="quotelev1">&gt; &quot;demons&quot;.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Suppose you have a Turing machine running a program which renders it
</em><br />
<em class="quotelev1">&gt; conscious.  However, the machine has a weak point in its design, which
</em><br />
<em class="quotelev1">&gt; causes occasional but rare intermittent failures.  During the failed
</em><br />
<em class="quotelev1">&gt; state, the machine executes randomly for a period of time, then the
</em><br />
<em class="quotelev1">&gt; failing part spontaneously corrects itself and the machine operates
</em><br />
<em class="quotelev1">&gt; correctly from then on.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Marchal then asks us to suppose that on some particular run of this
</em><br />
<em class="quotelev1">&gt; machine, the failure occurs, but during that time the random operation
</em><br />
<em class="quotelev1">&gt; of the machine &quot;just happens&quot; to match exactly what the machine was
</em><br />
<em class="quotelev1">&gt; supposed to be doing anyway.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I agree that during this time interval the machine cannot be considered
</em><br />
<em class="quotelev1">&gt; to handle counterfactuals correctly, hence the computation was not
</em><br />
<em class="quotelev1">&gt; implemented by that definition.  Had the inputs to the machine been
</em><br />
<em class="quotelev1">&gt; different, since the machine was behaving randomly there is no reason
</em><br />
<em class="quotelev1">&gt; to expect that it would have &quot;happened to&quot; performed correctly with
</em><br />
<em class="quotelev1">&gt; those inputs.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Just to clarify: by 'randomly' you mean that the behavior depends
<br />
only on the inputs.  I assume deterministic physics.
<br />
<br />[Marchal wrote]
<br />
<em class="quotelev3">&gt; &gt; &gt; Add a physically inactive piece such that, in the case of a change in the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; neighborhood of the UTM, that physically inactive piece become active, 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; and 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; act as an automated demon fixing instantaneously the UTM, in the 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; accidentally
</em><br />
<em class="quotelev3">&gt; &gt; &gt; correct state let by the lucky cosmic rays.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; (That that is possible is showned in Maudlin's paper).
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 	I take it that you mean that if the machine departs from it's
</em><br />
<em class="quotelev2">&gt; &gt; normal sequence, a switch will be triggered to activate a backup machine.
</em><br />
<em class="quotelev2">&gt; &gt; I think Maudlin's example used a false implementation, and I'm not
</em><br />
<em class="quotelev2">&gt; &gt; convinced that it could be done that way otherwise, but that's not the
</em><br />
<em class="quotelev2">&gt; &gt; quickest route to debunk the argument so let's continue.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I'm not sure I understand exactly what Marchal is proposing here.
</em><br />
<em class="quotelev1">&gt; He wants an automated demon to fix the UTM as soon as there is &quot;a change
</em><br />
<em class="quotelev1">&gt; in the neighborhood of the UTM&quot;.  What is this change which triggers
</em><br />
<em class="quotelev1">&gt; the fix?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't believe he refers to the failure of the machine.  If his demon
</em><br />
<em class="quotelev1">&gt; fixed the machine as soon as it broke, it would simply not be broken
</em><br />
<em class="quotelev1">&gt; and would behave properly during the interval in question, so would
</em><br />
<em class="quotelev1">&gt; handle counterfactuals correctly.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I think what he wants is that the demon watches the machine and if the
</em><br />
<em class="quotelev1">&gt; machine ever breaks AND behaves other than what it is supposed to by
</em><br />
<em class="quotelev1">&gt; its program and design, then it will be fixed.  So if the machine
</em><br />
<em class="quotelev1">&gt; randomly happens to follow the correct state transitions even while
</em><br />
<em class="quotelev1">&gt; broken, then the demon will not be activated and so the machine will
</em><br />
<em class="quotelev1">&gt; not need to get fixed.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; In the case of the example above, where the machine follows the correct
</em><br />
<em class="quotelev1">&gt; transitions &quot;by accident&quot; and then spontaneously fixes itself, the demon
</em><br />
<em class="quotelev1">&gt; is never active, and so the machine's actual activity is the same as
</em><br />
<em class="quotelev1">&gt; in the original state.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Assuming this is the intention, we can dispense with the demon and replace
</em><br />
<em class="quotelev1">&gt; him by some repair circuit.  However if we consider how this circuit would
</em><br />
<em class="quotelev1">&gt; work, I want to note one thing.  How can the repair circuit know when the
</em><br />
<em class="quotelev1">&gt; machine is behaving incorrectly, as defined above?  Incorrect behavior is
</em><br />
<em class="quotelev1">&gt; defined as departure from what the machine is actually supposed to do.
</em><br />
<em class="quotelev1">&gt; But the only way to detect that is to calculate, either in advance or
</em><br />
<em class="quotelev1">&gt; while the program is running, what the machine is supposed to be doing.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I agree.  In Maudlin's example the implementation was almost
<br />
'clock-style' (false) to begin with, so this was able to be swept under
<br />
the rug.  That's why I said to Marchal that I didn't know if it (Maudlin's
<br />
move) could be done for a non-false implementation.  (See my home page re:
<br />
false implementations.)
<br />
<br /><em class="quotelev1">&gt; This means that we either have to be running a replay of a previously
</em><br />
<em class="quotelev1">&gt; instantiated computation, or we have to be running a second computation
</em><br />
<em class="quotelev1">&gt; in parallel with this one.  In either case we are not dealing with a
</em><br />
<em class="quotelev1">&gt; unique calculation where this UTM is the only case where the calculation
</em><br />
<em class="quotelev1">&gt; is instantiated.  The consciousness in question WILL BE or HAS BEEN
</em><br />
<em class="quotelev1">&gt; instantiated.  If &quot;I&quot; am that consciousness, there is no question in
</em><br />
<em class="quotelev1">&gt; this thought experiment about whether I will ever have the experience of
</em><br />
<em class="quotelev1">&gt; thinking the thoughts in question.  I do, I must.  The only question is
</em><br />
<em class="quotelev1">&gt; whether my thoughts are being instantiated in this particular run of this
</em><br />
<em class="quotelev1">&gt; particular machine.  I, as a thinker, could not tell the difference; it's
</em><br />
<em class="quotelev1">&gt; not like it would make the difference between my existence and my lack
</em><br />
<em class="quotelev1">&gt; of existence.  It would only affect how many times I am instantiated,
</em><br />
<em class="quotelev1">&gt; and as I have argued before, it is questionable to me whether this has
</em><br />
<em class="quotelev1">&gt; any subjective or objective effects.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;While it is obvious to me that measure is proprtional to the
<br />
number of implementations, I must point out that is only true of
<br />
independent implementations.  In this case where one implementation
<br />
depends on another it is probably just a single (independent)
<br />
implementation and should be counted as such.
<br />
<br /><em class="quotelev3">&gt; &gt; &gt; Now I tell you that there will be no change between t1 and t2 in the 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; neighborhood of the UTM, so that the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; inactive demon remains inactive. Note that the whole setting is
</em><br />
<em class="quotelev3">&gt; &gt; &gt; counterfactually correct and should, I think, be considered 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; well-implemented,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; because &quot;the correct-conterfactualness&quot; concern the alledged turing 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; emulability
</em><br />
<em class="quotelev3">&gt; &gt; &gt; of the correct implemention (by construction) of the brain by the UTM.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 	OK, so you think the computation is implemented in this case.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I believe, from what Jacques says below, that he also believes that
</em><br />
<em class="quotelev1">&gt; the computation is implemented in this case, and that the addition of
</em><br />
<em class="quotelev1">&gt; the repair circuit (or demon, as Marchal has it) would make the
</em><br />
<em class="quotelev1">&gt; system conscious.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; So your &quot;correct implementation&quot; whatever it is, as far as it is 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Turing-emulable,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; will fall in the Maudlin's trap, I think.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; MORAL : You cannot associate consciousness to the physical activity 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; supporting
</em><br />
<em class="quotelev3">&gt; &gt; &gt; a computation. (i.e. NOT SUP-PHYS)
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; 	I think the key word here is 'activity'.
</em><br />
<em class="quotelev2">&gt; &gt; 	I don't go around using the term 'SUP-PHYS', but it seems that
</em><br />
<em class="quotelev2">&gt; &gt; what you mean by it is not what I mean by physical computationalism.
</em><br />
<em class="quotelev2">&gt; &gt; 	Whether or not a computation is implemented depends on the laws of
</em><br />
<em class="quotelev2">&gt; &gt; physics and the initial conditions.  Equivalently, it depends on the laws
</em><br />
<em class="quotelev2">&gt; &gt; of physics and the history of the system over time.
</em><br />
<em class="quotelev2">&gt; &gt; 	It is clear that in the two cases you described, the initial
</em><br />
<em class="quotelev2">&gt; &gt; conditions are *different*, and the history of the system is different.
</em><br />
<em class="quotelev2">&gt; &gt; In the first example there was no 'demon', while in the second example
</em><br />
<em class="quotelev2">&gt; &gt; there is a 'demon' and it moves at the constant velocity of the system.
</em><br />
<em class="quotelev2">&gt; &gt; 	That's why the argument is a straw man.  Maybe (?) some people
</em><br />
<em class="quotelev2">&gt; &gt; once said that only objects that move in certain ways affect whether a
</em><br />
<em class="quotelev2">&gt; &gt; computation is implemented and Maudlin countered that, but I never said
</em><br />
<em class="quotelev2">&gt; &gt; anything like that.  For me a stationary object is still part of the
</em><br />
<em class="quotelev2">&gt; &gt; system and it's perfectly OK if the computation depends on the position
</em><br />
<em class="quotelev2">&gt; &gt; and properties of that object.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I think this is a logical answer, that the system with a repair circuit
</em><br />
<em class="quotelev1">&gt; would have different properties than a system without one, even if the
</em><br />
<em class="quotelev1">&gt; repair circuit is not activated.  Hence we can say that the system is
</em><br />
<em class="quotelev1">&gt; conscious with repair circuit and unconscious without, and not contradict
</em><br />
<em class="quotelev1">&gt; outself.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Maudlin also accepts that this answer is possible, but he does offer some
</em><br />
<em class="quotelev1">&gt; critiques.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; To introduce them, let us sharpen the situation somewhat: we know that
</em><br />
<em class="quotelev1">&gt; the repair circuit is never activated.  Let us suppose that it is a rather
</em><br />
<em class="quotelev1">&gt; complicated circuit involving a robot which halts the TM, takes it
</em><br />
<em class="quotelev1">&gt; apart, repairs the machine, puts it back together, and allows it to
</em><br />
<em class="quotelev1">&gt; continue to run.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Now Jacques has agreed, I think, that the existence of consciousness
</em><br />
<em class="quotelev1">&gt; between t1 and t2 depends on the existence of this robot.  If the robot
</em><br />
<em class="quotelev1">&gt; exists and can function properly, then the TM is conscious.  If the robot
</em><br />
<em class="quotelev1">&gt; does not exist or cannot function, then the TM is unconscious.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The problem is that we can make the presence of consciousness in this
</em><br />
<em class="quotelev1">&gt; machine depend on some far-removed events.  For example, suppose that in
</em><br />
<em class="quotelev1">&gt; order to fix the machine the robot would have to order some new part.
</em><br />
<em class="quotelev1">&gt; Now suppose that, all the way around the world, there is a catastrophe
</em><br />
<em class="quotelev1">&gt; which makes the new part unavailable.  The robot would be unable to
</em><br />
<em class="quotelev1">&gt; complete his repairs, hence the machine becomes unconscious.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;It is no different from the usual case of implementation.  The
<br />
above argument is similar to the Chinese room argument.  If I am
<br />
corresponding by paper mail with some guy in Tibet and we take turns
<br />
manipulating some symbols a computation can be implemented.
<br />
<br /><em class="quotelev1">&gt; Again, remember that the robot is never actually activated during this
</em><br />
<em class="quotelev1">&gt; time interval.  So intuitively it is hard to understand why an event
</em><br />
<em class="quotelev1">&gt; happening on the other side of the world would affect the consciousness
</em><br />
<em class="quotelev1">&gt; here and now of the machine.  But that is the position which we appear
</em><br />
<em class="quotelev1">&gt; to be forced to if we take this path.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And I might also be corresponding with some guy in Africa.  I send
<br />
it to this guy only for certain choices of the symbols.  Suppose he dies
<br />
and I don't know it.  If so the computation will no longer be implemented
<br />
even if those symbols never occur in this run.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;All extremely standard stuff.
<br />
<br /><em class="quotelev1">&gt; Here is what Maudlin says:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; &quot;The modern picture of brain function rests primarily on the notion
</em><br />
<em class="quotelev1">&gt; of neural activity.  The essential structure of mentation seems to be
</em><br />
<em class="quotelev1">&gt; founded in patterns of neural firings.  Because those firings can be
</em><br />
<em class="quotelev1">&gt; analyzed as carrying information, the brain has come to be considered
</em><br />
<em class="quotelev1">&gt; as an information processor.  So let us suppose that some time in
</em><br />
<em class="quotelev1">&gt; the future the electro-encephalograph is so perfected that it is
</em><br />
<em class="quotelev1">&gt; capable of recording the firing of every single neuron in the brain.
</em><br />
<em class="quotelev1">&gt; Suppose that researchers take two different surveys of a brain which
</em><br />
<em class="quotelev1">&gt; match exactly: the very same neurons fire at exactly the same rate
</em><br />
<em class="quotelev1">&gt; and in exactly the same pattern through a given period.  They infer
</em><br />
<em class="quotelev1">&gt; (as surely they should!) that the brain supported the same occurrent
</em><br />
<em class="quotelev1">&gt; conscious state through the two periods.  But the computationalist now
</em><br />
<em class="quotelev1">&gt; must raise a doubt.  Perhaps some synaptic connection has been severed
</em><br />
<em class="quotelev1">&gt; in the interim.  Not a synaptic connection of any of the neurons which
</em><br />
<em class="quotelev1">&gt; actually fired during either period, or which was in any way involved
</em><br />
<em class="quotelev1">&gt; in the activity recorded by the encephalograph.  Still, such a change in
</em><br />
<em class="quotelev1">&gt; connection will affect the counterfactuals true of the brain, and so can
</em><br />
<em class="quotelev1">&gt; affect the subjective state of awareness.  Indeed, the computationalist
</em><br />
<em class="quotelev1">&gt; will have to maintain that perhaps the person in question was conscious
</em><br />
<em class="quotelev1">&gt; through the first episode but not conscious at all through the second.
</em><br />
<em class="quotelev1">&gt; I admit to a great deal of mystification about the connection between mind
</em><br />
<em class="quotelev1">&gt; and body, but I see no reason to endorse such possibilities that directly
</em><br />
<em class="quotelev1">&gt; contradict all that we do know about brain process and experience.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;He's not making much sense if he's saying that we know that
<br />
consciousness is present in such a case!  (BTW for it to be absent, as I
<br />
explained in a previous post, a large part of the brain would have to be
<br />
affected simultaneously.)
<br />
<br /><em class="quotelev1">&gt; &quot;Whether the reason is enshrined in the supervenience thesis or not, our
</em><br />
<em class="quotelev1">&gt; general picture of the relation between physical and mental reality firmly
</em><br />
<em class="quotelev1">&gt; grounds the intuition that Olympia's [Olympia is Maudlin's name for his
</em><br />
<em class="quotelev1">&gt; pseudo-conscious TM - Hal] experience cannot be changed by the presence
</em><br />
<em class="quotelev1">&gt; or absence of the second set of blocks [these are blocks which interrupt
</em><br />
<em class="quotelev1">&gt; the operation of an extra circuit, like the repair circuit above - Hal].
</em><br />
<em class="quotelev1">&gt; These intuitions are not sacrosanct, but the computationalist especially
</em><br />
<em class="quotelev1">&gt; abandons them at his own risk.  For similar intuitions are often appealed
</em><br />
<em class="quotelev1">&gt; to in defending the appropriateness of computational analogies in the
</em><br />
<em class="quotelev1">&gt; first place.  One first step in arguments aimed at inducing assent to
</em><br />
<em class="quotelev1">&gt; the possibility of computers that can think, or feel, or intend, is
</em><br />
<em class="quotelev1">&gt; to imagine that some sort of prosthetic human neuron made of silicon
</em><br />
<em class="quotelev1">&gt; has been invented.  We are then to imagine slowly replacing some poor
</em><br />
<em class="quotelev1">&gt; sap's brain bit by bit until at last we have a silicon brain that, our
</em><br />
<em class="quotelev1">&gt; intuitions should inform us, can do all of the mental and intensional
</em><br />
<em class="quotelev1">&gt; work of the original.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; &quot;This is as yet a far cry from showing that anything has mental properties
</em><br />
<em class="quotelev1">&gt; in virtue of its computational structure, but it is supposed to break
</em><br />
<em class="quotelev1">&gt; down parochial species-chauvinistic views about there being any deep
</em><br />
<em class="quotelev1">&gt; connection between mentality and organic chemistry.  But the thought
</em><br />
<em class="quotelev1">&gt; experiment rests on a tacit appeal to supervenience.  How could it
</em><br />
<em class="quotelev1">&gt; matter, one asks, whether the electrical impulses are carried by neurons
</em><br />
<em class="quotelev1">&gt; or by doped silicon?  The implication is that mentality supervenes
</em><br />
<em class="quotelev1">&gt; only on the pattern of electrical or electrochemical activity.  If the
</em><br />
<em class="quotelev1">&gt; computationalist now must assert that the presence or absence of a piece
</em><br />
<em class="quotelev1">&gt; of metal hanging untouched and inert in the midst of silent, frozen
</em><br />
<em class="quotelev1">&gt; machinery can make the difference between being conscious and not, who
</em><br />
<em class="quotelev1">&gt; knows what enormous changes in psychical state may result from replacing
</em><br />
<em class="quotelev1">&gt; axons and dendrites with little copper wires?  Should the computationalist
</em><br />
<em class="quotelev1">&gt; reject the extremely general intuitions at play in assessing Olympia's
</em><br />
<em class="quotelev1">&gt; case, no means of judging the plausibility or implausibility of any
</em><br />
<em class="quotelev1">&gt; theory of mind seems to remain.&quot;
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;That's simply and totally a false statement on his part.  The
<br />
computationalist has decided what seems important, such as the
<br />
counterfactual stucture, and has no problem believing that unless the
<br />
copper wires support a different counterfactual structure they would
<br />
implement the same computation.  There is no instability with respect to
<br />
tiny changes as he alleges.
<br />
<br /><em class="quotelev1">&gt; Or, in my example, if a factory fire in India can affect whether a system
</em><br />
<em class="quotelev1">&gt; here and now is conscious, you are moving into a realm where intuitions
</em><br />
<em class="quotelev1">&gt; about consciousness become highly suspect.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;'Here and now' is not relevant to the issue.  Physics is local but
<br />
the effects of a change propagate.  An implementation does not take place
<br />
at a point in spacetime, but depends on an extended stucture.
<br />
<br />From: Marchal &lt;marchal.domain.name.hidden&gt;
<br />
<em class="quotelev1">&gt;Jacques M Mallah did indeed accept that consciousness will rely on the 
</em><br />
<em class="quotelev1">&gt;presence or absence of inactive piece, but this will put arbitrariness
</em><br />
<em class="quotelev1">&gt;in any notion of physical instantiation of a computation, in the very
</em><br />
<em class="quotelev1">&gt;opposite direction of what Turing-mechanism, or computationalisme is.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;No.  First of all I never said that it depends on an inactive 
<br />
piece; I just said that inactivity does not disqualify that piece.  As
<br />
pointed out above the piece would likely not be inactive since it would
<br />
have to perform the computation to verify the run.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;As for &quot;arbritrariness&quot;, I don't know what you're smoking but I
<br />
*don't* see that happenning *AT ALL* in this example.  You have said
<br />
nothing to even *try* to justify such a statement.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- - - - - - -
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Jacques Mallah (jqm1584.domain.name.hidden)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Graduate Student / Many Worlder / Devil's Advocate
<br />
&quot;I know what no one else knows&quot; - 'Runaway Train', Soul Asylum
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My URL: <a href="http://pages.nyu.edu/~jqm1584/">http://pages.nyu.edu/~jqm1584/</a>
<br />
<span id="received"><dfn>Received on</dfn> Sun Jul 18 1999 - 16:04:56 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start959">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="0960.html" title="Next message in the list">Russell Standish: "Re: Ramanujan [was:  Raymond Smullyan]"</a></li>
<li><dfn>Previous message</dfn>: <a href="0958.html" title="Previous message in the list">Jacques M Mallah: "Re: minimal theory of consciousness"</a></li>
<li><dfn>In reply to</dfn>: <a href="0946.html" title="Message to which this message replies">hal.domain.name.hidden: "Re:implementation"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="0955.html" title="Next message in this discussion thread">Marchal: "Re:implementation"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg959" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg959" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg959" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg959" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
