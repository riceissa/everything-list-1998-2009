<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: need for anthropic reasoning from Jacques Mallah on 2001-02-20 (everything)</title>
<meta name="Author" content="Jacques Mallah (jackmallah.domain.name.hidden)" />
<meta name="Subject" content="Re: need for anthropic reasoning" />
<meta name="Date" content="2001-02-20" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: need for anthropic reasoning</h1>
<!-- received="Tue Feb 20 14:48:46 2001" -->
<!-- isoreceived="20010220224846" -->
<!-- sent="Tue, 20 Feb 2001 16:52:10 -0500" -->
<!-- isosent="20010220215210" -->
<!-- name="Jacques Mallah" -->
<!-- email="jackmallah.domain.name.hidden" -->
<!-- subject="Re: need for anthropic reasoning" -->
<!-- id="F104I8NFr9oD6XMLDth0001b49a.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="need for anthropic reasoning" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start2500" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="2501.html" accesskey="d" title="Russell Standish: &quot;Re: need for anthropic reasoning&quot;">Next message</a> ]
[ <a href="2499.html" title="George Levy: &quot;Re: on formally describable universes and measures&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="2501.html" accesskey="t" title="Russell Standish: &quot;Re: need for anthropic reasoning&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg2500" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg2500" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg2500" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg2500" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Jacques Mallah &lt;<a href="mailto:jackmallah.domain.name.hidden?Subject=Re%3A%20need%20for%20anthropic%20reasoning">jackmallah.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 20 Feb 2001 16:52:10 -0500</span><br />
</address>
<br />
<em class="quotelev1">&gt;From: Wei Dai &lt;weidai.domain.name.hidden&gt;
</em><br />
<em class="quotelev1">&gt;On Fri, Feb 16, 2001 at 10:22:35PM -0500, Jacques Mallah wrote:
</em><br />
<em class="quotelev2">&gt; &gt;     Any reasonable goal will, like social welfare, involve a function of 
</em><br />
<em class="quotelev1">&gt;the (unnormalized) measure distribution of conscious thoughts.  What else 
</em><br />
<em class="quotelev1">&gt;would social welfare mean?  For example, it could be to maximize the number 
</em><br />
<em class="quotelev1">&gt;of thoughts with a &quot;happiness&quot; property greater than &quot;life sucks&quot;.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;My current position is that one can care about any property of the entire 
</em><br />
<em class="quotelev1">&gt;structure of computation. Beyond that there are no reasonable or 
</em><br />
<em class="quotelev1">&gt;unreasonable goals.  One can have goals that do not distinguish between 
</em><br />
<em class="quotelev1">&gt;conscious or unconscious computations, or goals that treat conscious 
</em><br />
<em class="quotelev1">&gt;thoughts in emulated worlds differently from conscious thoughts in &quot;real&quot; 
</em><br />
<em class="quotelev1">&gt;worlds (i.e., in the same level of emulation as the goal-holders). None of 
</em><br />
<em class="quotelev1">&gt;these can be said to be unreasonable, in the sense that they are not 
</em><br />
<em class="quotelev1">&gt;ill-defined or obviously self-defeating or contradictory.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;I disagree on two counts.  First, I don't consider self-consistency to 
<br />
be the only requirement to call something a reasonable goal.  To be honest, 
<br />
I consider a goal reasonable only if it is not too different from my own 
<br />
goals.  It is only this type of goal that I am interested in.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Second, there is no way of knowing whether you are in a so called &quot;real 
<br />
world&quot; or in a &quot;virtual world&quot;.  So if I don't care about &quot;virtual&quot; people, 
<br />
I don't even know whether or not I care about myself.  That doesn't seem 
<br />
reasonable to me.
<br />
<br /><em class="quotelev1">&gt;In the end, evolution decides what kinds of goals are more popular within 
</em><br />
<em class="quotelev1">&gt;the structure of computation, but I don't think they will only involve 
</em><br />
<em class="quotelev1">&gt;functions on the measure distribution of conscious thoughts. For example, 
</em><br />
<em class="quotelev1">&gt;caring about thoughts that arise in emulations as if they are real (in the 
</em><br />
<em class="quotelev1">&gt;sense defined above) is not likely to be adaptive, but the distinction 
</em><br />
<em class="quotelev1">&gt;between emulated thoughts and real thoughts can't be captured in a function 
</em><br />
<em class="quotelev1">&gt;on the measure distribution of conscious thoughts.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&quot;Evolution&quot; is just the process that leads to the measure distribution.  
<br />
(Conversely, those who don't believe in an absolute measure distribution 
<br />
have no reason to expect Darwin to appear in their world to have been 
<br />
correct.)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Also, I disagree that caring about others (regardless of who they are) 
<br />
is not likely to be &quot;popular&quot;.  In my speculation, it's likely to occur in 
<br />
intelligent species that divide into groups, and then merge back into one 
<br />
group peacefully.
<br />
<br /><em class="quotelev2">&gt; &gt;     So you also bring in measure that way.  By the way, this is a bad 
</em><br />
<em class="quotelev1">&gt;idea: if the simulations are too perfect, they will give rise to conscious 
</em><br />
<em class="quotelev1">&gt;thoughts of their own!  So, you should be careful with it.  The very act of 
</em><br />
<em class="quotelev1">&gt;using the oracle could create a peculiar multiverse, when you just want to 
</em><br />
<em class="quotelev1">&gt;know if you should buy one can of veggies or two.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;The oracle was not meant to be a realistic example, just to illustrate my 
</em><br />
<em class="quotelev1">&gt;proposed decision procedure. However to answer your objection, the oracle 
</em><br />
<em class="quotelev1">&gt;could be programmed to ignore conscious thoughts that arise out of its 
</em><br />
<em class="quotelev1">&gt;internal computations (i.e., not account for them in its value function) 
</em><br />
<em class="quotelev1">&gt;and this would be a value judgement that can't be challenged on purely 
</em><br />
<em class="quotelev1">&gt;objective grounds.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;I've already pointed out a problem with that.  Let me add that your 
<br />
solution is also a rather boring solution to what could be an interesting 
<br />
problem, for those who do care about &quot;virtual&quot; guys (and have the computer 
<br />
resources).
<br />
<br /><em class="quotelev2">&gt; &gt;     Decision theory is not exactly the same as anthropic reasoning.  In 
</em><br />
<em class="quotelev1">&gt;decision theory, you want to do something to maximize some utility 
</em><br />
<em class="quotelev1">&gt;function.
</em><br />
<em class="quotelev2">&gt; &gt;     By contrast, anthropic reasoning is used when you want to find out 
</em><br />
<em class="quotelev1">&gt;some information.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Anthropic reasoning can't exist apart from a decision theory, otherwise 
</em><br />
<em class="quotelev1">&gt;there is no constraint on what reasoning process you can use. You might as 
</em><br />
<em class="quotelev1">&gt;well believe anything if it has no effect on your actions.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;I find that a very strange statement, especially coming from you.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;First, I (and other people) value knowledge as an end in itself.  Even 
<br />
if I were unable to take other actions, I would seek knowledge.  (You might 
<br />
argue that it's still an action, but clearly it's the *outcome* of this 
<br />
action that anthropic reasoning will affect, not the decision to take the 
<br />
action.)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Further, I do not believe that even in practice my motivation for 
<br />
studying the AUH (or much science) is really so as to make decisions about 
<br />
what actions to take; it is pretty much just out of curiousity.  One so 
<br />
motivated could well say &quot;you might as well do anything, if it has no effect 
<br />
on your knowledge&quot;.  (But you can't believe just anything, since you want to 
<br />
avoid errors in your knowledge.)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Secondly, it well known that you believe a static string of bits could 
<br />
be conscious.  Such a hypothetical observer would, by definition, be unable 
<br />
to take any actions.  (Including thinking, but he would &quot;have one thought 
<br />
stuck in his head&quot;.)
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- - - - - - -
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Jacques Mallah (jackmallah.domain.name.hidden)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Physicist  /  Many Worlder  /  Devil's Advocate
<br />
&quot;I know what no one else knows&quot; - 'Runaway Train', Soul Asylum
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My URL: <a href="http://hammer.prohosting.com/~mathmind/">http://hammer.prohosting.com/~mathmind/</a>
<br />
_________________________________________________________________
<br />
Get your FREE download of MSN Explorer at <a href="http://explorer.msn.com">http://explorer.msn.com</a>
<br />
<span id="received"><dfn>Received on</dfn> Tue Feb 20 2001 - 14:48:46 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start2500">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="2501.html" title="Next message in the list">Russell Standish: "Re: need for anthropic reasoning"</a></li>
<li><dfn>Previous message</dfn>: <a href="2499.html" title="Previous message in the list">George Levy: "Re: on formally describable universes and measures"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="2501.html" title="Next message in this discussion thread">Russell Standish: "Re: need for anthropic reasoning"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="2501.html" title="Message sent in reply to this message">Russell Standish: "Re: need for anthropic reasoning"</a></li>
<li><dfn>Reply</dfn>: <a href="2512.html" title="Message sent in reply to this message">Wei Dai: "Re: need for anthropic reasoning"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="2520.html" title="Message sent in reply to this message">Jacques Mallah: "Re: need for anthropic reasoning"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="2521.html" title="Message sent in reply to this message">Jacques Mallah: "Re: need for anthropic reasoning"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg2500" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg2500" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg2500" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg2500" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:07 PST
</em></small></p>
</body>
</html>
