<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Fwd: Implementation/Relativity from Russell Standish on 1999-07-27 (everything)</title>
<meta name="Author" content="Russell Standish (R.Standish.domain.name.hidden)" />
<meta name="Subject" content="Re: Fwd: Implementation/Relativity" />
<meta name="Date" content="1999-07-27" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Fwd: Implementation/Relativity</h1>
<!-- received="Tue Jul 27 18:01:00 1999" -->
<!-- isoreceived="19990728010100" -->
<!-- sent="Wed, 28 Jul 1999 11:01:48 +1000 (EST)" -->
<!-- isosent="19990728010148" -->
<!-- name="Russell Standish" -->
<!-- email="R.Standish.domain.name.hidden" -->
<!-- subject="Re: Fwd: Implementation/Relativity" -->
<!-- id="199907280101.LAA08266.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="e65644bc.24cf8de4.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start1016" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1017.html" accesskey="d" title="Hans Moravec: &quot;Re: Implementation&quot;">Next message</a> ]
[ <a href="1015.html" title="Russell Standish: &quot;Re: Implementation&quot;">Previous message</a> ]
[ <a href="1012.html" title="GSLevy.domain.name.hidden: &quot;Fwd: Implementation/Relativity&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1018.html" accesskey="t" title="Hans Moravec: &quot;Re: Fwd: Implementation/Relativity&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1016" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1016" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1016" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1016" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Russell Standish &lt;<a href="mailto:R.Standish.domain.name.hidden?Subject=Re%3A%20Fwd%3A%20Implementation%2FRelativity">R.Standish.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Wed, 28 Jul 1999 11:01:48 +1000 (EST)</span><br />
</address>
<br />
<em class="quotelev1">&gt; Hans writes
</em><br />
<em class="quotelev3">&gt; &gt;&gt;
</em><br />
<em class="quotelev1">&gt; Russell Standish &lt;R.Standish.domain.name.hidden&gt;:
</em><br />
<em class="quotelev2">&gt; &gt; ... However, it is always possible to _artificially_ construct a
</em><br />
<em class="quotelev2">&gt; &gt; system to pass the Turing test that isn't concious.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Balderdash!&gt;&gt;
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Hans is very succint so it's not clear if his deprecation is about building a 
</em><br />
<em class="quotelev1">&gt; Turing machine that can pass the Turing test or a Turing machine that is 
</em><br />
<em class="quotelev1">&gt; conscious or both of the above. So I may or may not agree with him.
</em><br />
<br />I clarified in the previous email that I meant &quot;to pass a particular
<br />
Turing test in which one knows all the questions beforehand&quot;. This is
<br />
the case of the Olympia story. Sorry for the confusion.
<br />
<br /><br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; A lot of discussion has been made about consciousness as if it was an 
</em><br />
<em class="quotelev1">&gt; objective, absolute quantity. And yet the only way to measure consciousness 
</em><br />
<em class="quotelev1">&gt; is by means of a relative test: the Turing test. Basically this test COMPARES 
</em><br />
<em class="quotelev1">&gt; the performance of a machine to a human. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I think that the only way to meaningfully &quot;measure&quot; consciousness is by means 
</em><br />
<em class="quotelev1">&gt; of a Turing test. So by definition if a machine passes the Turing test then 
</em><br />
<em class="quotelev1">&gt; it is conscious. If it doesn't then it isn't. It is understood that the 
</em><br />
<em class="quotelev1">&gt; Turing test will not be a superficial examination, but a thorough evaluation 
</em><br />
<em class="quotelev1">&gt; evolving measuring intellectual as well as emotional (even irrational) 
</em><br />
<em class="quotelev1">&gt; responses to a wide variety of situations. If the machine behaves like a 
</em><br />
<em class="quotelev1">&gt; human, then it should be entitled to all human rights under the law. If it 
</em><br />
<em class="quotelev1">&gt; behaves partially as a human, say in the intellectual domain but not in the 
</em><br />
<em class="quotelev1">&gt; emotional one, then, in relativistic terms, it differs from the human in that 
</em><br />
<em class="quotelev1">&gt; respect. Its consciousness STILL EXISTS BUT IS DIFFERENT from the human. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br />I demur from this slightly. Each and every one of us experiences
<br />
directly our own conciousness. We do not perform a Turing test on
<br />
ourselves to decide whether we're concious. However, the only way to
<br />
ascribe conciousness to external objects is to perform a Turing
<br />
test. i.e. we must ask &quot;Is our conciousness a good model for the
<br />
proerties of this external object?&quot;. It is clear that like all models,
<br />
it can be an incorrect description. I think Jacques is correct in
<br />
saying that the Turing test is neither necessary or sufficient - it is
<br />
simply the best we have. We have discussed a number of scenarios
<br />
whereby being too thorough in an investigation will reveal a concious
<br />
object as nonconcious.
<br />
<br /><em class="quotelev1">&gt; Similarly, a humans twin pretending to be the other twin, may not be capable 
</em><br />
<em class="quotelev1">&gt; of passing a Turing test aimed at finding out who he really is. This only 
</em><br />
<em class="quotelev1">&gt; proves that THE TWINS HAVE DIFFERENT CONSCIOUSNESS UNDER THIS PARTICULAR 
</em><br />
<em class="quotelev1">&gt; TURING TEST.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Now the kicker!. Had the Turing test not be capable of distinguishing the 
</em><br />
<em class="quotelev1">&gt; twin from his sibling, then UNDER THIS TURING TEST, THE TWINS WOULD HAVE THE 
</em><br />
<em class="quotelev1">&gt; SAME - IDENTICAL CONSCIOUSNESS!!! They would be the same person! Is this a 
</em><br />
<em class="quotelev1">&gt; paradox? Not at all. It is the same kind of situation generated when two 
</em><br />
<em class="quotelev1">&gt; persons, one in motion with respect to the other measure the velocity of an 
</em><br />
<em class="quotelev1">&gt; arbitrary object. They conclude that the object is animated with a different 
</em><br />
<em class="quotelev1">&gt; velocity with respect to their own frame of reference. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Thus a given person/machine will have a different consciousness depending on 
</em><br />
<em class="quotelev1">&gt; who is doing the observing. The &quot;observer&quot; could be a Turing test as well as 
</em><br />
<em class="quotelev1">&gt; a full fledged human, equipped with his own consciousness. The feeling of 
</em><br />
<em class="quotelev1">&gt; **I** is the self observing the self in an infinite recursion loop.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Thus, I propose that consciousness is a full fledged relativistic quantity. 
</em><br />
<em class="quotelev1">&gt; As such I must define how to specify its frame of reference. The frames of 
</em><br />
<em class="quotelev1">&gt; reference consists of information: That contained in the mind of the observed 
</em><br />
<em class="quotelev1">&gt; object and that contained in the mind of the observer. The information of 
</em><br />
<em class="quotelev1">&gt; interest is the mutual information which is the the difference between the 
</em><br />
<em class="quotelev1">&gt; two.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I would like to formalize the argument by comparing the information contained 
</em><br />
<em class="quotelev1">&gt; in the mind and in Turing tests to information constained in axiomatic 
</em><br />
<em class="quotelev1">&gt; mathematical systems. The full power of Goedel's incompleteness theorems 
</em><br />
<em class="quotelev1">&gt; could then be brought to bear. Some &quot;truth&quot; may not be provable within the 
</em><br />
<em class="quotelev1">&gt; system, similarly, the twins may not be distinguishable by a given Turing 
</em><br />
<em class="quotelev1">&gt; test and a machine may &quot;appear&quot; to be human, simply because the observing 
</em><br />
<em class="quotelev1">&gt; apparatus (human or test) does not have the power to distinguish it from a 
</em><br />
<em class="quotelev1">&gt; human.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Some of you may argue that even if a test is not capable of distinguishing 
</em><br />
<em class="quotelev1">&gt; between two consciousness, these consciousness have an objective, absolute 
</em><br />
<em class="quotelev1">&gt; reality. There is no way, however, to prove such an assertion independently 
</em><br />
<em class="quotelev1">&gt; of the Turing test process.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Wish me a good vacation!  :-)
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; George
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; --part1_e65644bc.24cf8de4_boundary
</em><br />
<em class="quotelev1">&gt; Content-Type: message/rfc822
</em><br />
<em class="quotelev1">&gt; Content-Disposition: inline
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Return-Path: &lt;everything-list-request.domain.name.hidden&gt;
</em><br />
<em class="quotelev1">&gt; Received: from  aol.com (rly-zd05.mail.aol.com [172.31.33.229]) by
</em><br />
<em class="quotelev1">&gt; 	air-zd04.mx.aol.com (v60.18) with ESMTP; Tue, 27 Jul 1999 14:24:49
</em><br />
<em class="quotelev1">&gt; 	2000
</em><br />
<em class="quotelev1">&gt; Received: from  mx1.eskimo.com (mx1.eskimo.com [204.122.16.48]) by
</em><br />
<em class="quotelev1">&gt; 	rly-zd05.mx.aol.com (v60.18) with ESMTP; Tue, 27 Jul 1999 14:24:40
</em><br />
<em class="quotelev1">&gt; 	-0400
</em><br />
<em class="quotelev1">&gt; Received: (from smartlst.domain.name.hidden)
</em><br />
<em class="quotelev1">&gt; 	by mx1.eskimo.com (8.9.1a/8.8.8) id LAA04227;
</em><br />
<em class="quotelev1">&gt; 	Tue, 27 Jul 1999 11:21:16 -0700
</em><br />
<em class="quotelev1">&gt; Resent-Date: Tue, 27 Jul 1999 11:21:16 -0700
</em><br />
<em class="quotelev1">&gt; Message-Id: &lt;199907271820.UAA09542.domain.name.hidden&gt;
</em><br />
<em class="quotelev1">&gt; Subject: Re: Implementation
</em><br />
<em class="quotelev1">&gt; Date: Mar, 27 Jul 99 20:17:57 +0100
</em><br />
<em class="quotelev1">&gt; x-sender: marchal.domain.name.hidden
</em><br />
<em class="quotelev1">&gt; x-mailer: Claris Emailer 1.1
</em><br />
<em class="quotelev1">&gt; From: Marchal &lt;marchal.domain.name.hidden&gt;
</em><br />
<em class="quotelev1">&gt; To: &lt;everything-list.domain.name.hidden&gt;
</em><br />
<em class="quotelev1">&gt; Mime-Version: 1.0
</em><br />
<em class="quotelev1">&gt; Content-Type: text/plain; charset=&quot;US-ASCII&quot;
</em><br />
<em class="quotelev1">&gt; Resent-Message-ID: &lt;&quot;KKnug1.0.-11.RYVdt&quot;.domain.name.hidden&gt;
</em><br />
<em class="quotelev1">&gt; Resent-From: everything-list.domain.name.hidden
</em><br />
<em class="quotelev1">&gt; X-Mailing-List: &lt;everything-list.domain.name.hidden&gt; archive/latest/1007
</em><br />
<em class="quotelev1">&gt; X-Loop: everything-list.domain.name.hidden
</em><br />
<em class="quotelev1">&gt; Precedence: list
</em><br />
<em class="quotelev1">&gt; Resent-Sender: everything-list-request.domain.name.hidden
</em><br />
<em class="quotelev1">&gt; Content-Transfer-Encoding: 7bit
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I will make some comments on the last posts. But we are entering in 
</em><br />
<em class="quotelev1">&gt; very deep
</em><br />
<em class="quotelev1">&gt; waters and I would like to make general remarks. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I said it before, but I want
</em><br />
<em class="quotelev1">&gt; repeat it here. One of my main goal is to understand what is &quot;the
</em><br />
<em class="quotelev1">&gt; physical&quot; and where does it comes from. And like Wheeler I don't think 
</em><br />
<em class="quotelev1">&gt; that this can be explain by physical laws. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; With Ockham razor there is no need of
</em><br />
<em class="quotelev1">&gt; the crackpot/Maudlin argument, the UD argument (PE-omega) is quasi-enough 
</em><br />
<em class="quotelev1">&gt; to convince oneself
</em><br />
<em class="quotelev1">&gt; that the 'universal part' of physics must be extract from computer 
</em><br />
<em class="quotelev1">&gt; science.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Note also that the 'reversal' is in both Tegmark and Schmidhuber (it 
</em><br />
<em class="quotelev1">&gt; seems to me), but they
</em><br />
<em class="quotelev1">&gt; haven't see the measure problem (do they ?), and they havent' put their 
</em><br />
<em class="quotelev1">&gt; methodology to its logical extreme.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Another general remark is that, in your post, I agree sometimes whith 
</em><br />
<em class="quotelev1">&gt; what you are saying until you jump to a conclusion which I don't 
</em><br />
<em class="quotelev1">&gt; understand.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; George Levy wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;Similarly, the insertion of the piece of wood in the computer must be done 
</em><br />
<em class="quotelev2">&gt; &gt;by 
</em><br />
<em class="quotelev2">&gt; &gt;someone. Let's call that someone Maudlin's demon.  Deciding what the right 
</em><br />
<em class="quotelev2">&gt; &gt;place and the right time is to make the wood irrelevent to the thinking 
</em><br />
<em class="quotelev2">&gt; &gt;process, in order to satisfy the counterfactual role that the wood must 
</em><br />
<em class="quotelev2">&gt; &gt;play, 
</em><br />
<em class="quotelev2">&gt; &gt;requires Maudlin's demon to think. Maudlin's demon then becomes part of the 
</em><br />
<em class="quotelev2">&gt; &gt;computer's consciousness just like the subject in the chinese room 
</em><br />
<em class="quotelev2">&gt; &gt;experiment 
</em><br />
<em class="quotelev2">&gt; &gt;becomes a cog in the chinese room ability to speak chinese.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; An interesting similar (although computationalist) move  has been made
</em><br />
<em class="quotelev1">&gt; by Eric Barnes &quot;The causal history of computational activity: Maudlin and
</em><br />
<em class="quotelev1">&gt; Olympia. (The journal of philosophy 1991, pp 304-316.) 
</em><br />
<em class="quotelev1">&gt; What is interesting for me is that Barnes'move forces him to pretend
</em><br />
<em class="quotelev1">&gt; having the ability to distinguish between being awake and being dreaming
</em><br />
<em class="quotelev1">&gt; (which I doubt), (which contredict also my theetetic self-referential
</em><br />
<em class="quotelev1">&gt; theory of knowledge where p is known when p is justified by the machine 
</em><br />
<em class="quotelev1">&gt; and true or just consistent).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; George Levy wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;In the end, I am a strong sceptic of both computationalism and physical 
</em><br />
<em class="quotelev2">&gt; &gt;supervenience. I believe that consciousness exists only in the eyes of the 
</em><br />
<em class="quotelev2">&gt; &gt;beholder, and is a relativistic property, based on the relativity of 
</em><br />
<em class="quotelev2">&gt; &gt;(mutual) 
</em><br />
<em class="quotelev2">&gt; &gt;information as defined by Claude Shannon.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I am definitely open to the idea that consciousness exists only in the 
</em><br />
<em class="quotelev1">&gt; eyes of the beholder, that it is a relativistic property, based on the
</em><br />
<em class="quotelev1">&gt; relativity of mutual information as defined by Claude Shannon, Kolmogorov,
</em><br />
<em class="quotelev1">&gt; and as used by Everett (but see also the paper of Adami and Cerf in the
</em><br />
<em class="quotelev1">&gt; quant-ph).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Hans Moravec wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;So, deterministic machines can have just as much free will as you or
</em><br />
<em class="quotelev2">&gt; &gt;I.  The key is that they don't know everything that's going on,
</em><br />
<em class="quotelev2">&gt; &gt;outside themselves or in, so often don't know what will happen next,
</em><br />
<em class="quotelev2">&gt; &gt;or how they will respond to it.  Many-worlds may provide an
</em><br />
<em class="quotelev2">&gt; &gt;interesting additional &quot;source&quot; of ignorance, but limitations on what
</em><br />
<em class="quotelev2">&gt; &gt;a finite process can model already provide sufficient ignorance for
</em><br />
<em class="quotelev2">&gt; &gt;free will even in a fully deterministic framework.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I agree. What MW or self-duplication adds is truly random uncertainty.
</em><br />
<em class="quotelev1">&gt; This is &quot;testify&quot; by quantum computers.
</em><br />
<em class="quotelev1">&gt; I don't think determinism is an &quot;effective&quot; problem for free-will,
</em><br />
<em class="quotelev1">&gt; nor do I think randomization can help in making free-will possible.
</em><br />
<em class="quotelev1">&gt; I think free-will is related with the boundary of self-knowledge.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Hal Finney wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;But more than one computation can be conscious, obviously.  It is
</em><br />
<em class="quotelev2">&gt; &gt;conceivable that the new computation, although different, is conscious
</em><br />
<em class="quotelev2">&gt; &gt;as well.  This is a possible escape from Maudlin's argument.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; [...]
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Are the content of consciousness different ? or the intensity are
</em><br />
<em class="quotelev1">&gt; different ? I'm not sure I understand.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; HF:
</em><br />
<em class="quotelev2">&gt; &gt;So it seems to me we need a new argument for why the computer sans
</em><br />
<em class="quotelev2">&gt; &gt;counterfactuals should not be considered conscious.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; [...]
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; It seems to me that a computer without counterfactuals is like
</em><br />
<em class="quotelev1">&gt; a doll, a teddy bear, or a sculpture.
</em><br />
<em class="quotelev1">&gt; Unlike Hans I don't understand what would it mean to ascribe them 
</em><br />
<em class="quotelev1">&gt; consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; HF:
</em><br />
<em class="quotelev2">&gt; &gt;One of the thins which is attractive about Wei's approach, as I understand
</em><br />
<em class="quotelev2">&gt; &gt;it, is that it does not try to answer the question of whether a given
</em><br />
<em class="quotelev2">&gt; &gt;system is conscious, at least not in yes-or-no terms.  Rather, it tries
</em><br />
<em class="quotelev2">&gt; &gt;to give a probability that a given system is conscious, and specifically
</em><br />
<em class="quotelev2">&gt; &gt;that it instantiates a particular consciousness, such as my own.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;This allows you to have such things as systems which are &quot;probably&quot;
</em><br />
<em class="quotelev2">&gt; &gt;conscious, or, in a sense, &quot;partially&quot; conscious (in the sense that
</em><br />
<em class="quotelev2">&gt; &gt;we can treat them as having a 10% chance of being conscious, say).
</em><br />
<em class="quotelev2">&gt; &gt;This interpretation makes most sense in the context of the Strong
</em><br />
<em class="quotelev2">&gt; &gt;Self-Selection Assumption (that we can consider our moments of experience
</em><br />
<em class="quotelev2">&gt; &gt;as randomly chosen from among all observer-moments).  The probabilities
</em><br />
<em class="quotelev2">&gt; &gt;assigned to consciousness serve as a weighting factor for how much they
</em><br />
<em class="quotelev2">&gt; &gt;contribute to the ensemble of all observer-moments.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I agree and I appreciate very much this way of seeing the things. It is
</em><br />
<em class="quotelev1">&gt; linked (from my humble understanding) to James Higgo's anthropic 
</em><br />
<em class="quotelev1">&gt; principle/occam-razor. This 'interpretation' along with comp leads to
</em><br />
<em class="quotelev1">&gt; a total reversal ....but in the relative way (I will not insist here).
</em><br />
<em class="quotelev1">&gt; I do link consciousness with machine's inference about their own possible
</em><br />
<em class="quotelev1">&gt; consistent extensions. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; David Seaman wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;This seems an excellent viewpoint, consciousness requires the freedom to
</em><br />
<em class="quotelev2">&gt; &gt;react to a reasonably wide range of circumstances in a way which is not
</em><br />
<em class="quotelev2">&gt; &gt;predictable to other observers.  So a single execution can never confirm or
</em><br />
<em class="quotelev2">&gt; &gt;deny consciousness however many times it is replayed.  But I'm not so sure
</em><br />
<em class="quotelev2">&gt; &gt;that a Turing machine cannot have free will.  I'd guess that the appearance
</em><br />
<em class="quotelev2">&gt; &gt;of free will can emerge from a sufficiently complex TM provided that the TM
</em><br />
<em class="quotelev2">&gt; &gt;exists in a suitably complex environment.  If a person built a machine
</em><br />
<em class="quotelev2">&gt; &gt;containing a TM it would be part of our MWI universe and the requirements
</em><br />
<em class="quotelev2">&gt; &gt;could be satisfied.  This would not be an isolated TM since it would be
</em><br />
<em class="quotelev2">&gt; &gt;simulated by and react to its environment, and any 'randomness' requirement
</em><br />
<em class="quotelev2">&gt; &gt;could actually involve a sensitivity to gravitons, photons, or quantum
</em><br />
<em class="quotelev2">&gt; &gt;interference.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;I tend to agree that a completely isolated TM is unlikely to have free will
</em><br />
<em class="quotelev2">&gt; &gt;or be conscious (and in any case it would be impossible to test it).  Of
</em><br />
<em class="quotelev2">&gt; &gt;course the program executed by an isolated TM may well be able to generate
</em><br />
<em class="quotelev2">&gt; &gt;a universe containing conscious subjects.  In the special case of an
</em><br />
<em class="quotelev2">&gt; &gt;isolated TM generating a universe which contains exactly one conscious
</em><br />
<em class="quotelev2">&gt; &gt;subject in a suitable environment it could loosely be said that the TM's
</em><br />
<em class="quotelev2">&gt; &gt;program is that conscious subject.  But this is different to saying that
</em><br />
<em class="quotelev2">&gt; &gt;the TM itself is conscious, and it would not be apparent from looking at
</em><br />
<em class="quotelev2">&gt; &gt;the TM that it was generating consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I agree in part. It is easy to build version of dreaming Olympia.
</em><br />
<em class="quotelev1">&gt; A dreaming machine would be, at least here and now, an isolated 
</em><br />
<em class="quotelev1">&gt; 'conscious'
</em><br />
<em class="quotelev1">&gt; (but not necessarily awake) machine.
</em><br />
<em class="quotelev1">&gt; I think an isolated 'conscious' machine cannot be isolate for ever for 
</em><br />
<em class="quotelev1">&gt; purely computational reasons.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Jacques Mallah wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;	Bruno, I think it is now abundently clear that Maudlin's paper
</em><br />
<em class="quotelev2">&gt; &gt;does not rule out physical computationalism, and other people on the list
</em><br />
<em class="quotelev2">&gt; &gt;have seen that as well.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Clear would be enough. Abundently clear is a little to much.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't understand what really means 'physical' in physical 
</em><br />
<em class="quotelev1">&gt; computationalism.
</em><br />
<em class="quotelev1">&gt; It is clear that we have not the same primitive elements.
</em><br />
<em class="quotelev1">&gt; I believe in numbers and number's dreams. Some dreams are deep and
</em><br />
<em class="quotelev1">&gt; partially sharable among UTMs, those are their relative realities.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I appreciate the everythinger's work on these questions, and I guess it
</em><br />
<em class="quotelev1">&gt; is not easy to abandon the physical supervenience thesis.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Russell Standish wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Chris, this is a well thought out reponse, and it persuades me that
</em><br />
<em class="quotelev3">&gt; &gt; &gt; the difference between conciousness and nonconciousness could be as
</em><br />
<em class="quotelev3">&gt; &gt; &gt; little as the &quot;inert block of wood&quot;, precisely because it is a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; physically different system. It actually reminds me of the quantum 2
</em><br />
<em class="quotelev3">&gt; &gt; &gt; split experiment. An interference pattern is seen, or not seen
</em><br />
<em class="quotelev3">&gt; &gt; &gt; according to whether a detector placed at one of the slits is switched
</em><br />
<em class="quotelev3">&gt; &gt; &gt; on or not.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; [...]
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 1) The great programmer dovetail also on the quantum turing machines...
</em><br />
<em class="quotelev1">&gt; 2) I think so. There is a deeper analogy between the computationalist's
</em><br />
<em class="quotelev1">&gt; counterfactuals and the quantum. This is linked to a paper by Hardegree
</em><br />
<em class="quotelev1">&gt; showing a formal similarity between a very natural definition of 'quantum
</em><br />
<em class="quotelev1">&gt; implication' and Stalnaker's logic of counterfactual and my own definition
</em><br />
<em class="quotelev1">&gt; of 'observation'. (ref. in my thesis), and the resulting arithmetical
</em><br />
<em class="quotelev1">&gt; &quot;quantum logic&quot;.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;Thinking about this some more, I realise this is exactly what is going
</em><br />
<em class="quotelev2">&gt; &gt;on. Consider Olympia from a MWI point of view. For the vast majority
</em><br />
<em class="quotelev2">&gt; &gt;of worlds containing Olympia, Karas (I believe that is what the
</em><br />
<em class="quotelev2">&gt; &gt;correcting machinery is called) is active, handling the
</em><br />
<em class="quotelev2">&gt; &gt;counterfactuals. Only on one world line (of measure zero!) is Karas
</em><br />
<em class="quotelev2">&gt; &gt;inactive, and Olympia is simply replaying the previously recorded
</em><br />
<em class="quotelev2">&gt; &gt;data.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Now consider what happens when Karas is turned off, or prevented from
</em><br />
<em class="quotelev2">&gt; &gt;operating. Then, in all world lines is Olympia simply a replay
</em><br />
<em class="quotelev2">&gt; &gt;device. From the MWI point of view, the simple inert piece of wood is
</em><br />
<em class="quotelev2">&gt; &gt;not so innocuous. It changes the systems dynamics completely.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; OK.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Now this has bearing on a supposition I have argued earlier - that
</em><br />
<em class="quotelev2">&gt; &gt;conciousness requires free will, and the only way to have free will is
</em><br />
<em class="quotelev2">&gt; &gt;via the MWI picture.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Not OK. See above. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;In this context, a Turing machine can never be
</em><br />
<em class="quotelev2">&gt; &gt;concious, because it follows a preprogrammed path, without free
</em><br />
<em class="quotelev2">&gt; &gt;will. Note this is not the same as saying comp is false, unless you
</em><br />
<em class="quotelev2">&gt; &gt;strictly define computers to be Turing machines. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I do. It is my working hypothesis.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;My suspicion is that
</em><br />
<em class="quotelev2">&gt; &gt;adding a genuine random number generator to the machine may be
</em><br />
<em class="quotelev2">&gt; &gt;sufficient to endow the architecture with free will, however, of
</em><br />
<em class="quotelev2">&gt; &gt;course the question is unresolved.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;What does this all mean for your thesis Bruno? Alas I didn't follow
</em><br />
<em class="quotelev2">&gt; &gt;your argument (not because it was written in French - which I have no
</em><br />
<em class="quotelev2">&gt; &gt;problem with, rather because I was not familiar with the modal logic
</em><br />
<em class="quotelev2">&gt; &gt;you employed, and haven't raised enough enthusiasm to follow up the
</em><br />
<em class="quotelev2">&gt; &gt;references). Could it be implying that you have too restrictive
</em><br />
<em class="quotelev2">&gt; &gt;definitions of both comp and sup-phys?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Church's Thesis is a vaccin against any restrictive interpretation
</em><br />
<em class="quotelev1">&gt; of comp.  Comp makes the unknown much bigger that we have ever thought.
</em><br />
<em class="quotelev1">&gt; Even if from the archimedian point of view there are only numbers 
</em><br />
<em class="quotelev1">&gt; relationships.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Quote from Bruno follows:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt;&gt; This seems rather magical to me. If only because, for a
</em><br />
<em class="quotelev3">&gt; &gt;&gt; computationalist,
</em><br />
<em class="quotelev3">&gt; &gt;&gt; the only role of the inert block (during the particular execution) is
</em><br />
<em class="quotelev3">&gt; &gt;&gt; to 
</em><br />
<em class="quotelev3">&gt; &gt;&gt; explain why the machine WOULD have give a correct answer in case the
</em><br />
<em class="quotelev3">&gt; &gt;&gt; inputs WOULD have been different.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; This mean that you don't associate consciousness with a particular
</em><br />
<em class="quotelev3">&gt; &gt;&gt; physical computation but with the entire set of possible computations.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; But that is exactly what I do ..., and what I mean by the abandon
</em><br />
<em class="quotelev3">&gt; &gt;&gt; of physical supervenience.
</em><br />
<em class="quotelev3">&gt; &gt;&gt; A singular brain's activity becomes an invention of the mind.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Could it mean that you are defining sup-phys to be supervenience on
</em><br />
<em class="quotelev2">&gt; &gt;the one track classical physics, rather than on the MWI style quantum
</em><br />
<em class="quotelev2">&gt; &gt;physics?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Most people in cognitive science do but I do not care about the level of
</em><br />
<em class="quotelev1">&gt; duplication.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt; I think that ANY sufficiently patient self-referentially correct
</em><br />
<em class="quotelev1">&gt; machines, either by introspection or by observation (or a mixture of 
</em><br />
<em class="quotelev1">&gt; both), will infer MWI-like physics (once observing below their level of
</em><br />
<em class="quotelev1">&gt;  duplication, for example).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Bruno
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; --part1_e65644bc.24cf8de4_boundary--
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br /><br /><br />----------------------------------------------------------------------------
<br />
Dr. Russell Standish            	Director
<br />
High Performance Computing Support Unit,
<br />
University of NSW			Phone 9385 6967
<br />
Sydney 2052				Fax   9385 6965
<br />
Australia                       	R.Standish.domain.name.hidden
<br />
Room 2075, Red Centre			<a href="http://parallel.hpc.unsw.edu.au/rks">http://parallel.hpc.unsw.edu.au/rks</a>
<br />
----------------------------------------------------------------------------
<br />
<span id="received"><dfn>Received on</dfn> Tue Jul 27 1999 - 18:01:00 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start1016">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1017.html" title="Next message in the list">Hans Moravec: "Re: Implementation"</a></li>
<li><dfn>Previous message</dfn>: <a href="1015.html" title="Previous message in the list">Russell Standish: "Re: Implementation"</a></li>
<li><dfn>In reply to</dfn>: <a href="1012.html" title="Message to which this message replies">GSLevy.domain.name.hidden: "Fwd: Implementation/Relativity"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1018.html" title="Next message in this discussion thread">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1016" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1016" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1016" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1016" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
