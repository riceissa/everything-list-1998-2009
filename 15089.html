<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: QTI &amp; euthanasia (brouillon) from Bruno Marchal on 2008-11-03 (everything)</title>
<meta name="Author" content="Bruno Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: QTI &amp; euthanasia (brouillon)" />
<meta name="Date" content="2008-11-03" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: QTI &amp; euthanasia (brouillon)</h1>
<!-- received="Mon Nov  3 06:23:49 2008" -->
<!-- isoreceived="20081103142349" -->
<!-- sent="Mon, 3 Nov 2008 12:22:25 +0100" -->
<!-- isosent="20081103112225" -->
<!-- name="Bruno Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: QTI &amp; euthanasia (brouillon)" -->
<!-- id="dab2b89a655b8ab52a6871858f5732ce.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="490EA929.7030900.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start15089" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="15090.html" accesskey="d" title="Jason Resch: &quot;Re: QTI &#0038; euthanasia (brouillon)&quot;">Next message</a> ]
[ <a href="15088.html" title="Brent Meeker: &quot;Re: QTI &#0038; euthanasia&quot;">Previous message</a> ]
[ <a href="15088.html" title="Brent Meeker: &quot;Re: QTI &#0038; euthanasia&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="15090.html" accesskey="t" title="Jason Resch: &quot;Re: QTI &#0038; euthanasia (brouillon)&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15089" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15089" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15089" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15089" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Bruno Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20QTI%20%26%20euthanasia%20(brouillon)">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon, 3 Nov 2008 12:22:25 +0100</span><br />
</address>
<br />
Le 03-nov.-08, à 08:32, Brent Meeker a écrit :
<br />
<br /><em class="quotelev1">&gt; I have reservations about #6:  Consciousness is a process, but  it
</em><br />
<em class="quotelev1">&gt; depends on a context.
</em><br />
<br />That is why I use the notion of generalized brain. I take into account 
<br />
the possible need of a context. The argument would break only if you 
<br />
stipulate that the context cannot be captured digitally, but this would 
<br />
make the generalized brain non turing emulable, and this would mean 
<br />
comp is false. Recall that my point is that comp implies something, not 
<br />
that comp is true.
<br />
<br /><br /><br /><em class="quotelev1">&gt;  In the argument as to whether a stone is a
</em><br />
<em class="quotelev1">&gt; computer, even a universal computer, the error is in ignoring that the
</em><br />
<em class="quotelev1">&gt; computation in a computer has an interpretation which the programmer
</em><br />
<em class="quotelev1">&gt; provides.
</em><br />
<br />I don't see the relevance of this concerning the step #6.
<br />
I have never written nor indeed believed that a stone can be a computer.
<br />
<br /><br /><em class="quotelev1">&gt;  If he can provide this interpretation to the processes within
</em><br />
<em class="quotelev1">&gt; a stone, then indeed it would be a computer; but in general he can't.
</em><br />
<br />I agree with this, but I don't see the relevance.
<br />
<br /><br /><em class="quotelev1">&gt;  I think consciousness is similar; it is a process but it only has an
</em><br />
<em class="quotelev1">&gt; interpretation as a *conscious* process within a context of perception
</em><br />
<em class="quotelev1">&gt; and action within a world.
</em><br />
<br />In step six, the context is taken into account. Your argument  will go 
<br />
through only if you think that the context is both needed integrally 
<br />
and is not turing emulable, But then comp is false.
<br />
Also consciousness makes sense only, strictly speaking, for the 
<br />
subject. If some direct access to a world was needed throughout, then 
<br />
even the experience of dream becomes impossible.
<br />
<br /><br /><em class="quotelev1">&gt; Which is why I think philosophical zombies
</em><br />
<em class="quotelev1">&gt; are impossible.
</em><br />
<br />If this were true, then the movie graph (step 8 without occam) would 
<br />
not been needed. Arithmetical truth is provably full of philosophical 
<br />
zombies if comp is true and step 8 false.
<br />
<br /><br /><br /><em class="quotelev1">&gt; But then, when you imagine reproducing someone's
</em><br />
<em class="quotelev1">&gt; consciousness, in a computer and simulating all the input/output, i.e.
</em><br />
<em class="quotelev1">&gt; all the context, then you have created a separate world in which there
</em><br />
<em class="quotelev1">&gt; is a consciousness in the context of *that* world.  But it doesn't
</em><br />
<em class="quotelev1">&gt; follow that it is a consciousness in this world.
</em><br />
<br />To accept this I have to assume &quot;I = the world&quot;, and that world is not 
<br />
turing-emulable. But then comp is false.
<br />
<br /><br /><br /><em class="quotelev1">&gt; The identification of
</em><br />
<em class="quotelev1">&gt; things that happen in the computer as &quot;He experiences this.&quot; depend on
</em><br />
<em class="quotelev1">&gt; our interpretation of the computer program.  There is no inherent,
</em><br />
<em class="quotelev1">&gt; ding-an-sich consciousness.
</em><br />
<br />Here I disagree. This would entail that if you beat a child in a way 
<br />
such that nobody knows, then the child does not suffer.
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Your step #6 can be saved by supposing that a robot is constructed so
</em><br />
<em class="quotelev1">&gt; that the duplicated consciousness lives in the context of our world, 
</em><br />
<em class="quotelev1">&gt; but
</em><br />
<em class="quotelev1">&gt; this does not support the extension to the UD in step #7.  To identify
</em><br />
<em class="quotelev1">&gt; some program the UD is generating as reproducing someone's 
</em><br />
<em class="quotelev1">&gt; consciousness
</em><br />
<em class="quotelev1">&gt; requires an interpretation.
</em><br />
<br />With comp the universal machine is the interpreter. Again you are 
<br />
telling me that comp is false.
<br />
<br /><br /><em class="quotelev1">&gt; But an interpretation is a mapping between
</em><br />
<em class="quotelev1">&gt; the program states and the real world states - so it presumes a real 
</em><br />
<em class="quotelev1">&gt; world.
</em><br />
<br />Then dreaming cannot be a conscious experience. But since the work of 
<br />
Laberge and Hearne, all brain physiologist accept this.
<br />
I am afraid you put something magical (non Turing emulable) in the 
<br />
world and in consciousness. This makes us non digital machine or 
<br />
entity.
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I have several problems with step #8.  What are consistent 1-histories?
</em><br />
<br />This is needed for the AUDA (arithmetical translation of the UDA). The 
<br />
movie graph just explain that comp makes it impossible to attach 
<br />
consciousness to the physical activity of the running UD. It explains 
<br />
why we don't have to run the UD. Digital machines cannot distinguish 
<br />
physical computations from arithmetical computations.
<br />
<br /><br /><em class="quotelev1">&gt; Can they be characterized without reference to nomological consistency?
</em><br />
<em class="quotelev1">&gt; The reduction to Platonia seems almost like a reduction argument 
</em><br />
<em class="quotelev1">&gt; against
</em><br />
<em class="quotelev1">&gt; comp.
</em><br />
<br />This is certainly possible, but up to now, nobody has been able to get 
<br />
a contradiction. In the seventies, some people pretend that I have 
<br />
refute comp by showing it entails many-worlds. At least since 
<br />
Everett-Feynman-Deutsch, people have abandon this idea (that many 
<br />
worlds = contradiction).
<br />
<br /><br /><br /><em class="quotelev1">&gt;  Except that comp was the assumption that one physical process can
</em><br />
<em class="quotelev1">&gt; be replaced by another that instantiates the same physical relations.
</em><br />
<br /><br />No, comp implicates the notion of &quot;me&quot; or of &quot;my consciousness&quot;. Comp 
<br />
is just the assumption that my consciousness is unchanged when my 
<br />
(generalized) brain is substituted by digital devices at some level of 
<br />
description.
<br />
<br /><br /><em class="quotelev1">&gt;  I
</em><br />
<em class="quotelev1">&gt; don't see how it follows from that there need not be an instantiation 
</em><br />
<em class="quotelev1">&gt; at
</em><br />
<em class="quotelev1">&gt; all and we can just assume that the timeless existence in Platonia is
</em><br />
<em class="quotelev1">&gt; equivalent.
</em><br />
<br />Well, it comes from the impossibility to attach consciopusness to the 
<br />
exclusively physical: that is the point of the movie graph argument 
<br />
(also entailed by Maudlin's Olympia argument).
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; You  write: &quot;...the appearance of physics must be recovered from some
</em><br />
<em class="quotelev1">&gt; point of views emerging from those propositions.&quot;  But how does is this
</em><br />
<em class="quotelev1">&gt; &quot;emergence&quot; work?  Isn't it like saying if I postulate an absolute 
</em><br />
<em class="quotelev1">&gt; whole
</em><br />
<em class="quotelev1">&gt; that includes all logically possible relations then this must include
</em><br />
<em class="quotelev1">&gt; the appearance of physics and all I need is the probability measure 
</em><br />
<em class="quotelev1">&gt; that
</em><br />
<em class="quotelev1">&gt; picks it out.  It's like Michaelangelo saying, &quot;This block of marble
</em><br />
<em class="quotelev1">&gt; contains a statue of David.  All I need is the measure that assigns 0 
</em><br />
<em class="quotelev1">&gt; to
</em><br />
<em class="quotelev1">&gt; the part that's not David and 1 to the part that is David.&quot;
</em><br />
<br /><br />To select effectively the statue of David, so that it becomes manifest 
<br />
relatively to his public, Michael Angelo has still to remove the zero 
<br />
part. This can be done by ... sculpting.
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; To be sure, do you understand the nuance between the following theses:
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; WEAK AI: some machines can behave as if their were conscious (but
</em><br />
<em class="quotelev2">&gt;&gt; could as well be zombies)
</em><br />
<em class="quotelev2">&gt;&gt; STRONG AI: some machines can be conscious
</em><br />
<em class="quotelev2">&gt;&gt; COMP: I am a machine
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; We have
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; COMP =&gt; STRONG AI =&gt; WEAK AI
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; WEAK does not imply STRONG AI which does not imply COMP. (it is not
</em><br />
<em class="quotelev2">&gt;&gt; because machine can be conscious that we are necessarily machine
</em><br />
<em class="quotelev2">&gt;&gt; ourself, of course with occam razor, STRONG AI go in the direction of
</em><br />
<em class="quotelev2">&gt;&gt; COMP).
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Does those nuances make sense? If not (1...8) does not, indeed, make
</em><br />
<em class="quotelev2">&gt;&gt; sense. You just don't believe in consciousness and/or person like in
</em><br />
<em class="quotelev2">&gt;&gt; the eliminative materialism of neuro-philosophers ( the Churchland,
</em><br />
<em class="quotelev2">&gt;&gt; amost Dennett in &quot;consciousness explained&quot;).
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev1">&gt; I think they make some good arguments.  I don't think that 
</em><br />
<em class="quotelev1">&gt; consciousness
</em><br />
<em class="quotelev1">&gt; is a thing or can exist apart from a much larger context.
</em><br />
<br />Again, if consciousness needs that context, then either the context is 
<br />
not turing emulable, and this means comp is false (because in that case 
<br />
consciousness needs something non turing emulable), or the context is 
<br />
turing emulable, and then the reasoning go through.
<br />
<br />You are not refuting the derivation. It seems you are hesitating 
<br />
between eliminating consciousness, or making it relying on something 
<br />
non Turing emulable. In both case comp is false then. You could as well 
<br />
say &quot;Marchals shows that comp entails there is no fundamental physical 
<br />
universe, thus marchal has refuted comp. But nobody has ever prove 
<br />
there is a primary physical universe so I take it as premature to 
<br />
pretend that we have shown comp contradictory. All what comp implies is 
<br />
that the appearance of a physical universe has to emerge from the many 
<br />
computational histories existing already in elementary arithmetic.
<br />
The contradiction even disappear completely once we look at the 
<br />
translation of UDA in arithmetic. Thanks to incompleteness, we have all 
<br />
the ingredient to explain how the laws of physics emerge from the 
<br />
computations as seen from internal points of view.
<br />
Is it so astonishing that, like the biological principles have emerged 
<br />
by natural selection, the laws of physics emerge from numbers by a 
<br />
logical and arithmetical selection principle?
<br />
<br />Tell me if you understand why step 6 and 7 are correct, before we 
<br />
tackle the more subtle step 8. Just remember that comp explicitly 
<br />
invoke the notion of consciousness, remind the use of generalized 
<br />
brain. It is very rare now that people have still problem with 1..7.  
<br />
To be sure in the seventies people did understood 1...7, and I have 
<br />
never met since (never, even at Brussels) someone who does not 
<br />
understand 1..7 in a oral presentation, despite the huge utilization of 
<br />
the first person experience delay-invariance. I hope you understand 
<br />
that your critics of #6 does not go through. OK?
<br />
<br />Bruno Marchal
<br />
<br /><a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
<br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Mon Nov 03 2008 - 06:23:49 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start15089">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="15090.html" title="Next message in the list">Jason Resch: "Re: QTI &#0038; euthanasia (brouillon)"</a></li>
<li><dfn>Previous message</dfn>: <a href="15088.html" title="Previous message in the list">Brent Meeker: "Re: QTI &#0038; euthanasia"</a></li>
<li><dfn>In reply to</dfn>: <a href="15088.html" title="Message to which this message replies">Brent Meeker: "Re: QTI &#0038; euthanasia"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="15090.html" title="Next message in this discussion thread">Jason Resch: "Re: QTI &#0038; euthanasia (brouillon)"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="15090.html" title="Message sent in reply to this message">Jason Resch: "Re: QTI &#0038; euthanasia (brouillon)"</a></li>
<li><dfn>Reply</dfn>: <a href="15093.html" title="Message sent in reply to this message">G&#0252;nther Greindl: "Re: QTI &#0038; euthanasia (brouillon)"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15089" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15089" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15089" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15089" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
