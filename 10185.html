<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: The Irreducibility of Consciousness from Brent Meeker on 2006-08-06 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: The Irreducibility of Consciousness" />
<meta name="Date" content="2006-08-06" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: The Irreducibility of Consciousness</h1>
<!-- received="Sun Aug  6 17:17:50 2006" -->
<!-- isoreceived="20060807001750" -->
<!-- sent="Sun, 06 Aug 2006 14:15:46 -0700" -->
<!-- isosent="20060806211546" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: The Irreducibility of Consciousness" -->
<!-- id="44D65C02.9050206.domain.name.hidden" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="BAY124-W21629EFB96B7D378E1181D2510.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start10185" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="10186.html" accesskey="d" title="Brent Meeker: &quot;Re: Bruno&#0039;s argument - Comp&quot;">Next message</a> ]
[ <a href="10184.html" title="Brent Meeker: &quot;Re: Bruno&#0039;s argument - Comp&quot;">Previous message</a> ]
[ <a href="10155.html" title="Stathis Papaioannou: &quot;RE: The Irreducibility of Consciousness&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="10191.html" accesskey="t" title="John M: &quot;Re: The Irreducibility of Consciousness&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10185" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10185" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10185" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10185" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20The%20Irreducibility%20of%20Consciousness">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sun, 06 Aug 2006 14:15:46 -0700</span><br />
</address>
<br />
Stathis Papaioannou wrote:
<br />
<em class="quotelev1">&gt; John M writes (quoting SP):
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;St:
</em><br />
<em class="quotelev2">&gt;&gt;Are you suggesting that a brain with the same
</em><br />
<em class="quotelev2">&gt;&gt;pattern of neurons firing, but without the appropriate environmental
</em><br />
<em class="quotelev2">&gt;&gt;stimulus, would not have exactly the same conscious experience?
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;[JM]:
</em><br />
<em class="quotelev2">&gt;&gt;Show me, I am an experimentalist.  First show two brains with the same 
</em><br />
<em class="quotelev2">&gt;&gt;pattern of  (ALL!)   neuron firings. Two extracted identical firings in a 
</em><br />
<em class="quotelev2">&gt;&gt;superdupercomplex brain is meaningless.
</em><br />
<em class="quotelev2">&gt;&gt;Then, please, show me (experimentally) the non-identity of environmental 
</em><br />
<em class="quotelev2">&gt;&gt;impacts reaching 2 different brains from the unlimited interaction of the 
</em><br />
<em class="quotelev2">&gt;&gt;totality.
</em><br />
<em class="quotelev2">&gt;&gt;(I wrote already that I do not approve thought-experiments).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Of course, you could not have both brains stimulated in the usual manner in 
</em><br />
<em class="quotelev1">&gt; both environments because then they would not have identical patterns of 
</em><br />
<em class="quotelev1">&gt; neural firing; you would have to artificially stimulate one of the brains in exactly 
</em><br />
<em class="quotelev1">&gt; the right manner to mimic the stimulation it would receive via its sense organs. 
</em><br />
<em class="quotelev1">&gt; That would be very difficult to achieve in a practical experiment, but the question 
</em><br />
<em class="quotelev1">&gt; is, *if* you could do this would you expect that the brains would be able to guess 
</em><br />
<em class="quotelev1">&gt; on the basis of their subjective experience alone which one was which? 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Actually, &quot;natural&quot; experiments something like this occur in people going through a 
</em><br />
<em class="quotelev1">&gt; psychotic episode. Most people who experience auditory hallucinations find it 
</em><br />
<em class="quotelev1">&gt; impossible to distinguish between the hallucination and the real thing: the voices 
</em><br />
<em class="quotelev1">&gt; sound *exactly* as it sounds when someone is talking to them, which is why (if 
</em><br />
<em class="quotelev1">&gt; they are that sort of person) they might assault a stranger on the train in the belief 
</em><br />
<em class="quotelev1">&gt; that they have insulted or threatened them, when the poor fellow has said nothing 
</em><br />
<em class="quotelev1">&gt; at all. I think this example alone is enough to show that it is possible to have a 
</em><br />
<em class="quotelev1">&gt; perception with cortical activity alone; you don't even need to artificially stimulate 
</em><br />
<em class="quotelev1">&gt; the auditory nerve.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;St:
</em><br />
<em class="quotelev2">&gt;&gt;That would imply some sort of extra-sensory perception, and there is
</em><br />
<em class="quotelev2">&gt;&gt;no evidence for such a thing. It is perfectly consistent with all the facts
</em><br />
<em class="quotelev2">&gt;&gt;to say that consciousness results from patterns of neurons firing in the
</em><br />
<em class="quotelev2">&gt;&gt;brain, and that if the same neurons fired, the same experience would
</em><br />
<em class="quotelev2">&gt;&gt;result regardless of what actually caused those neurons to fire.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;[JM]:
</em><br />
<em class="quotelev2">&gt;&gt;regardless also of the 'rest of the brain'? Would you pick one of the 
</em><br />
<em class="quotelev2">&gt;&gt;billions copmpleting the brainwork complexity and match it to a similar one 
</em><br />
<em class="quotelev2">&gt;&gt;in a different complexity?
</em><br />
<em class="quotelev2">&gt;&gt;But the more relevant question (and I mean it):
</em><br />
<em class="quotelev2">&gt;&gt;What would you identify as (your version) of &quot;consciousness&quot; that &quot;results 
</em><br />
<em class="quotelev2">&gt;&gt;from neuron-fiting&quot; consistent with all the facts?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; My neurons fire and I am conscious; if they didn't fire I wouldn't be conscious, 
</em><br />
<em class="quotelev1">&gt; and if they fired very differently to the way they are doing I would be differently 
</em><br />
<em class="quotelev1">&gt; conscious. That much, I think, is obvious. Maybe there is something *in addition* 
</em><br />
<em class="quotelev1">&gt; to the physical activity of our neurons which underpins consciousness, but at the 
</em><br />
<em class="quotelev1">&gt; moment it appears that the neurons are both necessary and sufficient, so you 
</em><br />
<em class="quotelev1">&gt; would have to present some convincing evidence (experimental is always best, as 
</em><br />
<em class="quotelev1">&gt; you say, but theoretical will do) if you want to claim otherwise.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;St:
</em><br />
<em class="quotelev2">&gt;&gt;As for consciousness being fundamentally irreducible, I agree
</em><br />
<em class="quotelev2">&gt;&gt;completely.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;[JM]:
</em><br />
<em class="quotelev2">&gt;&gt;Consider it a singularity, a Ding an Sich? Your statement looks to me as 
</em><br />
<em class="quotelev2">&gt;&gt;referring to a &quot;thing&quot;. Not a process. Or rather a state? (Awareness??)
</em><br />
<em class="quotelev2">&gt;&gt;*
</em><br />
<em class="quotelev2">&gt;&gt;St:
</em><br />
<em class="quotelev2">&gt;&gt;It is a fact that when neurons fire in a particular way, a conscious 
</em><br />
<em class="quotelev2">&gt;&gt;experience results; possibly, complex enough electronic activity in a 
</em><br />
<em class="quotelev2">&gt;&gt;digital computer might also result in conscious experience, although we 
</em><br />
<em class="quotelev2">&gt;&gt;cannot be sure of that. But this does not mean that the conscious experience 
</em><br />
<em class="quotelev2">&gt;&gt;*is* the brain or computer activity, even if it could somehow be shown that 
</em><br />
<em class="quotelev2">&gt;&gt;the physical process is necessary and sufficient for the experience.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;[JM]:
</em><br />
<em class="quotelev2">&gt;&gt;I hope you could share with us your version of that &quot;conscious experience&quot; 
</em><br />
<em class="quotelev2">&gt;&gt;as well, which &quot;could&quot; be assigned to a digital computer? What &quot;other&quot; 
</em><br />
<em class="quotelev2">&gt;&gt;activity may a digital computer have
</em><br />
<em class="quotelev2">&gt;&gt;beside &quot;electronic&quot;?
</em><br />
<em class="quotelev2">&gt;&gt;It is hard to show in 'parallel' observed phenopmena whether  one is 
</em><br />
<em class="quotelev2">&gt;&gt;'necessary' for the other, or just observervable in parallel? Maybe &quot;the 
</em><br />
<em class="quotelev2">&gt;&gt;other&quot; is necessary for the 'one'?
</em><br />
<em class="quotelev2">&gt;&gt;If you find that the 'physical' process (firing, or electronic) is 
</em><br />
<em class="quotelev2">&gt;&gt;SUFFICIENT then probably your definition is such that it allows such 
</em><br />
<em class="quotelev2">&gt;&gt;sufficiency.
</em><br />
<em class="quotelev2">&gt;&gt;I may question the complexity of the assigned situation
</em><br />
<em class="quotelev2">&gt;&gt;for such simplification,.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't know that computers can be conscious, and I don't even know that 
</em><br />
<em class="quotelev1">&gt; computers can emulate human-type intelligent behaviour. Proving the latter 
</em><br />
<em class="quotelev1">&gt; lies in the domain of experimental science, while proving the former is impossible,  
</em><br />
<em class="quotelev1">&gt; although it is also impossible to *prove* that another person is conscious. 
</em><br />
<br />I think you setting to high a standard for &quot;prove&quot;.  If you set the standard
<br />
&nbsp;&nbsp;as in mathematical proof, then the proof is relative to the axioms.  If
<br />
you set the standard of science, or the &quot;reasonable man&quot; of courtrooms, then
<br />
I think it is possible.  The scientific proof would be to construct a model
<br />
consistent with all observation, which is coherent with all other accept
<br />
theories, and which include consciousness as an essential element.  The
<br />
legal standard for criminal trials is &quot;beyond a reasonable doubt&quot; and that
<br />
is certainly proven everyday in courtrooms across the land, since conviction
<br />
for many crimes requires intent.
<br />
<br />So I would ask by what standard of 'proof' do you assert this impossibility;
<br />
and by the same standard, can you prove other people exist - or that you exist.
<br />
<br />Brent Meeker
<br />
The sciences do not try to explain, they hardly even try to  interpret, they
<br />
mainly make models. By a model is meant a  mathematical construct which,
<br />
with the addition of certain verbal  interpretations, describes observed
<br />
phenomena. The justification of  such a mathematical construct is solely and
<br />
precisely that it is  expected to work.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--—John von Neumann
<br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sun Aug 06 2006 - 17:17:50 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start10185">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="10186.html" title="Next message in the list">Brent Meeker: "Re: Bruno&#0039;s argument - Comp"</a></li>
<li><dfn>Previous message</dfn>: <a href="10184.html" title="Previous message in the list">Brent Meeker: "Re: Bruno&#0039;s argument - Comp"</a></li>
<li><dfn>In reply to</dfn>: <a href="10155.html" title="Message to which this message replies">Stathis Papaioannou: "RE: The Irreducibility of Consciousness"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="10191.html" title="Next message in this discussion thread">John M: "Re: The Irreducibility of Consciousness"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10185" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10185" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10185" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10185" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
