<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>RE: computationalism and supervenience from Stathis Papaioannou on 2006-09-16 (everything)</title>
<meta name="Author" content="Stathis Papaioannou (stathispapaioannou.domain.name.hidden)" />
<meta name="Subject" content="RE: computationalism and supervenience" />
<meta name="Date" content="2006-09-16" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>RE: computationalism and supervenience</h1>
<!-- received="Sat Sep 16 07:00:47 2006" -->
<!-- isoreceived="20060916140047" -->
<!-- sent="Sat, 16 Sep 2006 20:59:45 +1000" -->
<!-- isosent="20060916105945" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathispapaioannou.domain.name.hidden" -->
<!-- subject="RE: computationalism and supervenience" -->
<!-- id="000a01c6d97f$3804f200$0200a8c0.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="4870.60.230.177.147.1158394256.squirrel.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start11154" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="11155.html" accesskey="d" title="Bruno Marchal: &quot;Re: Russell&#0039;s book&quot;">Next message</a> ]
[ <a href="11153.html" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">Previous message</a> ]
[ <a href="11152.html" title="Colin Geoffrey Hales: &quot;RE: computationalism and supervenience&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="11156.html" accesskey="t" title="Bruno Marchal: &quot;Re: computationalism and supervenience&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg11154" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg11154" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg11154" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg11154" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Stathis Papaioannou &lt;<a href="mailto:stathispapaioannou.domain.name.hidden?Subject=RE%3A%20computationalism%20and%20supervenience">stathispapaioannou.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sat, 16 Sep 2006 20:59:45 +1000</span><br />
</address>
<br />
Colin Hales writes:
<br />
<br /><em class="quotelev2">&gt; &gt; I've had another think about this after reading the paper you sent
</em><br />
me.
<br />
<em class="quotelev1">&gt; It
</em><br />
<em class="quotelev2">&gt; &gt; seems that
</em><br />
<em class="quotelev2">&gt; &gt; you are making two separate claims. The first is that a zombie would
</em><br />
not
<br />
<em class="quotelev1">&gt; be able to
</em><br />
<em class="quotelev2">&gt; &gt; behave like a conscious being in every situation: specifically, when
</em><br />
<em class="quotelev1">&gt; called upon to be
</em><br />
<em class="quotelev2">&gt; &gt; scientifically creative. If this is correct it would be a corollary
</em><br />
of
<br />
<em class="quotelev1">&gt; the
</em><br />
<em class="quotelev2">&gt; &gt; Turing test, i.e.,
</em><br />
<em class="quotelev2">&gt; &gt; if it behaves as if it is conscious under every situation, then it's
</em><br />
<em class="quotelev1">&gt; conscious. However,
</em><br />
<em class="quotelev2">&gt; &gt; you are being quite specific in describing what types of behaviour
</em><br />
could
<br />
<em class="quotelev1">&gt; only occur
</em><br />
<em class="quotelev2">&gt; &gt; in the setting of phenomenal consciousness. Could you perhaps be
</em><br />
even
<br />
<em class="quotelev1">&gt; more
</em><br />
<em class="quotelev2">&gt; &gt; specific
</em><br />
<em class="quotelev2">&gt; &gt; and give an example of the simplest possible behaviour or scientific
</em><br />
<em class="quotelev1">&gt; theory which an
</em><br />
<em class="quotelev2">&gt; &gt; unconscious machine would be unable to mimic?
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; The second claim is that a computer could only ever be a zombie, and
</em><br />
<em class="quotelev1">&gt; therefore could
</em><br />
<em class="quotelev2">&gt; &gt; never be scientifically creative. However, it is possible to agree
</em><br />
with
<br />
<em class="quotelev1">&gt; the first claim and
</em><br />
<em class="quotelev2">&gt; &gt; reject this one. Perhaps if a computer were complex enough to truly
</em><br />
<em class="quotelev1">&gt; mimic
</em><br />
<em class="quotelev2">&gt; &gt; the behaviour
</em><br />
<em class="quotelev2">&gt; &gt; of a conscious being, including being scientifically creative, then
</em><br />
it
<br />
<em class="quotelev1">&gt; would indeed be
</em><br />
<em class="quotelev2">&gt; &gt; conscious. Perhaps our present computers are either unconscious
</em><br />
because
<br />
<em class="quotelev1">&gt; they are too
</em><br />
<em class="quotelev2">&gt; &gt; primitive or they are indeed conscious, but at the very low end of a
</em><br />
<em class="quotelev1">&gt; consciousness
</em><br />
<em class="quotelev2">&gt; &gt; continuum, like single-celled organisms or organisms with relatively
</em><br />
<em class="quotelev1">&gt; simple nervous systems
</em><br />
<em class="quotelev2">&gt; &gt; like planaria.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Stathis Papaioannou
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; COLIN:
</em><br />
<em class="quotelev1">&gt; Hi.... a bunch of points...
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 1) Re paper.. it is undergoing review and growing..
</em><br />
<em class="quotelev1">&gt; The point of the paper is to squash the solipsism argument ...in
</em><br />
<em class="quotelev1">&gt; particular the specific flavour of it that deals with 'other minds'
</em><br />
and as
<br />
<em class="quotelev1">&gt; it has (albeit tacitly) defined science's attitude to what is/is not
</em><br />
<em class="quotelev1">&gt; scientific evidence. As such I am only concerned with scientific
</em><br />
<em class="quotelev1">&gt; behaviour. The mere existence of a capacity to handle exquisite
</em><br />
novelty
<br />
<em class="quotelev1">&gt; demands the existence of the functionality of phenomenal consciousness
</em><br />
<em class="quotelev1">&gt; within the scientist. Novel technology exists, ergo science is
</em><br />
possible,
<br />
<em class="quotelev1">&gt; ergo phenomenal consciousness exists. Phenomenal consciousness is
</em><br />
proven
<br />
<em class="quotelev1">&gt; by the existence of novel technology. More than 1 scientist has
</em><br />
produced
<br />
<em class="quotelev1">&gt; novel technology. Ergo there is more then 1 'mind' (=collection of
</em><br />
<em class="quotelev1">&gt; phenomenal fields) ergo other minds do exist. Ergo solipsism is false.
</em><br />
The
<br />
<em class="quotelev1">&gt; problem is that along the way you have also proved that there is an
</em><br />
<em class="quotelev1">&gt; external 'reality'...which is a bit of a bonus. So all the
</em><br />
philosophical
<br />
<em class="quotelev1">&gt; arguments about 'existence' that have wasted so much of our time is
</em><br />
<em class="quotelev1">&gt; actually just that...a waste of time.
</em><br />
<br />That's a very bold and ambitious claim, if I may say so.
<br />
<br /><em class="quotelev1">&gt; 2) Turing test. I think the turing test is a completely misguided
</em><br />
idea.
<br />
<em class="quotelev1">&gt; It's based on the assumption that abstract (as-if) computation can
</em><br />
fully
<br />
<em class="quotelev1">&gt; replicate (has access to all the same information)  of computation
</em><br />
<em class="quotelev1">&gt; performed by the natural world. This assumption can be made obvious as
</em><br />
<em class="quotelev1">&gt; follows:
</em><br />
<em class="quotelev1">&gt; Q. What is it like to be a human? It is like being a mind. There is
</em><br />
<em class="quotelev1">&gt; information delivered into the mind by the action of brain material
</em><br />
which
<br />
<em class="quotelev1">&gt; bestows on the human intrinsic knowledge about the natural world
</em><br />
outside
<br />
<em class="quotelev1">&gt; the human....in the form of phenomenal consciousness. This knowledge
</em><br />
is
<br />
<em class="quotelev1">&gt; not a model/abstraction, but a literal mapping of what's there (no
</em><br />
matter
<br />
<em class="quotelev1">&gt; how mysterious its generation may seem). The zombie does not have
</em><br />
this.
<br />
<em class="quotelev1">&gt; Nor does the Turing machine. A turing machine is a zombie. No matter
</em><br />
what
<br />
<em class="quotelev1">&gt; the program, it's always 'like a tape and tape reader' to be a Turing
</em><br />
<em class="quotelev1">&gt; machine. The knowledge provided by phenonmenal cosnciousness is not an
</em><br />
<em class="quotelev1">&gt; abstraction (programmed model)...it is a direct mapping.
</em><br />
<br /><em class="quotelev1">&gt;From memory the original Turing test did not specify that the test
</em><br />
subject was a &quot;Turing machine&quot; but rather just a hidden subject who
<br />
answers questions, so that the testers have to guess whether it is
<br />
conscious on the basis of the answers to the questions alone. So are you
<br />
saying that you are confident that a mere Turing machine would fail the
<br />
test (you can ask it come up with new scientific theories or whatever
<br />
you like), or are you saying that you would not accept that a Turing
<br />
machine was conscious even if you did your worst to fail it and it still
<br />
passed? If the latter, it would seem to go against your central thesis
<br />
that you can prove scientists are not zombies, and can't be aped by
<br />
zombie machines.
<br />
<br /><em class="quotelev1">&gt; 3) RE:
</em><br />
<em class="quotelev2">&gt; &gt; and give an example of the simplest possible behaviour or scientific
</em><br />
<em class="quotelev1">&gt; theory which an
</em><br />
<em class="quotelev2">&gt; &gt; unconscious machine (UM) would be unable to mimic?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I think this is a meaningless quest. It depends on a) the
</em><br />
<em class="quotelev1">&gt; sensory/actuation facilities and b) the a-priori knowledge bestowed
</em><br />
upon
<br />
<em class="quotelev1">&gt; the UM by its human progenitor.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; No matter how good the a-priori abstraction given by the human the UM
</em><br />
will
<br />
<em class="quotelev1">&gt; do science on its sensory feeds until it can no longer distinguish any
</em><br />
<em class="quotelev1">&gt; effect because the senses cannot discriminate it (if the UM has any
</em><br />
idea
<br />
<em class="quotelev1">&gt; what this means anyway - remember it has no internal likfe, no idea it
</em><br />
is
<br />
<em class="quotelev1">&gt; in any universe, no experience of its sensory feeds...has no idea
</em><br />
there's
<br />
<em class="quotelev1">&gt; any thing around it, like a human...it's 'not there'). So this poor UM
</em><br />
<em class="quotelev1">&gt; will learn within the confines of its ecological niche that it doesn't
</em><br />
<em class="quotelev1">&gt; even know it is in, reach a point where no matter what it does nothing
</em><br />
<em class="quotelev1">&gt; novel can be detected through its sensory feeds...Then it will stay
</em><br />
that
<br />
<em class="quotelev1">&gt; way for good. To an outide observer it would look very weird. It would
</em><br />
<em class="quotelev1">&gt; also fall victim to any perceptual failure not consistent with its
</em><br />
<em class="quotelev1">&gt; survival.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 5) Re a fatal test for the Turing machine? Give it exquisite novelty
</em><br />
by
<br />
<em class="quotelev1">&gt; asking it to do science on an unknown area of the natural world.
</em><br />
Proper
<br />
<em class="quotelev1">&gt; science. It will fail because it does not know there is an outside
</em><br />
world.
<br />
<em class="quotelev1">&gt; Get it to make/guide the creation of novel technology. This is a human
</em><br />
<em class="quotelev1">&gt; behaviour that a Turing machine will never be able to do...because the
</em><br />
<em class="quotelev1">&gt; humans have not done it yet either.... put the Turing Machine and a
</em><br />
human
<br />
<em class="quotelev1">&gt; scientist together and get them to do science on true novelty. The
</em><br />
Turing
<br />
<em class="quotelev1">&gt; machine cannot have any a-priori knowledge of the natural world in
</em><br />
<em class="quotelev1">&gt; question because the humans who would give it to the machine dont have
</em><br />
it
<br />
<em class="quotelev1">&gt; either!
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; This is the real test. Can a Turing machine do science? No way. There
</em><br />
is
<br />
<em class="quotelev1">&gt; no 'mimicking' consciousness.... it is an oxymorom as a statement.
</em><br />
<br />Why? This is what I'm asking. You seem to be suggesting that the sensory
<br />
inputs of the UM have no real external referents, and it just
<br />
manipulates signals according to its programming. But the same could be
<br />
said of human signal processing. I don't *know* there is a real world
<br />
out there, all I know is that I experience sensory data which I have
<br />
learned to recognize as having certain patterns, which I then manipulate
<br />
and operate on in order to achieve certain outcomes according to my
<br />
programming, such as avoiding pain and satisfying hunger. I conveniently
<br />
classify certain patterns for future reference, eg. &quot;fire is hot&quot;, and
<br />
it is the sum of these experiences which constitute my &quot;model&quot; of the
<br />
world. If God made fire cold on Tuesdays I would be confused the first
<br />
few times it happened, but I would eventually modify my view of the
<br />
world to &quot;fire is hot, except on Tuesdays&quot;: and so would any competently
<br />
designed machine which had to deal with fire. We think 
<br />
We have knowledge of an external reality, but even if there is an
<br />
external reality and we are not brains in vats all we have is a virtual
<br />
reality created in our head which, if we are lucky, is isomorphic with
<br />
the external reality. A machine with sensors, effectors, programming,
<br />
signal-manipulation ability and learning would ipso facto create its own
<br />
model of external reality, and would potentially be just as capable of
<br />
dealing with the outside world as a person is. 
<br />
<br /><em class="quotelev1">&gt; --------------------------------
</em><br />
<em class="quotelev1">&gt; BTW I completeley agree about the continuum of consciousness. I
</em><br />
believe it
<br />
<em class="quotelev1">&gt; started with eukaryotes having 'proto-experiences'. In a generalised
</em><br />
model
<br />
<em class="quotelev1">&gt; of cognition and consciousness all critters have varying levels of
</em><br />
<em class="quotelev1">&gt; phenomenal consciousness and intellectual faculties for using that to
</em><br />
<em class="quotelev1">&gt; survive in an ecological niche.... however... this is not the point of
</em><br />
my
<br />
<em class="quotelev1">&gt; paper... the paper was to prove that phenomenal consciousness is
</em><br />
necessary
<br />
<em class="quotelev1">&gt; for scientific behaviour...
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Having reached that point in a proof...you can then look at other
</em><br />
<em class="quotelev1">&gt; behaviours (like tennis!) and other species (like bats and zombies).
</em><br />
The
<br />
<em class="quotelev1">&gt; key aspect to the idea is that truly scientific behaviour is the only
</em><br />
one
<br />
<em class="quotelev1">&gt; we can use as a real proof in respect of the existence of
</em><br />
consciousness,
<br />
<em class="quotelev1">&gt; as it makes real demands of the external world and relates them
</em><br />
directly
<br />
<em class="quotelev1">&gt; in a structured way to the internal life of the scientist in a way
</em><br />
that
<br />
<em class="quotelev1">&gt; has nothing to do with the scientist (it's about unknown/novel natural
</em><br />
<em class="quotelev1">&gt; laws operating outside the scientist).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Nobody has ever thought about this like this, have they?.... I just
</em><br />
had
<br />
<em class="quotelev1">&gt; this shivery feeling... that maybe I've tripped over something
</em><br />
useful... I
<br />
<em class="quotelev1">&gt; have found it so weird lately talking to scientists, standing
</em><br />
there...the
<br />
<em class="quotelev1">&gt; evidence for consiousness in front of me...saying &quot;there's no
</em><br />
<em class="quotelev1">&gt; evidence...&quot;...:-)  is it any wonder scientists can't see the
</em><br />
<em class="quotelev1">&gt; evidence...they ARE the evidence!
</em><br />
<br />Maybe so, but the thing I'm disputing is not that scientists cannot be
<br />
zombies, but that computers cannot be scientists.
<br />
<br />Stathis Papaioannou
<br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sat Sep 16 2006 - 07:00:47 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start11154">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="11155.html" title="Next message in the list">Bruno Marchal: "Re: Russell&#0039;s book"</a></li>
<li><dfn>Previous message</dfn>: <a href="11153.html" title="Previous message in the list">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<li><dfn>In reply to</dfn>: <a href="11152.html" title="Message to which this message replies">Colin Geoffrey Hales: "RE: computationalism and supervenience"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="11156.html" title="Next message in this discussion thread">Bruno Marchal: "Re: computationalism and supervenience"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg11154" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg11154" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg11154" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg11154" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
