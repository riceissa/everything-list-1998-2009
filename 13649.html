<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: How would a computer know if it were conscious? from David Nyman on 2007-06-26 (everything)</title>
<meta name="Author" content="David Nyman (david.nyman.domain.name.hidden)" />
<meta name="Subject" content="Re: How would a computer know if it were conscious?" />
<meta name="Date" content="2007-06-26" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: How would a computer know if it were conscious?</h1>
<!-- received="Tue Jun 26 17:11:07 2007" -->
<!-- isoreceived="20070627001107" -->
<!-- sent="Tue, 26 Jun 2007 22:10:49 +0100" -->
<!-- isosent="20070626211049" -->
<!-- name="David Nyman" -->
<!-- email="david.nyman.domain.name.hidden" -->
<!-- subject="Re: How would a computer know if it were conscious?" -->
<!-- id="b0b263660706261410o28a538d2vd3d0ea76f1b99ed8.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="1acbded70706261239y5dd65726l37ca3fe6ec91c3fd.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13649" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13650.html" accesskey="d" title="Russell Standish: &quot;Re: How would a computer know if it were conscious?&quot;">Next message</a> ]
[ <a href="13648.html" title="John Mikes: &quot;Re: How would a computer know if it were conscious?&quot;">Previous message</a> ]
[ <a href="13648.html" title="John Mikes: &quot;Re: How would a computer know if it were conscious?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13665.html" accesskey="t" title="Bruno Marchal: &quot;Re: How would a computer know if it were conscious?&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13649" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13649" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13649" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13649" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: David Nyman &lt;<a href="mailto:david.nyman.domain.name.hidden?Subject=Re%3A%20How%20would%20a%20computer%20know%20if%20it%20were%20conscious%3F">david.nyman.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 26 Jun 2007 22:10:49 +0100</span><br />
</address>
<br />
On 26/06/07, John Mikes &lt;jamikes.domain.name.hidden&gt; wrote:
<br />
<br />JM:  You mean a hallucination of x, when you * 'I just see x, hear x, feel
<br />
x' and so forth' *.  is included in your knowledge? or even substitutes for
<br />
it? Maybe yes...
<br />
<br />DN:  &quot;I am conscious of knowing x&quot; is distinguishable from &quot;I know x&quot;.  The
<br />
former has already differentiated 'knowing x' and so now &quot;I know [knowing
<br />
x]&quot;.  And so forth.  So knowing in this sense stands for a direct or
<br />
unmediated 'self-relation', a species of unity between knower and known -
<br />
hence its notorious 'incorrigibility'.
<br />
<br />JM:  But then can you differentiate? (or this is no reasonable question?)
<br />
<br />DN:  It seems that in the development of the individual at first there is no
<br />
such differentiation; then we find that we are 'thrown' directly into a
<br />
'world' populated with 'things' and 'other persons'; later, we differentiate
<br />
this from a distal 'real world' that putatively co-varies with it.  Now we
<br />
are in a position to make a distinction between 'plural' or 'rational' modes
<br />
of knowing, and solipsistic or 'crazy' ones.  But then it dawns that it's
<br />
*our world* - not the 'real' one, that's the 'hallucination'.  No wonder
<br />
we're crazy!  This evolutionarily-directed stance towards what we 'know' is
<br />
of course so pervasive that it's only a minority (like the lost souls on
<br />
this list!) who harbour any real concern about the precise status of such
<br />
correlations.  Hence, I suppose, our continual state of confusion.
<br />
<br />JM:  The classic question: &quot;Am I? and the classical answer:  &quot;Who is
<br />
asking?&quot;
<br />
<br />DN:  Just so. Crazy, like I say.
<br />
<br />JM: Are you including 'humans' into the machines or the computers? And dogs?
<br />
Amoebas?
<br />
<br />DN:  Actually, I just meant to distinguish between 'machines' considered
<br />
physically and computational processes.  I really have no idea of course
<br />
whether any non-human artefact will ever come to know and act in the sense
<br />
that a human does. My point was only to express my logical doubts that it
<br />
would ever do so in virtue of its behaving in a way that merely represents
<br />
*to us* a process of computation.  However, the more I reason about this the
<br />
stranger it gets, so I guess I really 'dunno'.
<br />
<br />JM:  Bruno is right: accepting that 'any machine' is part of its &quot;outside(?)
<br />
totality&quot;, i.e.  embedded into its ambiance, I would be scared to
<br />
differentiate myself. There is no hermetic 'skin' - it is transitional
<br />
effects transcending back and forth, we just do not observe those outside
<br />
the 'topical boundaries' of our actual observation (model, as I call it).
<br />
<br />DN:  Yes: all is relation (ultimately self-relation, IMO), and 'boundaries'
<br />
merely delimit what is 'observable'.  In this context, what do you think
<br />
about Colin's TPONOG post?
<br />
<br />Regards
<br />
<br />David
<br />
<br /><br />On 6/23/07, David Nyman &lt;david.nyman.domain.name.hidden&gt; wrote:
<br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; Hi John....
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; ....(just your Italics par-s quoted in this reply. Then &quot;JM: means present
</em><br />
<em class="quotelev1">&gt; text)):
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; *DN: Since we agree to eliminate the 'obsolete noumenon', we can perhaps
</em><br />
<em class="quotelev1">&gt; re-phrase this as just: 'how do you know x?'  And then the answers are of
</em><br />
<em class="quotelev1">&gt; the type 'I just see x, hear x, feel x' and so forth.  IOW, 'knowing x' is
</em><br />
<em class="quotelev1">&gt; unmediated** - 'objects' like x are just 'embedded' in the structure of
</em><br />
<em class="quotelev1">&gt; the 'knower', and this is recursively related to more inclusive structures
</em><br />
<em class="quotelev1">&gt; within which the knower and its environment are in turn embedded.
</em><br />
<em class="quotelev1">&gt; *
</em><br />
<em class="quotelev1">&gt; JM:  You mean a hallucination of x, when you * 'I just see x, hear x, feel
</em><br />
<em class="quotelev1">&gt; x' and so forth'*.
</em><br />
<em class="quotelev1">&gt; is included in your knowledge? or even substitutes for it? Maybe yes...
</em><br />
<em class="quotelev1">&gt; But then can you differentiate? (or this is no reasonable question?)
</em><br />
<em class="quotelev1">&gt; *
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; *((to JM: ...know if you are NOT conscious? Well, you wouldn't.))
</em><br />
<em class="quotelev1">&gt; DN: Agreed.  If we 'delete the noumenon' we get: &quot;How would you know if
</em><br />
<em class="quotelev1">&gt; you are NOT?&quot; or: &quot;How would you know if you did NOT (know)?&quot;.  To which we
</em><br />
<em class="quotelev1">&gt; might indeed respond: &quot;You would not know, if you were NOT&quot;, or: &quot;You would
</em><br />
<em class="quotelev1">&gt; not know, if you did NOT (know)&quot;. *
</em><br />
<em class="quotelev1">&gt; JM:  The classic question: &quot;Am I? and the classical answer:  &quot;Who is
</em><br />
<em class="quotelev1">&gt; asking?&quot;
</em><br />
<em class="quotelev1">&gt; *
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; *DN: I think we need to distinguish between 'computers' and 'machines'.  I
</em><br />
<em class="quotelev1">&gt; can see no reason in principle why an artifact could not 'know', and be
</em><br />
<em class="quotelev1">&gt; motivated by such knowing to interact with the human world: humans are of
</em><br />
<em class="quotelev1">&gt; course themselves 'natural artifacts'. * itself embedded.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; JM: Are you including 'humans' into the machines or the computers? And
</em><br />
<em class="quotelev1">&gt; dogs? Amoebas?
</em><br />
<em class="quotelev1">&gt; The main difference I see here is the 'extract' of the &quot;human world&quot; (or:
</em><br />
<em class="quotelev1">&gt; &quot;world, as humans can interpret what they learned&quot;) downsized to our
</em><br />
<em class="quotelev1">&gt; choice of necessity which WE liked to design into an artifact. (motors,
</em><br />
<em class="quotelev1">&gt; cellphones, AI, AL). Yes, we (humans etc.) are artefacts but 'use' a lot of
</em><br />
<em class="quotelev1">&gt; capabilities (mental etc. gadgets) we either don't know at all, or just
</em><br />
<em class="quotelev1">&gt; accept them as 'being human' (or an extract of human traits as 'being dog')
</em><br />
<em class="quotelev1">&gt; with no urge to build such into a microwave oven or an AI.
</em><br />
<em class="quotelev1">&gt; But then we are SSOO smart when we draw conclusions!!!!!
</em><br />
<em class="quotelev1">&gt; *
</em><br />
<em class="quotelev1">&gt; *DN:
</em><br />
<em class="quotelev1">&gt; Bruno's approach is to postulate the whole 'ball of wax' as computation,
</em><br />
<em class="quotelev1">&gt; so that any 'event' whether 'inside' or 'outside' the machine is 'computed'
</em><br />
<em class="quotelev1">&gt; *.
</em><br />
<em class="quotelev1">&gt; JM:
</em><br />
<em class="quotelev1">&gt; Bruno is right: accepting that 'any machine' is part of its &quot;outside(?)
</em><br />
<em class="quotelev1">&gt; totality&quot;, i.e.  embedded into its ambiance, I would be scared to
</em><br />
<em class="quotelev1">&gt; differentiate myself. There is no hermetic 'skin' - it is transitional
</em><br />
<em class="quotelev1">&gt; effects transcending back and forth, we just do not observe those outside
</em><br />
<em class="quotelev1">&gt; the 'topical boundaries' of our actual observation (model, as I call it).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; *DN:*
</em><br />
<em class="quotelev1">&gt; *The drift of my recent posts has been that even in this account, 'worlds'
</em><br />
<em class="quotelev1">&gt; can emerge 'orthogonally' to each other, such that from their reciprocal
</em><br />
<em class="quotelev1">&gt; perspectives, 'events' in their respective worlds will be 'imaginary'. *
</em><br />
<em class="quotelev1">&gt; JM:
</em><br />
<em class="quotelev1">&gt; I can't say: I have no idea how the world works, except for that little I
</em><br />
<em class="quotelev1">&gt; interpreted into my 1st person narrative. I accept &quot;maybe&quot;-s.
</em><br />
<em class="quotelev1">&gt; And I have a way to 'express' myself: I use &quot;I dunno&quot;.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Have fun
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; John
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; David
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;  Dear David.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; do not expect from me the theoretical level of technicality-talk er
</em><br />
<em class="quotelev3">&gt; &gt; &gt; get
</em><br />
<em class="quotelev3">&gt; &gt; &gt; from Bruno: I talk (and think) common sense (my own) and if the
</em><br />
<em class="quotelev3">&gt; &gt; &gt; theoretical technicalities sound strange, I return to my thinking.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; That's what I got, that's what I use (plagiarized from the Hungarian
</em><br />
<em class="quotelev3">&gt; &gt; &gt; commi
</em><br />
<em class="quotelev3">&gt; &gt; &gt; joke: what is the difference between the peoples' democracy and a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; wife?
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Nothing: that's what we got that's what we love)
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; When I read your &quot;questioning&quot; the computer, i realized that you are
</em><br />
<em class="quotelev3">&gt; &gt; &gt; in the ballpark of the AI people (maybe also AL - sorry, Russell)
</em><br />
<em class="quotelev3">&gt; &gt; &gt; who select machine-accessible aspects for comparing.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; You may ask about prejudice, shame (about goofed situations),  humor
</em><br />
<em class="quotelev3">&gt; &gt; &gt; (does a
</em><br />
<em class="quotelev3">&gt; &gt; &gt; computer laugh?)  boredom or preferential topics (you push for an
</em><br />
<em class="quotelev3">&gt; &gt; &gt; astronomical calculation and the computer says: I rather play some Bach
</em><br />
<em class="quotelev3">&gt; &gt; &gt; music now)
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Sexual preference (even disinterestedness is slanted), or laziness.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; If you add untruthfulness in risky situations, you really have a human
</em><br />
<em class="quotelev3">&gt; &gt; &gt; machine
</em><br />
<em class="quotelev3">&gt; &gt; &gt; with consciousness (whatever people say it is - I agree with your
</em><br />
<em class="quotelev3">&gt; &gt; &gt; evading
</em><br />
<em class="quotelev3">&gt; &gt; &gt; that unidentified obsolete noumenon as much as possible).
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I found Bruno's post well fitting - if i have some hint what
</em><br />
<em class="quotelev3">&gt; &gt; &gt; &quot;...inner personal or self-referential modality...&quot; may mean.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I could not 'practicalize' it.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I still frown when &quot;abondoning (the meaning of) something but consider
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;  items as pertaining to it&quot; - a rough paraphrasing, I admit.  To
</em><br />
<em class="quotelev3">&gt; &gt; &gt; what?.
</em><br />
<em class="quotelev3">&gt; &gt; &gt; I don't feel comfortable to borrow math-methods for nonmath
</em><br />
<em class="quotelev3">&gt; &gt; &gt; explanations
</em><br />
<em class="quotelev3">&gt; &gt; &gt; but that is my deficiency.
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Now that we arrived at thequestion I replied-added (sort of) to
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Colin's question I -
</em><br />
<em class="quotelev3">&gt; &gt; &gt; let me ask it again: how would YOU know if you are conscious?
</em><br />
<em class="quotelev3">&gt; &gt; &gt; (Conscious is more meaningful than cc-ness). Or rather: How would
</em><br />
<em class="quotelev3">&gt; &gt; &gt; you know if you are NOT conscious? Well, you wouldn't. If you can,
</em><br />
<em class="quotelev3">&gt; &gt; &gt; you are conscious.  Computers?????
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; Have a good weekend
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; John Mikes
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt; On 6/20/07, David Nyman &lt; david.nyman.domain.name.hidden &gt; wrote:
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; On Jun 5, 3:12 pm, Bruno Marchal &lt; marc....domain.name.hidden &gt; wrote:
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Personally I don' think we can be *personally* mistaken about our
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; own
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; consciousness even if we can be mistaken about anything that
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; consciousness could be about.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; I agree with this, but I would prefer to stop using the term
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; 'consciousness' at all.  To make a decision (to whatever degree of
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; certainty) about whether a machine possessed a 1-person pov
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; analogous
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; to a human one, we would surely ask it the same sort of questions
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; one
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; would ask a human.  That is: questions about its personal 'world' -
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; what it sees, hears, tastes (and perhaps extended non-human
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; modalitiies); what its intentions are, and how it carries them into
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; practice.  From the machine's point-of-view, we would expect it to
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; report such features of its personal world as being immediately
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; present (as ours are), and that it be 'blind' to whatever 'rendering
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; mechanisms' may underlie this (as we are).
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; If it passed these tests, it would be making similar claims on a
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; personal world as we do, and deploying this to achieve similar ends.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Since in this case it could ask itself the same questions that we
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; can,
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; it would have the same grounds for reaching the same conclusion.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; However, I've argued in the other bit of this thread against the
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; possibility of a computer in practice being able to instantiate such
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; a
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; 1-person world merely in virtue of 'soft' behaviour (i.e.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; programming).  I suppose I would therefore have to conclude that no
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; machine could actually pass the tests I describe above - whether
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; self-
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; administered or not - purely in virtue of running some AI program,
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; however complex.  This is an empirical prediction, and will have to
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; await an empirical outcome.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; David
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; On Jun 5, 3:12 pm, Bruno Marchal &lt; marc....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Le 03-juin-07, à 21:52, Hal Finney a écrit :
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; Part of what I wanted to get at in my thought experiment is the
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; bafflement and confusion an AI should feel when exposed to human
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; ideas
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; about consciousness.  Various people here have proffered their
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; own
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; ideas, and we might assume that the AI would read these
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; suggestions,
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; along with many other ideas that contradict the ones offered
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; here.
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; It seems hard to escape the conclusion that the only logical
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; response
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; is for the AI to figuratively throw up its hands and say that it
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; is
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; impossible to know if it is conscious, because even humans
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; cannot agree
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; on what consciousness is.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Augustin said about (subjective) *time* that he knows perfectly
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; what it
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; is, but that if you ask him to say what it is, then he admits
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; being
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; unable to say anything. I think that this applies to
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; &quot;consciousness&quot;.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; We know what it is, although only in some personal and
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; uncommunicable
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; way.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Now this happens to be true also for many mathematical concept.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Strictly speaking we don't know how to define the natural numbers,
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; and
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; we know today that indeed we cannot define them in a communicable
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; way,
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; that is without assuming the auditor knows already what they are.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; So what can we do. We can do what mathematicians do all the time.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; We
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; can abandon the very idea of *defining* what consciousness is, and
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; try
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; instead to focus on principles or statements about which we can
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; agree
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; that they apply to consciousness. Then we can search for
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; (mathematical)
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; object obeying to such or similar principles. This can be made
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; easier
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; by admitting some theory or realm for consciousness like the idea
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; that
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; consciousness could apply to *some* machine or to some
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; *computational
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; events&quot; etc.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; We could agree for example that:
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; 1) each one of us know what consciousness is, but nobody can prove
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; he/she/it is conscious.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; 2) consciousness is related to inner personal or self-referential
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; modality
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; etc.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; This is how I proceed in &quot;Conscience et Mécanisme&quot;.  (&quot;conscience&quot;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; is
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; the french for consciousness, &quot;conscience morale&quot; is the french
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; for the
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; english &quot;conscience&quot;).
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; In particular I don't think an AI could be expected to claim
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; that it
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; knows that it is conscious, that consciousness is a deep and
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; intrinsic
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; part of itself, that whatever else it might be mistaken about it
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; could
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; not be mistaken about being conscious.  I don't see any logical
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; way it
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; could reach this conclusion by studying the corpus of writings
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; on the
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; topic.  If anyone disagrees, I'd like to hear how it could
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; happen.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; As far as a machine is correct, when she introspects herself, she
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; cannot not discover a gap between truth (p) and provability (Bp).
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; The
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; machine can discover correctly (but not necessarily in a
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; completely
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; communicable way) a gap between provability (which can potentially
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; leads to falsities, despite correctness) and the incorrigible
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; knowability or knowledgeability (Bp &amp; p), and then the gap between
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; those notions and observability (Bp &amp; Dp) and sensibility (Bp &amp; Dp
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; &amp;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; p). Even without using the conventional name of &quot;consciousness&quot;,
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; machines can discover semantical fixpoint playing the role of non
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; expressible but true statements.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; We can *already* talk with machine about those true unnameable
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; things,
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; as have done Tarski, Godel, Lob, Solovay, Boolos, Goldblatt, etc.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; And the corollary to this is that perhaps humans also cannot
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; legitimately
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; make such claims, since logically their position is not so
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; different
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; from that of the AI.  In that case the seemingly axiomatic
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; question of
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; whether we are conscious may after all be something that we
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; could be
</em><br />
<em class="quotelev2">&gt; &gt; &gt; &gt; &gt; &gt; mistaken about.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; This is an inference from &quot;I cannot express p&quot; to &quot;I can express
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; not
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; p&quot;. Or from ~Bp to B~p.  Many atheist reason like that about the
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; concept of &quot;unameable&quot; reality, but it is a logical error.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Even for someone who is not willing to take the comp hyp into
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; consideration, it is a third person communicable fact that
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; self-observing machines can discover and talk about many non
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; 3-provable
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; and sometimes even non 3-definable true &quot;statements&quot; about them.
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; Some
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; true statements can only be interrogated.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Personally I don' think we can be *personally* mistaken about our
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt; own
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; consciousness even if we can be mistaken about anything that
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; consciousness could be about.
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; Bruno
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev1">&gt; &gt; &gt; &gt; &gt; <a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>&lt;<a href="http://iridia.ulb.ac.be/%7Emarchal/">http://iridia.ulb.ac.be/%7Emarchal/</a>&gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev4">&gt; &gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev3">&gt; &gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue Jun 26 2007 - 17:11:07 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13649">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13650.html" title="Next message in the list">Russell Standish: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13648.html" title="Previous message in the list">John Mikes: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13648.html" title="Message to which this message replies">John Mikes: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13665.html" title="Next message in this discussion thread">Bruno Marchal: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13649" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13649" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13649" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13649" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
