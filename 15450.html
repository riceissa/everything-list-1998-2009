<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: MGA 1 from Brent Meeker on 2008-11-25 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: MGA 1" />
<meta name="Date" content="2008-11-25" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: MGA 1</h1>
<!-- received="Tue Nov 25 14:17:12 2008" -->
<!-- isoreceived="20081125221712" -->
<!-- sent="Tue, 25 Nov 2008 11:16:55 -0800" -->
<!-- isosent="20081125191655" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: MGA 1" -->
<!-- id="492C4F27.5090608.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="7EA52564-47B8-471F-B4A5-C5BED7756E4F.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start15450" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="15451.html" accesskey="d" title="Abram Demski: &quot;Re: join post&quot;">Next message</a> ]
[ <a href="15449.html" title="Bruno Marchal: &quot;Re: MGA 1&quot;">Previous message</a> ]
[ <a href="15449.html" title="Bruno Marchal: &quot;Re: MGA 1&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="15454.html" accesskey="t" title="Russell Standish: &quot;Re: MGA 1&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15450" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15450" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15450" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15450" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20MGA%201">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 25 Nov 2008 11:16:55 -0800</span><br />
</address>
<br />
Bruno Marchal wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; On 25 Nov 2008, at 15:49, Kory Heath wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; On Nov 25, 2008, at 2:55 AM, Bruno Marchal wrote:
</em><br />
<em class="quotelev3">&gt;&gt;&gt; So you agree that MGA 1 does show that Lucky Alice is conscious
</em><br />
<em class="quotelev3">&gt;&gt;&gt; (logically).
</em><br />
<em class="quotelev2">&gt;&gt; I think I have a less rigorous view of the argument than you do. You
</em><br />
<em class="quotelev2">&gt;&gt; want the argument to have the rigor of a mathematical proof.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Yes. But it is applied mathematics, in a difficult domain (psychology/ 
</em><br />
<em class="quotelev1">&gt; theology and foundation of physics).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; There is a minimum of common sense and candidness which is asked for.  
</em><br />
<em class="quotelev1">&gt; The proof is rigorous in the way it should give to anyone the feeling  
</em><br />
<em class="quotelev1">&gt; that it could be entirely formalized in some intensional mathematics,  
</em><br />
<em class="quotelev1">&gt; S4 with quantifiers, or in the modal variant of G and G*. This is  
</em><br />
<em class="quotelev1">&gt; eventually the purpose of the interview of the lobian machine (using  
</em><br />
<em class="quotelev1">&gt; Theaetetus epistemological definition). But this is normally not  
</em><br />
<em class="quotelev1">&gt; needed for &quot;conscious english speaking being with enough common sense  
</em><br />
<em class="quotelev1">&gt; and some interest in the matter&quot;.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; You say
</em><br />
<em class="quotelev2">&gt;&gt; &quot;Let's start with the mechanist-materialist assumption that Fully-
</em><br />
<em class="quotelev2">&gt;&gt; Functional Alice is conscious. We can replace her neurons one-by-one
</em><br />
<em class="quotelev2">&gt;&gt; with random neurons
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; They are random in the sense that ALL strings are random. They are not  
</em><br />
<em class="quotelev1">&gt; random in Kolmogorov sense for example. MGA 2 should make this clear.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; that just happen to do what the fully-functional
</em><br />
<em class="quotelev2">&gt;&gt; ones were going to do.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; It is not random for that very reason. It is luckiness in MGA 1, and  
</em><br />
<em class="quotelev1">&gt; the record of computations in MGA 2.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; By definition none of her exterior or interior
</em><br />
<em class="quotelev2">&gt;&gt; behavior changes.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I never use those terms in this context, except in comp jokes like  
</em><br />
<em class="quotelev1">&gt; &quot;the brain is in the brain&quot;. It is dangerous because interior/exterior  
</em><br />
<em class="quotelev1">&gt; can refer both to the in-the skull/outside-the-skull,  and objective/ 
</em><br />
<em class="quotelev1">&gt; subjective.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I just use the fact that you say &quot;yes&quot; to a doctor &quot;qua  
</em><br />
<em class="quotelev1">&gt; computatio&quot; (with or without MAT).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; Therefore, the resulting Lucky Alice must be exactly
</em><br />
<em class="quotelev2">&gt;&gt; as conscious as Fully-Functional Alice.&quot;
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; To me, this argument doesn't have the full rigor of a mathematical
</em><br />
<em class="quotelev2">&gt;&gt; proof, because it's not entirely clear what the mechanist-materialists
</em><br />
<em class="quotelev2">&gt;&gt; really mean when they say that Fully-Functional Alice is conscious,
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Consciousness does not need to be defined more precisely than it is  
</em><br />
<em class="quotelev1">&gt; needed for saying &quot;yes&quot; to the doctor qua computatio, like a  
</em><br />
<em class="quotelev1">&gt; naturalist could say &quot;yes&quot; for an artificial heart.
</em><br />
<em class="quotelev1">&gt; Consciousness and (primitive) Matter don't need to be defined more  
</em><br />
<em class="quotelev1">&gt; precisely than needed to understand the physical supervenience thesis.
</em><br />
<em class="quotelev1">&gt; Despite term like &quot;existence of a primitive physical universe&quot; or the  
</em><br />
<em class="quotelev1">&gt; very general &quot;supervenience&quot; term itself.
</em><br />
<em class="quotelev1">&gt; You could have perhaps still a problem with the definitions or with  
</em><br />
<em class="quotelev1">&gt; the hypotheses?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; and it's not clear whether or not they would agree that &quot;none of her
</em><br />
<em class="quotelev2">&gt;&gt; exterior or interior behavior changes (in any way that's relevant)&quot;.
</em><br />
<em class="quotelev2">&gt;&gt; There *is* an objective physical difference between Fully-Functional
</em><br />
<em class="quotelev2">&gt;&gt; Alice and Lucky Alice - it's precisely the (discoverable, physical)
</em><br />
<em class="quotelev2">&gt;&gt; fact that her neurons are all being stimulated by cosmic rays rather
</em><br />
<em class="quotelev2">&gt;&gt; than by each other.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; There is an objective difference between very young Alice with her  
</em><br />
<em class="quotelev1">&gt; &quot;biological brain&quot; and very young Alice the day after the digital  
</em><br />
<em class="quotelev1">&gt; graft. But taking both MEC and MAT together, you cannot use that  
</em><br />
<em class="quotelev1">&gt; difference. If you want use that difference, you have to make change  
</em><br />
<em class="quotelev1">&gt; to MEC and/or to MAT. You can always be confused by the reasoning in a  
</em><br />
<em class="quotelev1">&gt; way which pushes you to (re)consider MEC or MAT, and to interpret them  
</em><br />
<em class="quotelev1">&gt; more vaguely so that those changes are made possible. But then we  
</em><br />
<em class="quotelev1">&gt; learn nothing &quot;clear&quot; from the reasoning. We learn if we do the same,  
</em><br />
<em class="quotelev1">&gt; but precisely.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; I don't see why the mechanist-materialists are
</em><br />
<em class="quotelev2">&gt;&gt; logically disallowed from incorporating that kind of physical
</em><br />
<em class="quotelev2">&gt;&gt; difference into their notion of consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; In our setting, it means that the neuron/logic gates have some form of  
</em><br />
<em class="quotelev1">&gt; prescience.
</em><br />
<br />I'm not sure I agree with that.  If consciousness is a process it may be 
<br />
instantiated in physical relations (causal?).  But relations are in general not 
<br />
attributes of the relata.  Distance is an abstract relation but it is always 
<br />
realized as the distance between two things.  The things themselves don't have 
<br />
&quot;distance&quot;.  If some neurons encode my experience of &quot;seeing a rose&quot; might not 
<br />
the experience depend on the existence of roses, the evolution of sight, and the 
<br />
causal chain as well as the immediate state of the neurons?
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Of course, in practice, Lucky Alice presents a conundrum for such
</em><br />
<em class="quotelev2">&gt;&gt; mechanist-materialists. But it's not obvious to me that the conundrum
</em><br />
<em class="quotelev2">&gt;&gt; is unanswerable for them, because the whole notion of &quot;consciousness&quot;
</em><br />
<em class="quotelev2">&gt;&gt; in this context seems so vague.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; No, what could be vague is the idea of linking consciousness with  
</em><br />
<em class="quotelev1">&gt; matter, but that is the point of the reasoning. If we keep comp, we  
</em><br />
<em class="quotelev1">&gt; have to (re)define the general notion of matter.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; Bostrom's views about fractional
</em><br />
<em class="quotelev2">&gt;&gt; &quot;quantities&quot; of experience are a case in point.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; If that was true, why would you say &quot;yes&quot; to the doctor without  
</em><br />
<em class="quotelev1">&gt; knowing the thickness of the artificial axons?
</em><br />
<em class="quotelev1">&gt; How can you be sure your consciousness will not half diminish when the  
</em><br />
<em class="quotelev1">&gt; doctor proposes to you the new cheaper brain which use thinner fibers,  
</em><br />
<em class="quotelev1">&gt; or half the number of redundant security fibers (thanks to a progress  
</em><br />
<em class="quotelev1">&gt; in security software)?
</em><br />
<em class="quotelev1">&gt; I would no more dare to say &quot;yes&quot; to the doctor if I could loose a  
</em><br />
<em class="quotelev1">&gt; fraction of my consciousness and become a partial zombie.
</em><br />
<br />But who would say &quot;yes&quot; to the doctor if he said that he would take a movie of 
<br />
your brain states and project it?  Or if he said he would just destroy you in 
<br />
this universe and you would continue your experiences in other branches of the 
<br />
multiverse or in platonia?  Not many I think.
<br />
<br />Brent
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; He clearly takes a
</em><br />
<em class="quotelev2">&gt;&gt; mechanist-materialist view of consciousness,
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Many believes in naturalism. At least, its move shows that he is aware  
</em><br />
<em class="quotelev1">&gt; of the difficulty of the mind body problem. But he has to modify comp  
</em><br />
<em class="quotelev1">&gt; deeply, for making its move meaningful.
</em><br />
<em class="quotelev1">&gt; If anything physical/geometrical about the neurons is needed, let the  
</em><br />
<em class="quotelev1">&gt; digital machine take into account that physical/geometrical feature.  
</em><br />
<em class="quotelev1">&gt; This means, let the level be refined. But once the level is correctly  
</em><br />
<em class="quotelev1">&gt; choose, comp forces us to abstract from the functioning of the  
</em><br />
<em class="quotelev1">&gt; elementary boolean gates.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; and he believes that a
</em><br />
<em class="quotelev2">&gt;&gt; grid of randomly-flipping bits cannot be conscious,
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; (I am ok with that. I mean, this will remain true both with comp and  
</em><br />
<em class="quotelev1">&gt; NON MAT).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt; no matter what it
</em><br />
<em class="quotelev2">&gt;&gt; does. He would argue that, during Fully-Functional Alice's slide into
</em><br />
<em class="quotelev2">&gt;&gt; Lucky Alice, her subjective quality of consciousness doesn't change,
</em><br />
<em class="quotelev2">&gt;&gt; but her &quot;quantity&quot; of consciousness gradually reduces until it becomes
</em><br />
<em class="quotelev2">&gt;&gt; zero. That seems weird to me, but I don't see how to &quot;logically prove&quot;
</em><br />
<em class="quotelev2">&gt;&gt; that it's wrong. All I have are messy philosophical arguments and
</em><br />
<em class="quotelev2">&gt;&gt; thought experiments - what Dennett calls &quot;intuition pumps&quot;.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Because I would have to say NO to the doctor who proposes me a digital  
</em><br />
<em class="quotelev1">&gt; neural net with &quot;infinitesimally&quot; or very thin but solid fibers&quot;. I  
</em><br />
<em class="quotelev1">&gt; would become a zombie if Bostrom is right. Bostrom does not use the  
</em><br />
<em class="quotelev1">&gt; digital MEC hypothesis.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; That being said, I'm happy to proceed as if our hypothetical  
</em><br />
<em class="quotelev2">&gt;&gt; mechanist-
</em><br />
<em class="quotelev2">&gt;&gt; materialists have accepted the force of your argument as a logical
</em><br />
<em class="quotelev2">&gt;&gt; proof. Yes, they claim, given the assumptions of our mechanism-
</em><br />
<em class="quotelev2">&gt;&gt; materialism, if Fully-Functional Alice is conscious, Lucky Alice must
</em><br />
<em class="quotelev2">&gt;&gt; *necessarily* also be conscious. If the laser-graph is conscious, then
</em><br />
<em class="quotelev2">&gt;&gt; the movie of it must *necessarily* be conscious. What's the problem
</em><br />
<em class="quotelev2">&gt;&gt; (they ask)? On to MGA 3.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Hmmm.... (asap). Still disentangling MGA 3 and MGA 4 ...
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Bruno
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; <a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue Nov 25 2008 - 14:17:12 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start15450">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="15451.html" title="Next message in the list">Abram Demski: "Re: join post"</a></li>
<li><dfn>Previous message</dfn>: <a href="15449.html" title="Previous message in the list">Bruno Marchal: "Re: MGA 1"</a></li>
<li><dfn>In reply to</dfn>: <a href="15449.html" title="Message to which this message replies">Bruno Marchal: "Re: MGA 1"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="15454.html" title="Next message in this discussion thread">Russell Standish: "Re: MGA 1"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="15454.html" title="Message sent in reply to this message">Russell Standish: "Re: MGA 1"</a></li>
<li><dfn>Reply</dfn>: <a href="15461.html" title="Message sent in reply to this message">Bruno Marchal: "Re: MGA 1"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15450" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15450" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15450" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15450" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
