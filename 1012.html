<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Fwd: Implementation/Relativity from GSLevy.domain.name.hidden on 1999-07-27 (everything)</title>
<meta name="Author" content="GSLevy.domain.name.hidden (GSLevy.domain.name.hidden)" />
<meta name="Subject" content="Fwd: Implementation/Relativity" />
<meta name="Date" content="1999-07-27" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Fwd: Implementation/Relativity</h1>
<!-- received="Tue Jul 27 15:38:13 1999" -->
<!-- isoreceived="19990727223813" -->
<!-- sent="Tue, 27 Jul 1999 18:34:12 EDT" -->
<!-- isosent="19990727223412" -->
<!-- name="GSLevy.domain.name.hidden" -->
<!-- email="GSLevy.domain.name.hidden" -->
<!-- subject="Fwd: Implementation/Relativity" -->
<!-- id="e65644bc.24cf8de4.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start1012" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1013.html" accesskey="d" title="Hans Moravec: &quot;Re: Implementation&quot;">Next message</a> ]
[ <a href="1011.html" title="Jacques M Mallah: &quot;Re: Implementation&quot;">Previous message</a> ]
<!-- unextthread="start" -->
[ <a href="1016.html" accesskey="t" title="Russell Standish: &quot;Re: Fwd: Implementation/Relativity&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1012" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1012" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1012" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1012" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: &lt;<a href="mailto:GSLevy.domain.name.hidden?Subject=Re%3A%20Fwd%3A%20Implementation%2FRelativity">GSLevy.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 27 Jul 1999 18:34:12 EDT</span><br />
</address>
<br />
Thank you Bruno for your usual very detailed response to everybodies' posts. 
<br />
What I like about you is your thoroughness and the fact that you seem to 
<br />
agree with everybody ( if not 100%, at least to some extent).
<br />
<br />I'll be in vacation for the next couple of weeks. So here is my last post for 
<br />
a while.
<br />
<br />Hans writes
<br />
<em class="quotelev2">&gt;&gt;
</em><br />
Russell Standish &lt;R.Standish.domain.name.hidden&gt;:
<br />
<em class="quotelev1">&gt; ... However, it is always possible to _artificially_ construct a
</em><br />
<em class="quotelev1">&gt; system to pass the Turing test that isn't concious.
</em><br />
<br />Balderdash!&gt;&gt;
<br />
<br />Hans is very succint so it's not clear if his deprecation is about building a 
<br />
Turing machine that can pass the Turing test or a Turing machine that is 
<br />
conscious or both of the above. So I may or may not agree with him.
<br />
<br />A lot of discussion has been made about consciousness as if it was an 
<br />
objective, absolute quantity. And yet the only way to measure consciousness 
<br />
is by means of a relative test: the Turing test. Basically this test COMPARES 
<br />
the performance of a machine to a human. 
<br />
<br />I think that the only way to meaningfully &quot;measure&quot; consciousness is by means 
<br />
of a Turing test. So by definition if a machine passes the Turing test then 
<br />
it is conscious. If it doesn't then it isn't. It is understood that the 
<br />
Turing test will not be a superficial examination, but a thorough evaluation 
<br />
evolving measuring intellectual as well as emotional (even irrational) 
<br />
responses to a wide variety of situations. If the machine behaves like a 
<br />
human, then it should be entitled to all human rights under the law. If it 
<br />
behaves partially as a human, say in the intellectual domain but not in the 
<br />
emotional one, then, in relativistic terms, it differs from the human in that 
<br />
respect. Its consciousness STILL EXISTS BUT IS DIFFERENT from the human. 
<br />
<br />Similarly, a humans twin pretending to be the other twin, may not be capable 
<br />
of passing a Turing test aimed at finding out who he really is. This only 
<br />
proves that THE TWINS HAVE DIFFERENT CONSCIOUSNESS UNDER THIS PARTICULAR 
<br />
TURING TEST.
<br />
<br />Now the kicker!. Had the Turing test not be capable of distinguishing the 
<br />
twin from his sibling, then UNDER THIS TURING TEST, THE TWINS WOULD HAVE THE 
<br />
SAME - IDENTICAL CONSCIOUSNESS!!! They would be the same person! Is this a 
<br />
paradox? Not at all. It is the same kind of situation generated when two 
<br />
persons, one in motion with respect to the other measure the velocity of an 
<br />
arbitrary object. They conclude that the object is animated with a different 
<br />
velocity with respect to their own frame of reference. 
<br />
<br />Thus a given person/machine will have a different consciousness depending on 
<br />
who is doing the observing. The &quot;observer&quot; could be a Turing test as well as 
<br />
a full fledged human, equipped with his own consciousness. The feeling of 
<br />
**I** is the self observing the self in an infinite recursion loop.
<br />
<br />Thus, I propose that consciousness is a full fledged relativistic quantity. 
<br />
As such I must define how to specify its frame of reference. The frames of 
<br />
reference consists of information: That contained in the mind of the observed 
<br />
object and that contained in the mind of the observer. The information of 
<br />
interest is the mutual information which is the the difference between the 
<br />
two.
<br />
<br />I would like to formalize the argument by comparing the information contained 
<br />
in the mind and in Turing tests to information constained in axiomatic 
<br />
mathematical systems. The full power of Goedel's incompleteness theorems 
<br />
could then be brought to bear. Some &quot;truth&quot; may not be provable within the 
<br />
system, similarly, the twins may not be distinguishable by a given Turing 
<br />
test and a machine may &quot;appear&quot; to be human, simply because the observing 
<br />
apparatus (human or test) does not have the power to distinguish it from a 
<br />
human.
<br />
<br />Some of you may argue that even if a test is not capable of distinguishing 
<br />
between two consciousness, these consciousness have an objective, absolute 
<br />
reality. There is no way, however, to prove such an assertion independently 
<br />
of the Turing test process.
<br />
<br />Wish me a good vacation!  :-)
<br />
<br />George
<br />
<br /><p><strong>attached mail follows:</strong></p><hr /><br />
<br />I will make some comments on the last posts. But we are entering in 
<br />
very deep
<br />
waters and I would like to make general remarks. 
<br />
<br />I said it before, but I want
<br />
repeat it here. One of my main goal is to understand what is &quot;the
<br />
physical&quot; and where does it comes from. And like Wheeler I don't think 
<br />
that this can be explain by physical laws. 
<br />
<br />With Ockham razor there is no need of
<br />
the crackpot/Maudlin argument, the UD argument (PE-omega) is quasi-enough 
<br />
to convince oneself
<br />
that the 'universal part' of physics must be extract from computer 
<br />
science.
<br />
<br />Note also that the 'reversal' is in both Tegmark and Schmidhuber (it 
<br />
seems to me), but they
<br />
haven't see the measure problem (do they ?), and they havent' put their 
<br />
methodology to its logical extreme.
<br />
<br />Another general remark is that, in your post, I agree sometimes whith 
<br />
what you are saying until you jump to a conclusion which I don't 
<br />
understand.
<br />
<br /><br />George Levy wrote:
<br />
<br /><em class="quotelev1">&gt;Similarly, the insertion of the piece of wood in the computer must be done 
</em><br />
<em class="quotelev1">&gt;by 
</em><br />
<em class="quotelev1">&gt;someone. Let's call that someone Maudlin's demon.  Deciding what the right 
</em><br />
<em class="quotelev1">&gt;place and the right time is to make the wood irrelevent to the thinking 
</em><br />
<em class="quotelev1">&gt;process, in order to satisfy the counterfactual role that the wood must 
</em><br />
<em class="quotelev1">&gt;play, 
</em><br />
<em class="quotelev1">&gt;requires Maudlin's demon to think. Maudlin's demon then becomes part of the 
</em><br />
<em class="quotelev1">&gt;computer's consciousness just like the subject in the chinese room 
</em><br />
<em class="quotelev1">&gt;experiment 
</em><br />
<em class="quotelev1">&gt;becomes a cog in the chinese room ability to speak chinese.
</em><br />
<br />An interesting similar (although computationalist) move  has been made
<br />
by Eric Barnes &quot;The causal history of computational activity: Maudlin and
<br />
Olympia. (The journal of philosophy 1991, pp 304-316.) 
<br />
What is interesting for me is that Barnes'move forces him to pretend
<br />
having the ability to distinguish between being awake and being dreaming
<br />
(which I doubt), (which contredict also my theetetic self-referential
<br />
theory of knowledge where p is known when p is justified by the machine 
<br />
and true or just consistent).
<br />
<br />George Levy wrote:
<br />
<br /><em class="quotelev1">&gt;In the end, I am a strong sceptic of both computationalism and physical 
</em><br />
<em class="quotelev1">&gt;supervenience. I believe that consciousness exists only in the eyes of the 
</em><br />
<em class="quotelev1">&gt;beholder, and is a relativistic property, based on the relativity of 
</em><br />
<em class="quotelev1">&gt;(mutual) 
</em><br />
<em class="quotelev1">&gt;information as defined by Claude Shannon.
</em><br />
<br />I am definitely open to the idea that consciousness exists only in the 
<br />
eyes of the beholder, that it is a relativistic property, based on the
<br />
relativity of mutual information as defined by Claude Shannon, Kolmogorov,
<br />
and as used by Everett (but see also the paper of Adami and Cerf in the
<br />
quant-ph).
<br />
<br /><br />Hans Moravec wrote:
<br />
<br /><em class="quotelev1">&gt;So, deterministic machines can have just as much free will as you or
</em><br />
<em class="quotelev1">&gt;I.  The key is that they don't know everything that's going on,
</em><br />
<em class="quotelev1">&gt;outside themselves or in, so often don't know what will happen next,
</em><br />
<em class="quotelev1">&gt;or how they will respond to it.  Many-worlds may provide an
</em><br />
<em class="quotelev1">&gt;interesting additional &quot;source&quot; of ignorance, but limitations on what
</em><br />
<em class="quotelev1">&gt;a finite process can model already provide sufficient ignorance for
</em><br />
<em class="quotelev1">&gt;free will even in a fully deterministic framework.
</em><br />
<br />I agree. What MW or self-duplication adds is truly random uncertainty.
<br />
This is &quot;testify&quot; by quantum computers.
<br />
I don't think determinism is an &quot;effective&quot; problem for free-will,
<br />
nor do I think randomization can help in making free-will possible.
<br />
I think free-will is related with the boundary of self-knowledge.
<br />
<br /><br />Hal Finney wrote:
<br />
<br /><em class="quotelev1">&gt;But more than one computation can be conscious, obviously.  It is
</em><br />
<em class="quotelev1">&gt;conceivable that the new computation, although different, is conscious
</em><br />
<em class="quotelev1">&gt;as well.  This is a possible escape from Maudlin's argument.
</em><br />
<br /><em class="quotelev1">&gt; [...]
</em><br />
<br />Are the content of consciousness different ? or the intensity are
<br />
different ? I'm not sure I understand.
<br />
<br />HF:
<br />
<em class="quotelev1">&gt;So it seems to me we need a new argument for why the computer sans
</em><br />
<em class="quotelev1">&gt;counterfactuals should not be considered conscious.
</em><br />
<br /><em class="quotelev1">&gt; [...]
</em><br />
<br />It seems to me that a computer without counterfactuals is like
<br />
a doll, a teddy bear, or a sculpture.
<br />
Unlike Hans I don't understand what would it mean to ascribe them 
<br />
consciousness.
<br />
<br />HF:
<br />
<em class="quotelev1">&gt;One of the thins which is attractive about Wei's approach, as I understand
</em><br />
<em class="quotelev1">&gt;it, is that it does not try to answer the question of whether a given
</em><br />
<em class="quotelev1">&gt;system is conscious, at least not in yes-or-no terms.  Rather, it tries
</em><br />
<em class="quotelev1">&gt;to give a probability that a given system is conscious, and specifically
</em><br />
<em class="quotelev1">&gt;that it instantiates a particular consciousness, such as my own.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;This allows you to have such things as systems which are &quot;probably&quot;
</em><br />
<em class="quotelev1">&gt;conscious, or, in a sense, &quot;partially&quot; conscious (in the sense that
</em><br />
<em class="quotelev1">&gt;we can treat them as having a 10% chance of being conscious, say).
</em><br />
<em class="quotelev1">&gt;This interpretation makes most sense in the context of the Strong
</em><br />
<em class="quotelev1">&gt;Self-Selection Assumption (that we can consider our moments of experience
</em><br />
<em class="quotelev1">&gt;as randomly chosen from among all observer-moments).  The probabilities
</em><br />
<em class="quotelev1">&gt;assigned to consciousness serve as a weighting factor for how much they
</em><br />
<em class="quotelev1">&gt;contribute to the ensemble of all observer-moments.
</em><br />
<br />I agree and I appreciate very much this way of seeing the things. It is
<br />
linked (from my humble understanding) to James Higgo's anthropic 
<br />
principle/occam-razor. This 'interpretation' along with comp leads to
<br />
a total reversal ....but in the relative way (I will not insist here).
<br />
I do link consciousness with machine's inference about their own possible
<br />
consistent extensions. 
<br />
<br /><br />David Seaman wrote:
<br />
<br /><em class="quotelev1">&gt;This seems an excellent viewpoint, consciousness requires the freedom to
</em><br />
<em class="quotelev1">&gt;react to a reasonably wide range of circumstances in a way which is not
</em><br />
<em class="quotelev1">&gt;predictable to other observers.  So a single execution can never confirm or
</em><br />
<em class="quotelev1">&gt;deny consciousness however many times it is replayed.  But I'm not so sure
</em><br />
<em class="quotelev1">&gt;that a Turing machine cannot have free will.  I'd guess that the appearance
</em><br />
<em class="quotelev1">&gt;of free will can emerge from a sufficiently complex TM provided that the TM
</em><br />
<em class="quotelev1">&gt;exists in a suitably complex environment.  If a person built a machine
</em><br />
<em class="quotelev1">&gt;containing a TM it would be part of our MWI universe and the requirements
</em><br />
<em class="quotelev1">&gt;could be satisfied.  This would not be an isolated TM since it would be
</em><br />
<em class="quotelev1">&gt;simulated by and react to its environment, and any 'randomness' requirement
</em><br />
<em class="quotelev1">&gt;could actually involve a sensitivity to gravitons, photons, or quantum
</em><br />
<em class="quotelev1">&gt;interference.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;I tend to agree that a completely isolated TM is unlikely to have free will
</em><br />
<em class="quotelev1">&gt;or be conscious (and in any case it would be impossible to test it).  Of
</em><br />
<em class="quotelev1">&gt;course the program executed by an isolated TM may well be able to generate
</em><br />
<em class="quotelev1">&gt;a universe containing conscious subjects.  In the special case of an
</em><br />
<em class="quotelev1">&gt;isolated TM generating a universe which contains exactly one conscious
</em><br />
<em class="quotelev1">&gt;subject in a suitable environment it could loosely be said that the TM's
</em><br />
<em class="quotelev1">&gt;program is that conscious subject.  But this is different to saying that
</em><br />
<em class="quotelev1">&gt;the TM itself is conscious, and it would not be apparent from looking at
</em><br />
<em class="quotelev1">&gt;the TM that it was generating consciousness.
</em><br />
<br />I agree in part. It is easy to build version of dreaming Olympia.
<br />
A dreaming machine would be, at least here and now, an isolated 
<br />
'conscious'
<br />
(but not necessarily awake) machine.
<br />
I think an isolated 'conscious' machine cannot be isolate for ever for 
<br />
purely computational reasons.
<br />
<br /><br />Jacques Mallah wrote:
<br />
<br /><em class="quotelev1">&gt;	Bruno, I think it is now abundently clear that Maudlin's paper
</em><br />
<em class="quotelev1">&gt;does not rule out physical computationalism, and other people on the list
</em><br />
<em class="quotelev1">&gt;have seen that as well.
</em><br />
<br />Clear would be enough. Abundently clear is a little to much.
<br />
<br />I don't understand what really means 'physical' in physical 
<br />
computationalism.
<br />
It is clear that we have not the same primitive elements.
<br />
I believe in numbers and number's dreams. Some dreams are deep and
<br />
partially sharable among UTMs, those are their relative realities.
<br />
<br />I appreciate the everythinger's work on these questions, and I guess it
<br />
is not easy to abandon the physical supervenience thesis.
<br />
<br /><br />Russell Standish wrote:
<br />
<br /><em class="quotelev2">&gt; &gt; Chris, this is a well thought out reponse, and it persuades me that
</em><br />
<em class="quotelev2">&gt; &gt; the difference between conciousness and nonconciousness could be as
</em><br />
<em class="quotelev2">&gt; &gt; little as the &quot;inert block of wood&quot;, precisely because it is a
</em><br />
<em class="quotelev2">&gt; &gt; physically different system. It actually reminds me of the quantum 2
</em><br />
<em class="quotelev2">&gt; &gt; split experiment. An interference pattern is seen, or not seen
</em><br />
<em class="quotelev2">&gt; &gt; according to whether a detector placed at one of the slits is switched
</em><br />
<em class="quotelev2">&gt; &gt; on or not.
</em><br />
<br /><em class="quotelev1">&gt; [...]
</em><br />
<br />1) The great programmer dovetail also on the quantum turing machines...
<br />
2) I think so. There is a deeper analogy between the computationalist's
<br />
counterfactuals and the quantum. This is linked to a paper by Hardegree
<br />
showing a formal similarity between a very natural definition of 'quantum
<br />
implication' and Stalnaker's logic of counterfactual and my own definition
<br />
of 'observation'. (ref. in my thesis), and the resulting arithmetical
<br />
&quot;quantum logic&quot;.
<br />
<br /><em class="quotelev1">&gt;Thinking about this some more, I realise this is exactly what is going
</em><br />
<em class="quotelev1">&gt;on. Consider Olympia from a MWI point of view. For the vast majority
</em><br />
<em class="quotelev1">&gt;of worlds containing Olympia, Karas (I believe that is what the
</em><br />
<em class="quotelev1">&gt;correcting machinery is called) is active, handling the
</em><br />
<em class="quotelev1">&gt;counterfactuals. Only on one world line (of measure zero!) is Karas
</em><br />
<em class="quotelev1">&gt;inactive, and Olympia is simply replaying the previously recorded
</em><br />
<em class="quotelev1">&gt;data.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Now consider what happens when Karas is turned off, or prevented from
</em><br />
<em class="quotelev1">&gt;operating. Then, in all world lines is Olympia simply a replay
</em><br />
<em class="quotelev1">&gt;device. From the MWI point of view, the simple inert piece of wood is
</em><br />
<em class="quotelev1">&gt;not so innocuous. It changes the systems dynamics completely.
</em><br />
<br />OK.
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Now this has bearing on a supposition I have argued earlier - that
</em><br />
<em class="quotelev1">&gt;conciousness requires free will, and the only way to have free will is
</em><br />
<em class="quotelev1">&gt;via the MWI picture.
</em><br />
<br />Not OK. See above. 
<br />
<br /><em class="quotelev1">&gt;In this context, a Turing machine can never be
</em><br />
<em class="quotelev1">&gt;concious, because it follows a preprogrammed path, without free
</em><br />
<em class="quotelev1">&gt;will. Note this is not the same as saying comp is false, unless you
</em><br />
<em class="quotelev1">&gt;strictly define computers to be Turing machines. 
</em><br />
<br />I do. It is my working hypothesis.
<br />
<br /><em class="quotelev1">&gt;My suspicion is that
</em><br />
<em class="quotelev1">&gt;adding a genuine random number generator to the machine may be
</em><br />
<em class="quotelev1">&gt;sufficient to endow the architecture with free will, however, of
</em><br />
<em class="quotelev1">&gt;course the question is unresolved.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;What does this all mean for your thesis Bruno? Alas I didn't follow
</em><br />
<em class="quotelev1">&gt;your argument (not because it was written in French - which I have no
</em><br />
<em class="quotelev1">&gt;problem with, rather because I was not familiar with the modal logic
</em><br />
<em class="quotelev1">&gt;you employed, and haven't raised enough enthusiasm to follow up the
</em><br />
<em class="quotelev1">&gt;references). Could it be implying that you have too restrictive
</em><br />
<em class="quotelev1">&gt;definitions of both comp and sup-phys?
</em><br />
<br />Church's Thesis is a vaccin against any restrictive interpretation
<br />
of comp.  Comp makes the unknown much bigger that we have ever thought.
<br />
Even if from the archimedian point of view there are only numbers 
<br />
relationships.
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Quote from Bruno follows:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; This seems rather magical to me. If only because, for a
</em><br />
<em class="quotelev2">&gt;&gt; computationalist,
</em><br />
<em class="quotelev2">&gt;&gt; the only role of the inert block (during the particular execution) is
</em><br />
<em class="quotelev2">&gt;&gt; to 
</em><br />
<em class="quotelev2">&gt;&gt; explain why the machine WOULD have give a correct answer in case the
</em><br />
<em class="quotelev2">&gt;&gt; inputs WOULD have been different.
</em><br />
<em class="quotelev2">&gt;&gt; This mean that you don't associate consciousness with a particular
</em><br />
<em class="quotelev2">&gt;&gt; physical computation but with the entire set of possible computations.
</em><br />
<em class="quotelev2">&gt;&gt; But that is exactly what I do ..., and what I mean by the abandon
</em><br />
<em class="quotelev2">&gt;&gt; of physical supervenience.
</em><br />
<em class="quotelev2">&gt;&gt; A singular brain's activity becomes an invention of the mind.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Could it mean that you are defining sup-phys to be supervenience on
</em><br />
<em class="quotelev1">&gt;the one track classical physics, rather than on the MWI style quantum
</em><br />
<em class="quotelev1">&gt;physics?
</em><br />
<br />Most people in cognitive science do but I do not care about the level of
<br />
duplication.
<br />
&nbsp;
<br />
I think that ANY sufficiently patient self-referentially correct
<br />
machines, either by introspection or by observation (or a mixture of 
<br />
both), will infer MWI-like physics (once observing below their level of
<br />
&nbsp;duplication, for example).
<br />
<br />Bruno
<br />
<span id="received"><dfn>Received on</dfn> Tue Jul 27 1999 - 15:38:13 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start1012">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1013.html" title="Next message in the list">Hans Moravec: "Re: Implementation"</a></li>
<li><dfn>Previous message</dfn>: <a href="1011.html" title="Previous message in the list">Jacques M Mallah: "Re: Implementation"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1016.html" title="Next message in this discussion thread">Russell Standish: "Re: Fwd: Implementation/Relativity"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1016.html" title="Message sent in reply to this message">Russell Standish: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1018.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1024.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1029.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1030.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1032.html" title="Message sent in reply to this message">hal.domain.name.hidden: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1036.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1037.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1038.html" title="Message sent in reply to this message">hal.domain.name.hidden: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1040.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1042.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1044.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1045.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1046.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1048.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1049.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1054.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1055.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1057.html" title="Message sent in reply to this message">Hans Moravec: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="1065.html" title="Message sent in reply to this message">Higgo James: "RE: Fwd: Implementation/Relativity"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1012" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1012" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1012" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1012" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
