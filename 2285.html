<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: PhD-thesis on Observational Selection Effects from Jacques Mallah on 2000-11-17 (everything)</title>
<meta name="Author" content="Jacques Mallah (jackmallah.domain.name.hidden)" />
<meta name="Subject" content="Re: PhD-thesis on Observational Selection Effects" />
<meta name="Date" content="2000-11-17" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: PhD-thesis on Observational Selection Effects</h1>
<!-- received="Fri Nov 17 15:08:04 2000" -->
<!-- isoreceived="20001117230804" -->
<!-- sent="Fri, 17 Nov 2000 17:50:12 EST" -->
<!-- isosent="20001117225012" -->
<!-- name="Jacques Mallah" -->
<!-- email="jackmallah.domain.name.hidden" -->
<!-- subject="Re: PhD-thesis on Observational Selection Effects" -->
<!-- id="F45RaNgEpTX5V3GykBb00001140.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="PhD-thesis on Observational Selection Effects" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start2285" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="2286.html" accesskey="d" title="Hal Ruhl: &quot;Eliminating the machine&quot;">Next message</a> ]
[ <a href="2284.html" title="Hal Ruhl: &quot;simpler yet restated - ouch&quot;">Previous message</a> ]
[ <a href="2081.html" title="Bostrom,N  (pg): &quot;PhD-thesis on Observational Selection Effects&quot;">Maybe in reply to</a> ]
<!-- unextthread="start" -->
[ <a href="2210.html" accesskey="t" title="Nick Bostrom: &quot;Re: Re: PhD-thesis on Observational Selection Effects&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg2285" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg2285" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg2285" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg2285" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Jacques Mallah &lt;<a href="mailto:jackmallah.domain.name.hidden?Subject=Re%3A%20PhD-thesis%20on%20Observational%20Selection%20Effects">jackmallah.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 17 Nov 2000 17:50:12 EST</span><br />
</address>
<br />
&nbsp;&nbsp;&nbsp;&nbsp;This is a rewrite of a post I tried to send at an earlier date, but it 
<br />
got lost.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;By the way, at the end of October I attended the Plank symposium at the 
<br />
Univ. of Puget Sound (in Washington state).  It was interesting, a lot of 
<br />
history as well as QM, and I gave a talk on my approach to QM.  The paper 
<br />
report will contain some of my latest ideas, only a litle bit about the AUH 
<br />
though.  It was also interesting to meet some people who are well known 
<br />
within the field such as James Hartle and Roland Omnes (as well as people 
<br />
who are less known).  I asked Hartle if he believes the MWI, and he still 
<br />
couldn't give a straight answer.  (He would not say he doesn't, but seems 
<br />
not to care about the distinction between MWI and Copenhagen.  He does 
<br />
reject hidden variables.)  Omnes seemed open to the idea of computationalism 
<br />
but had his doubts.
<br />
<br />From: &quot;Nick Bostrom&quot; &lt;nick.bostrom.domain.name.hidden&gt;:
<br />
<em class="quotelev1">&gt;Even assuming that Adam is 100% certain about the truth of MWI [...] and 
</em><br />
<em class="quotelev1">&gt;even assuming he knows that for a typical day the effective probability of 
</em><br />
<em class="quotelev1">&gt;Deer is 1%, it is still not in general the case that he should think that 
</em><br />
<em class="quotelev1">&gt;there is a 1% probability of Deer that morning.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;If by &quot;probability&quot; you mean effective probability, please say so.    
<br />
Also, it would help to distinguish the effective probability from the 
<br />
Bayesian probability, with the only difference being that the former is 
<br />
defined given an initial wavefunction of the universe (and can be defined 
<br />
objectively), but the latter includes his uncertainty about that 
<br />
wavefunction.
<br />
<br /><em class="quotelev1">&gt;The reason why I was suspecting that you were confusing objective and 
</em><br />
<em class="quotelev1">&gt;subjective probabilities is that I thought you were claiming that Adam 
</em><br />
<em class="quotelev1">&gt;should assign a credence of 1% to deer turning up.  If you admit that Adam 
</em><br />
<em class="quotelev1">&gt;should believe that the probability of Deer (giving him forming the right 
</em><br />
<em class="quotelev1">&gt;intentions) is very great even though he knows that the effective 
</em><br />
<em class="quotelev1">&gt;probability of Deer on a typical day is only 1%, then my
</em><br />
ground for suspecting this confusion vanishes.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;That's wrong.  With the MWI, if on a typical day there is a 1% chance, 
<br />
then for any reasonable simple (thus subjectively likely assuming he uses 
<br />
Occam's razor) initial wavefunction of the universe, the effective 
<br />
probability on that day will still be 1% and so his Bayesian probability of 
<br />
seeing the deer would be very close to 1% regardless of what intentions he 
<br />
forms.
<br />
<br /><em class="quotelev2">&gt;&gt;So, in both the non-MWI and the MWI case, p~=.01 is his prior probability 
</em><br />
<em class="quotelev2">&gt;&gt;before he considers his own situation regarding reproduction, but the 
</em><br />
<em class="quotelev2">&gt;&gt;effect of the latter is different.  So far I think you agree with that.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;Yes, I think that's right so far.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;Then you should agree with what I've been saying.
<br />
<br /><em class="quotelev3">&gt;&gt;&gt;(Note that I'm talking about an objective chance here which varies from 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;day to day, depending on what the deer in the region are up to. The more 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;deer nearby, the greater the objective physical chance that some will 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;pass by Adam's cave within a certain time interval.)
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;    In the MWI, btw, there would be little such variation since one must 
</em><br />
<em class="quotelev2">&gt;&gt;sum over the branches desribing the various deer activities.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;Over time, the objective probabilities might get smeared out into a general 
</em><br />
<em class="quotelev1">&gt;deer-fog over the whole region. But at the beginning of the world, the 
</em><br />
<em class="quotelev1">&gt;objective deer-probability will be concentrated where the initial 
</em><br />
<em class="quotelev1">&gt;conditions say that the deer start out.
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;First, for the initial conditions to be so complicated as to even 
<br />
include deer is extremely unlikely.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Even supposing this incredible situation though, the &quot;fog&quot; as you call 
<br />
it would &quot;smear&quot; rather quickly.  Deer thoughts, like weather, are chaotic 
<br />
and thus the system will bifurcate often.  In the time it would take Adam to 
<br />
establish the 1% per day rule, the &quot;deer fog&quot; would be completely smeared.  
<br />
If Adam (or, I should say, the many Adams in the many branches) know this 
<br />
his Bayesian probability of seeing the wounded deer would quickly approach 
<br />
the true effective probability of 1% regardless of his intentions.
<br />
<br /><em class="quotelev3">&gt;&gt;&gt;2. Adam might not know contemporary physics.
</em><br />
<em class="quotelev2">&gt;&gt;    Irrelevant.
</em><br />
<em class="quotelev1">&gt;No, that's very relevant, because if Adam does not know contemporary
</em><br />
physics then he has no reason to think that MWI is true, and then he would 
<br />
have no reason not to assign such a &quot;ludicrously high&quot; probability as 50% to 
<br />
the idea that the MWI might be false.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;First, we were discussing the effect of the MWI, so we should assume he 
<br />
knows the MWI.  And even without modern physics, he could derive the AUH (a 
<br />
MWI even if not QM) from Occam's razor.
<br />
<br /><em class="quotelev4">&gt;&gt;&gt; &gt;    As I see it, it is a priori possible that I could have been any 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;observer.  Thus all observers must be included, by definition.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;I find the &quot;I could have been you&quot; talk quite suspicious and murky. It's 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;not clear to me that this is the way to cast light on the situtation.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;    Let me try to enlighten you a little then.  Think of it like this: I 
</em><br />
<em class="quotelev2">&gt;&gt;know I'm an observer-moment (or thought, if you like); that much I can 
</em><br />
<em class="quotelev2">&gt;&gt;assume a priori.  Now I (or my brain, which is the computer actually 
</em><br />
<em class="quotelev2">&gt;&gt;carrying out the calculations, with observer-moments like me &quot;along for 
</em><br />
<em class="quotelev2">&gt;&gt;the ride&quot;) want to compare two possible models of the universe, so I need 
</em><br />
<em class="quotelev2">&gt;&gt;to calculate the Bayesian probability that each model is true.
</em><br />
<em class="quotelev2">&gt;&gt;    (In my view, first I must get the prior for this from Occam's razor, 
</em><br />
<em class="quotelev2">&gt;&gt;or &quot;exp(-complexity)&quot;; pretend for this exercise that it results in just 
</em><br />
<em class="quotelev2">&gt;&gt;two models with significant prior probability and that each of these is 
</em><br />
<em class="quotelev2">&gt;&gt;roughly 50% likely a priori.  Even if you don't like that, in any case 
</em><br />
<em class="quotelev2">&gt;&gt;assume I have two competing models of equal a priori probability.  I can 
</em><br />
<em class="quotelev2">&gt;&gt;always just find the conditional Bayesian probability that model #1 is 
</em><br />
<em class="quotelev2">&gt;&gt;true given that either #1 or #2 is true; that's more or less what 
</em><br />
<em class="quotelev2">&gt;&gt;scientists traditionally do, since they neglect the simplest [AUH] 
</em><br />
<em class="quotelev2">&gt;&gt;models.)
</em><br />
<em class="quotelev2">&gt;&gt;    For that I need to know the Bayesian probability that, if a given 
</em><br />
<em class="quotelev2">&gt;&gt;model is true, the other information that I take as known would also be 
</em><br />
<em class="quotelev2">&gt;&gt;true.  This other information takes the form &quot;I see x&quot;.  Since
</em><br />
<em class="quotelev1">&gt;this is not used as a priori information, it will allow me to update my 
</em><br />
<em class="quotelev1">&gt;prior.  But I need the Bayesian probabilities that the information would be 
</em><br />
<em class="quotelev1">&gt;true if each model were true.
</em><br />
<em class="quotelev2">&gt;&gt;    So what is the Bayesian probability that I would see x if model #1 
</em><br />
<em class="quotelev2">&gt;&gt;were true?  In order to get it, I do not first assume that I see x, since 
</em><br />
<em class="quotelev2">&gt;&gt;then I would get 1 and that's not what I need.  So the only information I 
</em><br />
<em class="quotelev2">&gt;&gt;assume is the a priori information, I am an observer-moment.  That is the 
</em><br />
<em class="quotelev2">&gt;&gt;only other thing I know about myself, other than the observation that I 
</em><br />
<em class="quotelev2">&gt;&gt;see x.  So if model #1 predicts the existance of N observer-moments, m of 
</em><br />
<em class="quotelev2">&gt;&gt;whom see x, I have no a priori reason to say that any of them is more 
</em><br />
<em class="quotelev2">&gt;&gt;likely to be me than the others.  So the Bayesian probability that &quot;I 
</em><br />
<em class="quotelev2">&gt;&gt;would see x&quot; if model #1 were true is the effective probability, m / N.
</em><br />
<br /><em class="quotelev1">&gt;Well, if we assume that it is a priori knowledge that I am an
</em><br />
observer-moment, then why should this a priori knowledge not be used in 
<br />
evaluating hypotheses? For example by saying: it would be more probable that 
<br />
I should exit if many observer-moments came into existence? (This is the 
<br />
Self-Indication Assumption, which as you know I reject. But I would be 
<br />
interested in hearing your story of why it should be rejected.)
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;That's not how a-priori information is used.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;For example, if there are 10 balls in a jar and ether A) 9 iron and 1 
<br />
wood, or B) 1 iron and 9 wood, and I pick one randomly and see it's iron, 
<br />
that's new information and I would update my prior to reflect it so I think 
<br />
A is more likely to be true.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;If on the other hand I tell a robot to go pick one up with a magnet 
<br />
(assume that it will always pick up one ball) and it fetches me an iron 
<br />
ball, this does not tell me anything new.  I know that if it failed the 
<br />
first time, it would keep trying and that I would only see the result of 
<br />
picking an iron ball.  (Iron-thropic principle.)  This is a-priori 
<br />
information.
<br />
<br /><em class="quotelev1">&gt;Second, suppose I say to you: Not only &quot;I exist (am an observer-moment).&quot; 
</em><br />
<em class="quotelev1">&gt;is a priori, but &quot;I exist and I'm currently thinking about something 
</em><br />
<em class="quotelev1">&gt;related to anthropic reasoning.&quot; is also a priori. And for the same reason: 
</em><br />
<em class="quotelev1">&gt;you couldn't possibly have found out otherwise. Then by reasoning you 
</em><br />
<em class="quotelev1">&gt;describe, the reference class would not consist of all observer-moments but 
</em><br />
<em class="quotelev1">&gt;instead of all observer-moments thinking about something related to 
</em><br />
<em class="quotelev1">&gt;anthropic reasoning. What do you say about that? (Incidentally, I am 
</em><br />
<em class="quotelev1">&gt;recently drawn to a definition of the reference class which might look 
</em><br />
<em class="quotelev1">&gt;rather like that.)
</em><br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;I don't like it - but can't really give a good objection.  Usually I say 
<br />
that the observer must be intelligent enough to be able to use anthropic 
<br />
reasoning ...
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Still, it is a good question and not unreasonable.  In practice, it 
<br />
makes no difference, since the fraction of observers using anthropic 
<br />
reasoning is probably not sensitive to the differences in physical models.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;Also, I'm not sure how one would define it precisely.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;Just to be clear for those who may want an example - suppose I know that 
<br />
either there are 10^6 observers, only 10 of which would think about 
<br />
anthropic reasoning; or else, I am the only observer.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;The a priori probability of either case (presumably from Occam's razor, 
<br />
although in this example Occam needs new blades) is 50%.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;If &quot;I am thinking about anthropic reasoning&quot; is a priori info, the prior 
<br />
remains at 50%.
<br />
&nbsp;&nbsp;&nbsp;&nbsp;If not, then since it is additional (&quot;new&quot;) info, the prior is updated 
<br />
and I know that most probably I am the only observer.
<br />
<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- - - - - - -
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Jacques Mallah (jackmallah.domain.name.hidden)
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Physicist  /  Many Worlder  /  Devil's Advocate
<br />
&quot;I know what no one else knows&quot; - 'Runaway Train', Soul Asylum
<br />
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;My URL: <a href="http://hammer.prohosting.com/~mathmind/">http://hammer.prohosting.com/~mathmind/</a>
<br />
_________________________________________________________________________
<br />
Get Your Private, Free E-mail from MSN Hotmail at <a href="http://www.hotmail.com">http://www.hotmail.com</a>.
<br />
<br />Share information about yourself, create your own public profile at 
<br />
<a href="http://profiles.msn.com">http://profiles.msn.com</a>.
<br />
<span id="received"><dfn>Received on</dfn> Fri Nov 17 2000 - 15:08:04 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start2285">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="2286.html" title="Next message in the list">Hal Ruhl: "Eliminating the machine"</a></li>
<li><dfn>Previous message</dfn>: <a href="2284.html" title="Previous message in the list">Hal Ruhl: "simpler yet restated - ouch"</a></li>
<li><dfn>Maybe in reply to</dfn>: <a href="2081.html" title="Message to which this message replies">Bostrom,N  (pg): "PhD-thesis on Observational Selection Effects"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="2210.html" title="Next message in this discussion thread">Nick Bostrom: "Re: Re: PhD-thesis on Observational Selection Effects"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Maybe reply</dfn>: <a href="2210.html" title="Message sent in reply to this message">Nick Bostrom: "Re: Re: PhD-thesis on Observational Selection Effects"</a></li>
<li><dfn>Maybe reply</dfn>: <a href="2217.html" title="Message sent in reply to this message">Nick Bostrom: "Re: Re: PhD-thesis on Observational Selection Effects"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg2285" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg2285" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg2285" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg2285" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:07 PST
</em></small></p>
</body>
</html>
