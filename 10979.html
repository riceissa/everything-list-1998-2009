<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: computationalism and supervenience from Brent Meeker on 2006-09-07 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: computationalism and supervenience" />
<meta name="Date" content="2006-09-07" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: computationalism and supervenience</h1>
<!-- received="Fri Sep  8 00:27:56 2006" -->
<!-- isoreceived="20060908072756" -->
<!-- sent="Thu, 07 Sep 2006 21:26:56 -0700" -->
<!-- isosent="20060908042656" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: computationalism and supervenience" -->
<!-- id="4500F110.9030706.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="BAY124-W136BEA567C8A5FC7F0407D2370.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start10979" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="10980.html" accesskey="d" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">Next message</a> ]
[ <a href="10978.html" title="marc.geddes.domain.name.hidden: &quot;Re: The Mathematico-Cognition Reality Theory (MCRT) Ver 6.0&quot;">Previous message</a> ]
[ <a href="10977.html" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="11009.html" accesskey="t" title="1Z: &quot;Re: computationalism and supervenience&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10979" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10979" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10979" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10979" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20computationalism%20and%20supervenience">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu, 07 Sep 2006 21:26:56 -0700</span><br />
</address>
<br />
Stathis Papaioannou wrote:
<br />
<em class="quotelev1">&gt; Brent meeker writes:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;Let's not try to define consciousness at all, but agree that we know what it is
</em><br />
<em class="quotelev3">&gt;&gt;&gt;from personal experience. Computationalism is the theory that consciousness arises
</em><br />
<em class="quotelev3">&gt;&gt;&gt;as a result of computer activity: that our brains are just complex computers, and
</em><br />
<em class="quotelev3">&gt;&gt;&gt;in the manner of computers, could be emulated by another computer, so that
</em><br />
<em class="quotelev3">&gt;&gt;&gt;computer would experience consciousness in the same way we do. (This theory may be
</em><br />
<em class="quotelev3">&gt;&gt;&gt;completely wrong, and perhaps consciousness is due to a substance secreted by a
</em><br />
<em class="quotelev3">&gt;&gt;&gt;special group of neurons or some other such non-computational process, but let's
</em><br />
<em class="quotelev3">&gt;&gt;&gt;leave that possibility aside for now). What we mean by one computer emulating
</em><br />
<em class="quotelev3">&gt;&gt;&gt;another is that there is an isomorphism between the activity of two physical
</em><br />
<em class="quotelev3">&gt;&gt;&gt;computers, so that there is a mapping function definable from the states of
</em><br />
<em class="quotelev3">&gt;&gt;&gt;computer A to the states of computer B. If this mapping function is fully
</em><br />
<em class="quotelev3">&gt;&gt;&gt;specified we can use it practically, for example to run Windows on an x86
</em><br />
<em class="quotelev3">&gt;&gt;&gt;processor emulated on a Power PC processor running Mac OS. If you look at the
</em><br />
<em class="quotelev3">&gt;&gt;&gt;Power PC processor and the x86 processor running side by side it would be
</em><br />
<em class="quotelev3">&gt;&gt;&gt;extremely difficult to see them doing the &quot;same&quot; computation, but according to the
</em><br />
<em class="quotelev3">&gt;&gt;&gt;mapping function inherent in the emulation program, they are, and they still would
</em><br />
<em class="quotelev3">&gt;&gt;&gt;be a thousand years from now even if the human race is extinct.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;In a similar fashion, there is an isomorphism between a computer and any other
</em><br />
<em class="quotelev3">&gt;&gt;&gt;physical system, even if the mapping function is unknown and extremely
</em><br />
<em class="quotelev3">&gt;&gt;&gt;complicated. 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;I don't see how there can be an isomorphism between any two systems.  Without some
</em><br />
<em class="quotelev2">&gt;&gt;structural constraint that seems to throw away the &quot;iso&quot; part and simply leave a
</em><br />
<em class="quotelev2">&gt;&gt;morphism.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The definition of the structural constraint is part of the isomorphism. Some isomorphisms are 
</em><br />
<em class="quotelev1">&gt; more economical than others, but there are no God-given isomorphisms or structural constraints. 
</em><br />
<em class="quotelev1">&gt; The limiting case is simply a lookup table mapping any arbitrary system to another arbitrary 
</em><br />
<em class="quotelev1">&gt; system. That this is inelegant does not make it invalid.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;That's not very interesting for non-conscious computations, because
</em><br />
<em class="quotelev3">&gt;&gt;&gt;they are only useful or meaningful if they can be observed or interact with their
</em><br />
<em class="quotelev3">&gt;&gt;&gt;environment. However, a conscious computation is interesting all on its own. It
</em><br />
<em class="quotelev3">&gt;&gt;&gt;might have a fuller life if it can interact with other minds, but its meaning is
</em><br />
<em class="quotelev3">&gt;&gt;&gt;not contingent on other minds the way a non-conscious computation's is. 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;Empirically, all of the meaning seems to be referred to things outside the
</em><br />
<em class="quotelev2">&gt;&gt;computation.  So if the conscious computation thinks of the word &quot;chair&quot; it doesn't
</em><br />
<em class="quotelev2">&gt;&gt;provide any meaning unless there is a chair - outside the computation.  So it is not
</em><br />
<em class="quotelev2">&gt;&gt;clear to me that meaning can be supplied &quot;from the inside&quot; in this way.  I think this
</em><br />
<em class="quotelev2">&gt;&gt;is where Bruno talks about &quot;the required level of substitution&quot; and allows that the
</em><br />
<em class="quotelev2">&gt;&gt;level may be the brain at a neural level PLUS all the outside world.  So that within
</em><br />
<em class="quotelev2">&gt;&gt;this simulation the simulated brain is conscious *relative* to the rest of the
</em><br />
<em class="quotelev2">&gt;&gt;simulated world.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't think it is right to say that the brain is *conscious* relative to the environment. It is 
</em><br />
<em class="quotelev1">&gt; intelligent relative to the environment, whether that means able to communicate with another 
</em><br />
<em class="quotelev1">&gt; conscious being or otherwise interacting with the environment in a meaningful way. Although 
</em><br />
<em class="quotelev1">&gt; we deduce that a being is conscious from its behaviour, and you can only have behaviour 
</em><br />
<em class="quotelev1">&gt; relative to an environment, only the being itself directly experiences its consciousness. This is 
</em><br />
<em class="quotelev1">&gt; the 3rd person/ 1st person distinction. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;I know 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;this because I am conscious, however difficult it may be to actually define that
</em><br />
<em class="quotelev3">&gt;&gt;&gt;term.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;But do you know you would be conscious if you could not interact with the world?
</em><br />
<em class="quotelev2">&gt;&gt;That seems doubtful to me.  Of course you can close your eyes, stop your ears, etc
</em><br />
<em class="quotelev2">&gt;&gt;and still experience consciousness - for a while - but perhaps not indefinitely and
</em><br />
<em class="quotelev2">&gt;&gt;maybe not even very long.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Maybe there is something about my brain that would render me unconscious if all outside 
</em><br />
<em class="quotelev1">&gt; input stopped, but that seems to me a contingent fact about brains, like the fact that I 
</em><br />
<em class="quotelev1">&gt; would be rendered unconscious if my oxygen supply were cut off. A hallucination is defined 
</em><br />
<em class="quotelev1">&gt; as a perception without a stimulus 
</em><br />
<br />Not really; it may just be a perception that doesn't match the stimulus, e.g. a 
<br />
perception of Christ brought about by hearing certain piece of music.
<br />
<br /><em class="quotelev1">&gt;and there are millions of people in the world who have 
</em><br />
<em class="quotelev1">&gt; hallucinations all the time. Sometimes people are so overwhelmed by hallucinatory experiences 
</em><br />
<em class="quotelev1">&gt; that you could saw their leg off and they don't notice, which is in part how dissociative 
</em><br />
<em class="quotelev1">&gt; anaesthetics like ketamine work. If you like, you can say that consciousness is maintained by 
</em><br />
<em class="quotelev1">&gt; one part of the brain interacting with another part of the brain: one part is program, the other 
</em><br />
<em class="quotelev1">&gt; part data, or one part is computer, the other part environment. The point is, whatever you 
</em><br />
<em class="quotelev1">&gt; choose to call it, an isolated physical system can experience consciousness.
</em><br />
<br />I won't insist, because you might be right, but I don't think that is proven.  It may 
<br />
be that interaction with the environment is essential to continued consciousness.
<br />
<br /><em class="quotelev3">  &gt;&gt;&gt;The conclusion I therefore draw from computationalism is that every possible
</em><br />
<em class="quotelev3">&gt;&gt;&gt;conscious computation is implemented necessarily if any physical process exists.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;That would seem to require mappings that are not isomorphisms.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; How do you define the non-isomorphic mappings?
</em><br />
<br />Consider the physical process &quot;tick tock tick tock...&quot;  There are only two states so 
<br />
it can be isomorphic to &quot;1010101...&quot; or &quot;abababa...&quot;. But it cannot be isomorphic to 
<br />
a process &quot;rock scissors paper rock scissors paper...&quot; with three states.  There can 
<br />
be a mapping between them: there can be a mapping between &quot;1&quot; and the content of the 
<br />
Oxford English Dictionary, but there's no &quot;iso&quot; about the morphism unless there is 
<br />
some structure that is preserved by the mapping.
<br />
<br /><em class="quotelev3">&gt;&gt;&gt;This seems to me very close to saying that every conscious computation is
</em><br />
<em class="quotelev3">&gt;&gt;&gt;implemented necessarily in Platonia, as the physical reality seems hardly
</em><br />
<em class="quotelev3">&gt;&gt;&gt;relevant.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;It seems to me to be very close to a reductio ad absurdum.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Like Bruno, I am not claiming that this is definitely the case, just that it is the case if 
</em><br />
<em class="quotelev1">&gt; computationalism is true. Several philosophers (eg. Searle) have used the self-evident 
</em><br />
<em class="quotelev1">&gt; absurdity of the idea as an argument demonstrating that computationalism is false - 
</em><br />
<em class="quotelev1">&gt; that there is something non-computational about brains and consciousness. I have not 
</em><br />
<em class="quotelev1">&gt; yet heard an argument that rejects this idea and saves computationalism. Personally, 
</em><br />
<em class="quotelev1">&gt; I would bet in favour of computationalism being true, but I cannot say that I am sure.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Stathis Papaioannou
</em><br />
<br />I would bet on computationalism too.  But I still think the conclusion that every 
<br />
physical process, even the null one, necessarily implements all possible 
<br />
consciousness is absurd.
<br />
<br />Brent Meeker
<br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Fri Sep 08 2006 - 00:27:56 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start10979">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="10980.html" title="Next message in the list">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<li><dfn>Previous message</dfn>: <a href="10978.html" title="Previous message in the list">marc.geddes.domain.name.hidden: "Re: The Mathematico-Cognition Reality Theory (MCRT) Ver 6.0"</a></li>
<li><dfn>In reply to</dfn>: <a href="10977.html" title="Message to which this message replies">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="11009.html" title="Next message in this discussion thread">1Z: "Re: computationalism and supervenience"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10979" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10979" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10979" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10979" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
