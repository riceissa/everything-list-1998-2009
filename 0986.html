<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Implementation from Christopher Maloney on 1999-07-23 (everything)</title>
<meta name="Author" content="Christopher Maloney (dude.domain.name.hidden)" />
<meta name="Subject" content="Re: Implementation" />
<meta name="Date" content="1999-07-23" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Implementation</h1>
<!-- received="Fri Jul 23 05:04:48 1999" -->
<!-- isoreceived="19990723120448" -->
<!-- sent="Fri, 23 Jul 1999 07:32:16 -0400" -->
<!-- isosent="19990723113216" -->
<!-- name="Christopher Maloney" -->
<!-- email="dude.domain.name.hidden" -->
<!-- subject="Re: Implementation" -->
<!-- id="379852C0.2A1A.domain.name.hidden" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="199907231047.MAA01339.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start986" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="0987.html" accesskey="d" title="Marchal: &quot;Re: Implementation&quot;">Next message</a> ]
[ <a href="0985.html" title="Higgo James: &quot;RE: FW: reality&quot;">Previous message</a> ]
[ <a href="0987.html" title="Marchal: &quot;Re: Implementation&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="0990.html" accesskey="t" title="Gilles HENRI: &quot;Re: Implementation&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg986" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg986" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg986" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg986" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Christopher Maloney &lt;<a href="mailto:dude.domain.name.hidden?Subject=Re%3A%20Implementation">dude.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 23 Jul 1999 07:32:16 -0400</span><br />
</address>
<br />
Bruno, my position is very simple:  I keep physical supervenience,
<br />
but I disagree with Maudlin's definition.  See below.
<br />
<br /><br />Marchal wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Chris wrote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;I've concluded that
</em><br />
<em class="quotelev2">&gt; &gt;Maudlin's proof of the incompatibility between physical supervenience
</em><br />
<em class="quotelev2">&gt; &gt;and a computational theory of consciousness, is without merit.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Gosh ...
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;Maudlin's main error is a subtle one, and the seeds for it can be
</em><br />
<em class="quotelev2">&gt; &gt;found in this introduction to the concept of physical supervenience,
</em><br />
<em class="quotelev2">&gt; &gt;on page 408:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;    Computational structure supervenes on physical structure, so
</em><br />
<em class="quotelev2">&gt; &gt;    physically identical brains are also computationally identical.
</em><br />
<br />This conclusion is wrong.  The second phrase does not follow from
<br />
the first.
<br />
<br /><em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;Indeed, he defines the _supervenience thesis_ thus:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;    Two physical systems engaged in precisely the same physical
</em><br />
<em class="quotelev2">&gt; &gt;    activity through a time will support the same modes of
</em><br />
<em class="quotelev2">&gt; &gt;    consciousness (if any) through that time.
</em><br />
<br />Olympia makes it clear why this conclusion is wrong.  Computation
<br />
supervenes on physical structures, but you must take the entire
<br />
physical structure into account, including parts that happen to
<br />
be inactive during a particular run.  Those parts change the
<br />
counterfactuals, and thus change the program.
<br />
<br /><em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;He doesn't provide any evidence to support this conjecture, he
</em><br />
<em class="quotelev2">&gt; &gt;assumes it as fairly obvious.  In the case of human brains, it is
</em><br />
<em class="quotelev2">&gt; &gt;fairly obvious, and probably true.  But in the case of his final
</em><br />
<em class="quotelev2">&gt; &gt;computational machine, Olympia, it is clearly false, as I will show.
</em><br />
<em class="quotelev2">&gt; &gt;As a summary: the great lengths that Maudlin goes to in contriving
</em><br />
<em class="quotelev2">&gt; &gt;Olympia are precisely those which invalidate the supervenience
</em><br />
<em class="quotelev2">&gt; &gt;thesis, as he has defined it.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I'm not sure I understand you because it would mean that
</em><br />
<em class="quotelev1">&gt; Maudlin'argumentation succeed.
</em><br />
<br />Note the &quot;as he has defined it&quot;.
<br />
&nbsp;
<br />
<em class="quotelev2">&gt; &gt;Maudlin elaborates on his definition, as Hal pointed out in his post:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;    If we introduce into the vicinity of the system an entirely inert
</em><br />
<em class="quotelev2">&gt; &gt;    object that has absolutely no causal or physical interaction with
</em><br />
<em class="quotelev2">&gt; &gt;    the system, then the same activity will still support the same
</em><br />
<em class="quotelev2">&gt; &gt;    mode of consciousness.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;But this is clearly incorrect, as a moment's reflection will verify.
</em><br />
<em class="quotelev2">&gt; &gt;Computation supervenes on physical processes precisely to the extent
</em><br />
<em class="quotelev2">&gt; &gt;that, to put it simply, the outputs depend on the inputs.  As Maudlin
</em><br />
<em class="quotelev2">&gt; &gt;(and everyone on this group) accepts, correct handling of some set
</em><br />
<em class="quotelev2">&gt; &gt;of counterfactuals are essential to be able to call an implementation
</em><br />
<em class="quotelev2">&gt; &gt;an instantiation of a computation (say _that_ three times fast!)  So
</em><br />
<em class="quotelev2">&gt; &gt;this definition of physical supervenience is where the error lies.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; OK. You just don't believe in the physical supervenience thesis.
</em><br />
<em class="quotelev1">&gt; That is great !
</em><br />
<br />Note &quot;this definition&quot;.
<br />
<br /><em class="quotelev1">&gt; But you will be obliged to explain why you still believe that
</em><br />
<em class="quotelev1">&gt; consciousness supervenes on the brain's activity (don't you ?).
</em><br />
<em class="quotelev1">&gt; In fact you will have to solve Mallah's implementation problem.
</em><br />
<em class="quotelev1">&gt; This is still more clear when you add:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;In fact, &quot;objects that have absolutely no causal or physical
</em><br />
<em class="quotelev2">&gt; &gt;interaction&quot; could affect the ability of the mechanism to deal with
</em><br />
<em class="quotelev2">&gt; &gt;counterfactuals, and so they would change the nature of the
</em><br />
<em class="quotelev2">&gt; &gt;computational device.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; All right. This is coherent with your suspicion against sup-phys.
</em><br />
<em class="quotelev1">&gt; Like Jacques M Mallah (and also like anyone who agree with both sup-phys
</em><br />
<em class="quotelev1">&gt; and comp, you make &quot;inactive physical piece&quot; having a role for
</em><br />
<em class="quotelev1">&gt; consciousness.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;To put it simply, as Jacques Mallah has pointed out many times, you
</em><br />
<em class="quotelev2">&gt; &gt;must consider the entire physical system whenever you are talking
</em><br />
<em class="quotelev2">&gt; &gt;about exactly what computation is instantiated.  The parts of the
</em><br />
<em class="quotelev2">&gt; &gt;system that don't happen to interact with other parts during a
</em><br />
<em class="quotelev2">&gt; &gt;particular run are still part of the system, and thus still have an
</em><br />
<em class="quotelev2">&gt; &gt;affect on which program is actually being run.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;I enjoyed Maudlins discussion, on pages 413ff, of &quot;the ploy of funny
</em><br />
<em class="quotelev2">&gt; &gt;instantiation&quot;, and other arguments, including Searle's &quot;Chinese
</em><br />
<em class="quotelev2">&gt; &gt;Room&quot;.  I agree with his assessments of these arguments as basically
</em><br />
<em class="quotelev2">&gt; &gt;non-substantive.  So it's ironic (to me, anyway) that I've reached
</em><br />
<em class="quotelev2">&gt; &gt;the conclusion that his argument falls into exactly this same class.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Like Jacques M Mallah. See my preeceeding &quot;re-implementation&quot; post
</em><br />
<em class="quotelev1">&gt; (responding to Jacques M Mallah) for my feeling about that.
</em><br />
<br />Okay, I'll look at it.
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; But do you realise, Chris, that, like Nathanael, you will make
</em><br />
<em class="quotelev1">&gt; Olympia a Zombie ! (I know you aversion of the concept). Just remember
</em><br />
<em class="quotelev1">&gt; that Olympia just talk and behave like us.
</em><br />
<br />I'll tell you exactly what I think of that.  First let's be clear
<br />
about what we're talking about.  Olympia, without the second set
<br />
of blocks, and _including all of the supporting Klaras_, is conscious,
<br />
because the physical system _as a whole_ is counterfactually correct.
<br />
Maudlin is not clear if he intends the Klaras to be part of Olympia
<br />
in that construction, or not.  (For the record:  the Klaras are
<br />
responsible for taking over the computation if the inputs differ from
<br />
the reference run).
<br />
<br />Now, if you add the second set of blocks, or if you don't include
<br />
the Klaras, then Olympia is just a replay device, not quite a
<br />
zombie.  She's not a zombie because she _doesn't_ talk and behave
<br />
like us -- I wouldn't be able to ask her questions, because she
<br />
would instantly die!  She does not implement anything other that
<br />
a replay of the reference run.
<br />
<br /><br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;In particular, he mentions, on p. 416, a trick that can be played
</em><br />
<em class="quotelev2">&gt; &gt;when discussing a proposed computational system:
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;    Someone might suggest that no activity is needed.  Let a rock
</em><br />
<em class="quotelev2">&gt; &gt;    sitting on a table be the machine.  Now let Si be:  sitting on
</em><br />
<em class="quotelev2">&gt; &gt;    the table from 12:00 to 12:01.  Let Sj be:  sitting on the table
</em><br />
<em class="quotelev2">&gt; &gt;    from 12:01 to 12:02.  The machine will effect a transition
</em><br />
<em class="quotelev2">&gt; &gt;    between the two states without undergoing any physical change at
</em><br />
<em class="quotelev2">&gt; &gt;    all.  I shall take such tricks to be inadmissable.
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev2">&gt; &gt;But the trick he makes in defining Olympia is of exactly this
</em><br />
<em class="quotelev2">&gt; &gt;variety!  It doesn't go quite as far, but it is the same in that it
</em><br />
<em class="quotelev2">&gt; &gt;encodes information about a _particular run of the device_ into the
</em><br />
<em class="quotelev2">&gt; &gt;definition, or structure, of the device itself.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Any program which is able to remember its activity do something like
</em><br />
<em class="quotelev1">&gt; that. This is just memorising. Frankly I don't see the difference.
</em><br />
<em class="quotelev1">&gt; The rock has no counterfactual abilities. Olympia does.
</em><br />
<br />Olympia does only when you add the supporting structure.  The rock
<br />
does, also, when you add the external computer.
<br />
<br /><em class="quotelev1">&gt; The only bizare feature of Olympia is that the memories and the
</em><br />
<em class="quotelev1">&gt; counterfactual are implemented in a way to be inactive during a
</em><br />
<em class="quotelev1">&gt; particular run. If that would affect consciousness, I would
</em><br />
<em class="quotelev1">&gt; prefer to abandon computationalism.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;It should be obvious how this trick is of the same sort as the rock
</em><br />
<em class="quotelev2">&gt; &gt;trick above.  In the original machine, the order of the troughs had a
</em><br />
<em class="quotelev2">&gt; &gt;particular significance.  He has then redefined the significance of
</em><br />
<em class="quotelev2">&gt; &gt;the order of the troughs, ad hoc, to have a new significance which
</em><br />
<em class="quotelev2">&gt; &gt;relates directly to information from the reference run of the device.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Here I would agree for a purely formal reason, and I see it as a
</em><br />
<em class="quotelev1">&gt; pedagogical weakness of Maudlin's presentation of his argument.
</em><br />
<em class="quotelev1">&gt; But it is not to difficult to eliminate this difficulty.
</em><br />
<br />I don't think I've read any thought experiments that eliminate it,
<br />
in discussions so far.  I'll look them over again.  How would you
<br />
propose to eliminate it?
<br />
<br /><em class="quotelev1">&gt; And, at least for me, the fact that counterfactual will be well managed is
</em><br />
<em class="quotelev1">&gt; enough. I don't believe in zombie !
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; snip ...
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;The same argument also applies when Maudlin discusses his &quot;second
</em><br />
<em class="quotelev2">&gt; &gt;block&quot;, which causes the gears to jam if ever the counterfactual is
</em><br />
<em class="quotelev2">&gt; &gt;encountered.  Again, this changes the overall structure of the
</em><br />
<em class="quotelev2">&gt; &gt;device, and thus changes the program which is instantiated.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; But any physical instantiation of a conditional instruction like
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt;   IF M = O THEN RUN &lt;this part of the device&gt;
</em><br />
<em class="quotelev1">&gt;   ELSE do nothing
</em><br />
<br /><br />So, Bruno, it seems that you do agree that a physical structure
<br />
can run a program!  Congratulations on seeing your error!
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; do precisely this.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;My point is that it is meaningless to talk of whether any of these
</em><br />
<em class="quotelev2">&gt; &gt;instantiations is &quot;conscious&quot;.  As many have pointed out recently,
</em><br />
<em class="quotelev2">&gt; &gt;consciousness is a subjective phenomenon.  We can study it from the
</em><br />
<em class="quotelev2">&gt; &gt;outside, just like we can study a computer program, but the actual
</em><br />
<em class="quotelev2">&gt; &gt;conscious entity experiencing the experiences will not be sensitive
</em><br />
<em class="quotelev2">&gt; &gt;to whether the machine breaks.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I clearly agree with you if you include the normal brain in 'these
</em><br />
<em class="quotelev1">&gt; instantiations'. That was the point to be prove.
</em><br />
<em class="quotelev1">&gt; If we keep &quot;comp&quot; we must abandon sup-phys.
</em><br />
<em class="quotelev1">&gt; Even on 'normal brain activity'. Is that your move ? I am not sure.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;And one final note, which I think is the most powerful argument yet:
</em><br />
<em class="quotelev2">&gt; &gt;to make this conjecture stand, you'd have to show that physical
</em><br />
<em class="quotelev2">&gt; &gt;processes are incapable of instantiating a computation, ever.  I
</em><br />
<em class="quotelev2">&gt; &gt;don't think Maudlin attempted this.  The reason is clear:  if you
</em><br />
<em class="quotelev2">&gt; &gt;agree that consciousness is computational, and you agree that
</em><br />
<em class="quotelev2">&gt; &gt;physical processes can instantiate computations, then it follows that
</em><br />
<em class="quotelev2">&gt; &gt;physical processes can instantiate consciousnesses.  I don't know how
</em><br />
<em class="quotelev2">&gt; &gt;Maudlin would address this.  Would he say that conscious computations
</em><br />
<em class="quotelev2">&gt; &gt;are of a high enough order of complexity that they fall apart?  Just
</em><br />
<em class="quotelev2">&gt; &gt;hand-waving about a whether a particular contrived instantiation is
</em><br />
<em class="quotelev2">&gt; &gt;conscious or not cannot lead you to any conclusions about the general
</em><br />
<em class="quotelev2">&gt; &gt;case.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Maudlin abandon computationalism.
</em><br />
<em class="quotelev1">&gt; I abandon sup-phys and the wole idea that consciousness is emergent
</em><br />
<em class="quotelev1">&gt; or secondary with respect to physical laws.
</em><br />
<br />I do not.  But the truly beautiful, weird, and elegant thing is
<br />
that physical laws are, at least partly, a result of computational
<br />
indeterminism.  But that doesn't preclude one from considering
<br />
Tegmark's mathematical models in order to gain an idea of the
<br />
measure associated with a conscious experience.  It also doesn't
<br />
say that its necessary, either.  In fact, I'm leaning more and
<br />
more your way in my thinking about measure.  I'm very anxious
<br />
to read your thesis.
<br />
<br /><br /><em class="quotelev1">&gt; And I show it is quite consistent that the physical laws emerges
</em><br />
<em class="quotelev1">&gt; from the possible (arithmetical) discourse of consistent machines
</em><br />
<em class="quotelev1">&gt; infering their own (relative) consistency.
</em><br />
<em class="quotelev1">&gt; The role of an 'apparent brain' is not the producing of consciousness.
</em><br />
<em class="quotelev1">&gt; The role of such a brain is only to make possible for a (conscious)
</em><br />
<em class="quotelev1">&gt; computation to manifest itself relatively to his more probable (measure 1)
</em><br />
<em class="quotelev1">&gt; computational neighborhood.
</em><br />
<em class="quotelev1">&gt; Is that a too big leap ?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I am still not sure you abandon sup-phys. You cannot abandon it for
</em><br />
<em class="quotelev1">&gt; Olympia and not for the 'normal brain'. At least not without giving us a
</em><br />
<em class="quotelev1">&gt; &quot;physical&quot; definition of &quot;correct&quot; implementation (like JMM).
</em><br />
<em class="quotelev1">&gt; But the end of your post seems to me going in the direction of total
</em><br />
<em class="quotelev1">&gt; abandon of sup-phys.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; So, I ask you again, is Olympia a zombie ?
</em><br />
<em class="quotelev1">&gt; (From your conversation with Steve Price, I am aware of the
</em><br />
<em class="quotelev1">&gt; high provocation here !). I just try to have a better
</em><br />
<em class="quotelev1">&gt; understanding of your post.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Bruno
</em><br />
<br /><pre>
-- 
Chris Maloney
<a href="http://www.chrismaloney.com">http://www.chrismaloney.com</a>
&quot;Knowledge is good&quot;
-- Emil Faber
</pre>
<span id="received"><dfn>Received on</dfn> Fri Jul 23 1999 - 05:04:48 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start986">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="0987.html" title="Next message in the list">Marchal: "Re: Implementation"</a></li>
<li><dfn>Previous message</dfn>: <a href="0985.html" title="Previous message in the list">Higgo James: "RE: FW: reality"</a></li>
<li><dfn>In reply to</dfn>: <a href="0987.html" title="Message to which this message replies">Marchal: "Re: Implementation"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="0990.html" title="Next message in this discussion thread">Gilles HENRI: "Re: Implementation"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="0990.html" title="Message sent in reply to this message">Gilles HENRI: "Re: Implementation"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg986" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg986" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg986" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg986" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
