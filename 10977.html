<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>RE: computationalism and supervenience from Stathis Papaioannou on 2006-09-07 (everything)</title>
<meta name="Author" content="Stathis Papaioannou (stathispapaioannou.domain.name.hidden)" />
<meta name="Subject" content="RE: computationalism and supervenience" />
<meta name="Date" content="2006-09-07" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>RE: computationalism and supervenience</h1>
<!-- received="Thu Sep  7 22:41:39 2006" -->
<!-- isoreceived="20060908054139" -->
<!-- sent="Fri, 8 Sep 2006 12:40:42 +1000" -->
<!-- isosent="20060908024042" -->
<!-- name="Stathis Papaioannou" -->
<!-- email="stathispapaioannou.domain.name.hidden" -->
<!-- subject="RE: computationalism and supervenience" -->
<!-- id="BAY124-W136BEA567C8A5FC7F0407D2370.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="computationalism and supervenience" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start10977" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="10978.html" accesskey="d" title="marc.geddes.domain.name.hidden: &quot;Re: The Mathematico-Cognition Reality Theory (MCRT) Ver 6.0&quot;">Next message</a> ]
[ <a href="10976.html" title="Tom Caylor: &quot;Re: ROADMAP (SHORT)&quot;">Previous message</a> ]
[ <a href="10576.html" title="Stathis Papaioannou: &quot;computationalism and supervenience&quot;">Maybe in reply to</a> ]
<!-- unextthread="start" -->
[ <a href="10979.html" accesskey="t" title="Brent Meeker: &quot;Re: computationalism and supervenience&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10977" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10977" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10977" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10977" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Stathis Papaioannou &lt;<a href="mailto:stathispapaioannou.domain.name.hidden?Subject=RE%3A%20computationalism%20and%20supervenience">stathispapaioannou.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 8 Sep 2006 12:40:42 +1000</span><br />
</address>
<br />
Brent meeker writes:
<br />
<br /><em class="quotelev2">&gt; &gt; Let's not try to define consciousness at all, but agree that we know what it is
</em><br />
<em class="quotelev2">&gt; &gt; from personal experience. Computationalism is the theory that consciousness arises
</em><br />
<em class="quotelev2">&gt; &gt; as a result of computer activity: that our brains are just complex computers, and
</em><br />
<em class="quotelev2">&gt; &gt; in the manner of computers, could be emulated by another computer, so that
</em><br />
<em class="quotelev2">&gt; &gt; computer would experience consciousness in the same way we do. (This theory may be
</em><br />
<em class="quotelev2">&gt; &gt; completely wrong, and perhaps consciousness is due to a substance secreted by a
</em><br />
<em class="quotelev2">&gt; &gt; special group of neurons or some other such non-computational process, but let's
</em><br />
<em class="quotelev2">&gt; &gt; leave that possibility aside for now). What we mean by one computer emulating
</em><br />
<em class="quotelev2">&gt; &gt; another is that there is an isomorphism between the activity of two physical
</em><br />
<em class="quotelev2">&gt; &gt; computers, so that there is a mapping function definable from the states of
</em><br />
<em class="quotelev2">&gt; &gt; computer A to the states of computer B. If this mapping function is fully
</em><br />
<em class="quotelev2">&gt; &gt; specified we can use it practically, for example to run Windows on an x86
</em><br />
<em class="quotelev2">&gt; &gt; processor emulated on a Power PC processor running Mac OS. If you look at the
</em><br />
<em class="quotelev2">&gt; &gt; Power PC processor and the x86 processor running side by side it would be
</em><br />
<em class="quotelev2">&gt; &gt; extremely difficult to see them doing the &quot;same&quot; computation, but according to the
</em><br />
<em class="quotelev2">&gt; &gt; mapping function inherent in the emulation program, they are, and they still would
</em><br />
<em class="quotelev2">&gt; &gt; be a thousand years from now even if the human race is extinct.
</em><br />
<em class="quotelev2">&gt; &gt; 
</em><br />
<em class="quotelev2">&gt; &gt; In a similar fashion, there is an isomorphism between a computer and any other
</em><br />
<em class="quotelev2">&gt; &gt; physical system, even if the mapping function is unknown and extremely
</em><br />
<em class="quotelev2">&gt; &gt; complicated. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't see how there can be an isomorphism between any two systems.  Without some
</em><br />
<em class="quotelev1">&gt; structural constraint that seems to throw away the &quot;iso&quot; part and simply leave a
</em><br />
<em class="quotelev1">&gt; morphism.
</em><br />
<br />The definition of the structural constraint is part of the isomorphism. Some isomorphisms are 
<br />
more economical than others, but there are no God-given isomorphisms or structural constraints. 
<br />
The limiting case is simply a lookup table mapping any arbitrary system to another arbitrary 
<br />
system. That this is inelegant does not make it invalid.
<br />
<br /><em class="quotelev2">&gt; &gt;That's not very interesting for non-conscious computations, because
</em><br />
<em class="quotelev2">&gt; &gt; they are only useful or meaningful if they can be observed or interact with their
</em><br />
<em class="quotelev2">&gt; &gt; environment. However, a conscious computation is interesting all on its own. It
</em><br />
<em class="quotelev2">&gt; &gt; might have a fuller life if it can interact with other minds, but its meaning is
</em><br />
<em class="quotelev2">&gt; &gt; not contingent on other minds the way a non-conscious computation's is. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Empirically, all of the meaning seems to be referred to things outside the
</em><br />
<em class="quotelev1">&gt; computation.  So if the conscious computation thinks of the word &quot;chair&quot; it doesn't
</em><br />
<em class="quotelev1">&gt; provide any meaning unless there is a chair - outside the computation.  So it is not
</em><br />
<em class="quotelev1">&gt; clear to me that meaning can be supplied &quot;from the inside&quot; in this way.  I think this
</em><br />
<em class="quotelev1">&gt; is where Bruno talks about &quot;the required level of substitution&quot; and allows that the
</em><br />
<em class="quotelev1">&gt; level may be the brain at a neural level PLUS all the outside world.  So that within
</em><br />
<em class="quotelev1">&gt; this simulation the simulated brain is conscious *relative* to the rest of the
</em><br />
<em class="quotelev1">&gt; simulated world.
</em><br />
<br />I don't think it is right to say that the brain is *conscious* relative to the environment. It is 
<br />
intelligent relative to the environment, whether that means able to communicate with another 
<br />
conscious being or otherwise interacting with the environment in a meaningful way. Although 
<br />
we deduce that a being is conscious from its behaviour, and you can only have behaviour 
<br />
relative to an environment, only the being itself directly experiences its consciousness. This is 
<br />
the 3rd person/ 1st person distinction. 
<br />
<br /><em class="quotelev2">&gt; &gt;I know 
</em><br />
<em class="quotelev2">&gt; &gt; this because I am conscious, however difficult it may be to actually define that
</em><br />
<em class="quotelev2">&gt; &gt; term.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; But do you know you would be conscious if you could not interact with the world?
</em><br />
<em class="quotelev1">&gt; That seems doubtful to me.  Of course you can close your eyes, stop your ears, etc
</em><br />
<em class="quotelev1">&gt; and still experience consciousness - for a while - but perhaps not indefinitely and
</em><br />
<em class="quotelev1">&gt; maybe not even very long.
</em><br />
<br />Maybe there is something about my brain that would render me unconscious if all outside 
<br />
input stopped, but that seems to me a contingent fact about brains, like the fact that I 
<br />
would be rendered unconscious if my oxygen supply were cut off. A hallucination is defined 
<br />
as a perception without a stimulus and there are millions of people in the world who have 
<br />
hallucinations all the time. Sometimes people are so overwhelmed by hallucinatory experiences 
<br />
that you could saw their leg off and they don't notice, which is in part how dissociative 
<br />
anaesthetics like ketamine work. If you like, you can say that consciousness is maintained by 
<br />
one part of the brain interacting with another part of the brain: one part is program, the other 
<br />
part data, or one part is computer, the other part environment. The point is, whatever you 
<br />
choose to call it, an isolated physical system can experience consciousness.
<br />
&nbsp;
<br />
<em class="quotelev2">&gt; &gt; The conclusion I therefore draw from computationalism is that every possible
</em><br />
<em class="quotelev2">&gt; &gt; conscious computation is implemented necessarily if any physical process exists.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; That would seem to require mappings that are not isomorphisms.
</em><br />
<br />How do you define the non-isomorphic mappings?
<br />
&nbsp;
<br />
<em class="quotelev2">&gt; &gt; This seems to me very close to saying that every conscious computation is
</em><br />
<em class="quotelev2">&gt; &gt; implemented necessarily in Platonia, as the physical reality seems hardly
</em><br />
<em class="quotelev2">&gt; &gt; relevant.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; It seems to me to be very close to a reductio ad absurdum.
</em><br />
<br />Like Bruno, I am not claiming that this is definitely the case, just that it is the case if 
<br />
computationalism is true. Several philosophers (eg. Searle) have used the self-evident 
<br />
absurdity of the idea as an argument demonstrating that computationalism is false - 
<br />
that there is something non-computational about brains and consciousness. I have not 
<br />
yet heard an argument that rejects this idea and saves computationalism. Personally, 
<br />
I would bet in favour of computationalism being true, but I cannot say that I am sure.
<br />
<br />Stathis Papaioannou
<br />
_________________________________________________________________
<br />
Be one of the first to try Windows Live Mail.
<br />
<a href="http://ideas.live.com/programpage.aspx?versionId=5d21c51a-b161-4314-9b0e-4911fb2b2e6d">http://ideas.live.com/programpage.aspx?versionId=5d21c51a-b161-4314-9b0e-4911fb2b2e6d</a>
<br />
--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Thu Sep 07 2006 - 22:41:39 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start10977">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="10978.html" title="Next message in the list">marc.geddes.domain.name.hidden: "Re: The Mathematico-Cognition Reality Theory (MCRT) Ver 6.0"</a></li>
<li><dfn>Previous message</dfn>: <a href="10976.html" title="Previous message in the list">Tom Caylor: "Re: ROADMAP (SHORT)"</a></li>
<li><dfn>Maybe in reply to</dfn>: <a href="10576.html" title="Message to which this message replies">Stathis Papaioannou: "computationalism and supervenience"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="10979.html" title="Next message in this discussion thread">Brent Meeker: "Re: computationalism and supervenience"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="10979.html" title="Message sent in reply to this message">Brent Meeker: "Re: computationalism and supervenience"</a></li>
<li><dfn>Reply</dfn>: <a href="11009.html" title="Message sent in reply to this message">1Z: "Re: computationalism and supervenience"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10977" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10977" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10977" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10977" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
