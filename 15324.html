<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: MGA 1 from Kory Heath on 2008-11-21 (everything)</title>
<meta name="Author" content="Kory Heath (kory.domain.name.hidden)" />
<meta name="Subject" content="Re: MGA 1" />
<meta name="Date" content="2008-11-21" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: MGA 1</h1>
<!-- received="Fri Nov 21 04:45:50 2008" -->
<!-- isoreceived="20081121124550" -->
<!-- sent="Fri, 21 Nov 2008 01:45:36 -0800" -->
<!-- isosent="20081121094536" -->
<!-- name="Kory Heath" -->
<!-- email="kory.domain.name.hidden" -->
<!-- subject="Re: MGA 1" -->
<!-- id="F614D963-6109-4A6B-968A-06679A606848.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="C6A31E93-CF35-4771-ADC9-25A87D0609E6.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start15324" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="15325.html" accesskey="d" title="Kory Heath: &quot;Re: Little exercise&quot;">Next message</a> ]
[ <a href="15323.html" title="Jason Resch: &quot;Re: Mathematical methods for the discrete space-time.&quot;">Previous message</a> ]
[ <a href="15312.html" title="Bruno Marchal: &quot;Re: MGA 1&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="15331.html" accesskey="t" title="Bruno Marchal: &quot;Re: MGA 1&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15324" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15324" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15324" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15324" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Kory Heath &lt;<a href="mailto:kory.domain.name.hidden?Subject=Re%3A%20MGA%201">kory.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 21 Nov 2008 01:45:36 -0800</span><br />
</address>
<br />
On Nov 20, 2008, at 10:52 AM, Bruno Marchal wrote:
<br />
<em class="quotelev1">&gt; I am afraid you are already too much suspect of the contradictory
</em><br />
<em class="quotelev1">&gt; nature of MEC+MAT.
</em><br />
<em class="quotelev1">&gt; Take the reasoning has a game. Try to keep both MEC and MAT, the game
</em><br />
<em class="quotelev1">&gt; consists in showing the more clearly as possible what will go wrong.
</em><br />
<br />I understand what you're saying, and I accept the rules of the game. I  
<br />
*am* trying to keep both MEC and MAT. But it seems as though we differ  
<br />
on how we understand MEC and MAT, because in my understanding,  
<br />
mechanist-materialists should say that Bruno's Lucky Alice is not  
<br />
conscious (for the same reason that Telmo's Lucky Alice is not  
<br />
conscious).
<br />
<br /><em class="quotelev1">&gt; You mean the ALICE of Telmo's solution of MGA 1bis, I guess. The
</em><br />
<em class="quotelev1">&gt; original Alice, well I mean the one in MGA 1, is functionally
</em><br />
<em class="quotelev1">&gt; identical at the right level of description (actually she has already
</em><br />
<em class="quotelev1">&gt; digital brain). The physical instantiation of a computation is
</em><br />
<em class="quotelev1">&gt; completely realized. No neurons can &quot;know&quot; that the info (correct and
</em><br />
<em class="quotelev1">&gt; at the right places) does not come from the relevant neurons, but from
</em><br />
<em class="quotelev1">&gt; a lucky beam.
</em><br />
<br />I agree that the neurons don't &quot;know&quot; or &quot;care&quot; where their inputs are  
<br />
coming from. They just get their inputs, perform their computations,  
<br />
and send their outputs. But when it comes to the functional, physical  
<br />
behavior of Alice's whole brain, the mechanist-materialist is  
<br />
certainly allowed (indeed, forced) to talk about where each neuron's  
<br />
input is coming from. That's a part of the computational picture.
<br />
<br />I see the point that you're making. Each neuron receives some input,  
<br />
performs some computation, and then produces some output. We're  
<br />
imagining that every neuron has been disconnected from its inputs, but  
<br />
that cosmic rays have luckily produced the exact same input that the  
<br />
previously connected neurons would have produced. You're arguing that  
<br />
since every neuron is performing the exact same computations that it  
<br />
would have performed anyway, the two situations are computationally  
<br />
identical.
<br />
<br />But I don't think that's correct. I think that plain old, garden  
<br />
variety mechanism-materialism has an easy way of saying that Lucky  
<br />
Alice's brain, viewed as a whole system, is not performing the same  
<br />
computations that fully-functioning Alice's brain is. None of the  
<br />
neurons in Lucky Alice's brain are even causally connected to each  
<br />
other. That's a pretty big computational difference!
<br />
<br />I am arguing, in essence, that for the mechanist-materialist,  
<br />
&quot;causality&quot; is an important aspect of computation and consciousness.  
<br />
Maybe your goal is to show that there's something deeply wrong with  
<br />
that idea, or with the idea of &quot;causality&quot; itself. But we're supposed  
<br />
to be starting from a foundation of MEC and MAT.
<br />
<br />Are you saying that the mechanist-materialist *does* say that Lucky  
<br />
Alice is conscious, or only that the mechanist-materialist *should*  
<br />
say it? Because if you're saying the latter, then I'm &quot;playing the  
<br />
game&quot; better than you are! I'm pretty sure that Dennett (and the other  
<br />
mechanist-materialists I've read) would say that Lucky Alice is not  
<br />
conscious, and for them, they have a perfectly straightforward way of  
<br />
explaining what they *mean* when they say that she's not conscious.  
<br />
They mean (among other things) that the actions of her neurons are not  
<br />
being affected at all by the paper lying in front of her on the table,  
<br />
or the ball flying at her head. For Dennett, it's practically a non- 
<br />
sequitur to say that she's conscious of a ball that's not affecting  
<br />
her brain.
<br />
<br /><em class="quotelev1">&gt; But the physical difference does not play a role.
</em><br />
<br />It depends on what you mean by &quot;play a role&quot;. You're right that the  
<br />
physical difference (very luckily) didn't change what the neurons did.  
<br />
It just so happens that the neurons did exactly what they were going  
<br />
to do anyway. But the *cause* of why the neurons did what they did is  
<br />
totally different. The action of each individual neuron was caused by  
<br />
cosmic rays rather than by neighboring neurons. You seem to be asking,  
<br />
&quot;Why should this difference play any role in whether or not Alice was  
<br />
conscious?&quot; But for the mechanist-materialist, the difference is  
<br />
primary. Those kinds of causal connections are a fundamental part of  
<br />
what they *mean* when they say that something is conscious.
<br />
<br /><em class="quotelev1">&gt; If you invoke it,
</em><br />
<em class="quotelev1">&gt; how could you accept saying yes to a doctor, who introduce bigger
</em><br />
<em class="quotelev1">&gt; difference?
</em><br />
<br />Do you mean the &quot;teleportation doctor&quot;, who makes a copy of me,  
<br />
destroys me, and then reconstructs me somewhere else using the copied  
<br />
information? That case is not problematic in the way that Lucky Alice  
<br />
is, because there is an unbroken causal chain between the &quot;new&quot; me and  
<br />
the &quot;old&quot; me. What's problematic about Lucky Alice is the fact that  
<br />
her ducking out of the way of the ball (the movements of her eyes, the  
<br />
look of surprise, etc.) has nothing to do with the ball, and yet  
<br />
somehow she's still supposed to be conscious of the ball.
<br />
<br />A much closer analogy to Lucky Alice would be if the doctor  
<br />
accidentally destroys me without making the copy, turns on the  
<br />
receiving teleporter in desperation, and then the exact copy that  
<br />
would have appeared anyway steps out, because (luckily!) cosmic rays  
<br />
hit the receiver's mechanisms in just the right way. I actually find  
<br />
this thought experiment more persuasive than Lucky Alice (although I'm  
<br />
sure some will argue that they're identical). At the very least, the  
<br />
mechanist-materialist has to say that the resulting Lucky Kory is  
<br />
conscious. I think it's also clear that Lucky Kory's consciousness  
<br />
must be exactly what it would have been if the teleportation had  
<br />
worked correctly. This does in fact lead me to feel that maybe  
<br />
causality shouldn't have any bearing on consciousness after all.
<br />
<br />However, the materialist-mechanist still has some grounds to say that  
<br />
there's something interestingly different about Lucky Kory than  
<br />
Original Kory. It is a physical fact of the matter that Lucky Kory is  
<br />
not causally connected to Pre-Teleportation Kory. When someone asks  
<br />
Lucky Kory, &quot;Why do you tie your shoes that way?&quot;, and Lucky Kory  
<br />
says, &quot;Because of something I learned when I was ten years old&quot;, Lucky  
<br />
Kory's statement is quite literally false. Lucky Kory ties his shoes  
<br />
that way because of some cosmic rays. I actually don't know what the  
<br />
standard mechanist-materialist way of viewing this situation is. But  
<br />
it does seem to suggest that maybe breaks in the causal chain  
<br />
shouldn't affect consciousness after all.
<br />
<br />And of course, we can turn the screws in the usual way. If we can do  
<br />
Lucky Teleportation once, we can do it once a day, and then once an  
<br />
hour, and then once a second, and so on, until eventually we just have  
<br />
nothing but random numbers, and if those random numbers happen to look  
<br />
like Kory, aren't they just as conscious as Lucky Kory was? But this  
<br />
doesn't convince me (yet) that Lucky Alice should be viewed as  
<br />
conscious after all. It just convinces me (again) that there's  
<br />
something weird about the mechanistic-materialist view of  
<br />
consciousness. Or about the materialist's view of &quot;causality&quot;.
<br />
<br /><em class="quotelev2">&gt;&gt; But the mechanist-materialist can (and must) claim that
</em><br />
<em class="quotelev2">&gt;&gt; Lucky Alice did not in fact respond to the ball at all.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Consciously or privately?
</em><br />
<br />Physically! By the definition of the thought experiment, it is a  
<br />
physical fact that no neuron in Alice's head responded to the ball (in  
<br />
the indirect way that they normally would have if she were wired  
<br />
correctly). Whether or not she had a conscious experience of a ball is  
<br />
a different question.
<br />
<br /><em class="quotelev2">&gt;&gt; When Alice's brain is working properly, her act of
</em><br />
<em class="quotelev2">&gt;&gt; ducking *is* causally connected to the movement of the ball. And this
</em><br />
<em class="quotelev2">&gt;&gt; kind of causal connection is an important part of what the mechanist-
</em><br />
<em class="quotelev2">&gt;&gt; materialist means by &quot;consciousness&quot;.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Careful:  such kind of causality needs ... MAT.
</em><br />
<br />Yes, of course. But we're *supposed* to be considering the question in  
<br />
the context of MAT.
<br />
<br /><em class="quotelev1">&gt; But at that level, a
</em><br />
<em class="quotelev1">&gt; neurophysiologist looking in the detail would see the neurons doing
</em><br />
<em class="quotelev1">&gt; their job. Only, he will also see, some neurons breaking down, and
</em><br />
<em class="quotelev1">&gt; then being fixed, not by an internal biological fixing mechanism (like
</em><br />
<em class="quotelev1">&gt; it occurs all the time in biological system, but by a lucky beam, but
</em><br />
<em class="quotelev1">&gt; despite this, and thanks to this, the brain of Alice (MGA 1) does the
</em><br />
<em class="quotelev1">&gt; entire normal usual work.
</em><br />
<br />What do you mean by &quot;fixed&quot;? If the cosmic rays &quot;fix&quot; the neurons so  
<br />
that they are able to respond to the input of their neighboring  
<br />
neurons as they're supposed to, then I've misunderstood the thought  
<br />
experiment. But if you mean that the cosmic rays &quot;fix&quot; the neurons by  
<br />
(very luckily) sending them the same inputs that they would have  
<br />
received from their neighboring neurons, then I don't agree that the  
<br />
neurophysiologist looking at the details would conclude that the  
<br />
neurons are doing their job, or that the brain of Alice MGA 1 is doing  
<br />
its entire normal usual work. He would conclude that the brain is not  
<br />
physically reacting to the pencil or the paper or the ball at all. For  
<br />
a mechanist, how can a person be aware of a ball if not a single  
<br />
neuron in her head is physically reacting to that ball?
<br />
<br /><em class="quotelev2">&gt;&gt; The mechanist-materialist can only talk about
</em><br />
<em class="quotelev2">&gt;&gt; consciousness in computational / physical terms. For Dennett, if you
</em><br />
<em class="quotelev2">&gt;&gt; say that Alice is &quot;aware&quot;, you must be able to translate this into
</em><br />
<em class="quotelev2">&gt;&gt; mechanistic terms. And I can't see any mechanistic sense in which
</em><br />
<em class="quotelev2">&gt;&gt; Lucky Alice can be said to be &quot;aware&quot; of anything.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Alice MGA 1 can be said to be aware in the roiginal mechanist sense.
</em><br />
<em class="quotelev1">&gt; When she thought &quot;Oh the math problem is easy&quot;, she trigged the right
</em><br />
<em class="quotelev1">&gt; memories in her brain, with the correct physical activity, even if
</em><br />
<em class="quotelev1">&gt; just luckily in that case.
</em><br />
<br />Memory is notoriously confusing, so lets keep talking about the ball.  
<br />
What can a mechanist possibly mean by saying that Lucky Alice was  
<br />
aware of the ball? By the definition of the thought experiment (unless  
<br />
I've misunderstood it), every single neuron in Lucky Alice's brain is  
<br />
being triggered by cosmic rays rather than by neighboring neurons. Not  
<br />
a single action of any neuron (and therefore, not a single movement of  
<br />
her body) has anything to do with the movement of the ball. All we can  
<br />
say is that the neurons are (very improbably) being triggered in the  
<br />
exact same way that they *would* have been triggered if they were  
<br />
wired up correctly, and they were actually responding (indirectly) to  
<br />
the light on her retinas, etc.
<br />
<br />So what would it mean to say that, nevertheless, Lucky Alice is aware  
<br />
of the ball? The only sense I can make of this is that, since each  
<br />
individual neuron is doing exactly what it would have done anyway, the  
<br />
same &quot;experience&quot; (qualia, whatever) results (or supervenes, or  
<br />
whatever). But that's exactly the view of consciousness that Dennett  
<br />
(the archetypical mechanist-materialist) has spent a lifetime arguing  
<br />
against. For him, that would be a very magical view of consciousness.  
<br />
For him, the &quot;experience&quot; of being aware of the ball, &quot;deciding&quot; to  
<br />
duck, etc., is simply what it feels like to be a collection of neurons  
<br />
responding to that ball. When he says, &quot;This collection of neurons is  
<br />
aware of that ball&quot;, he is saying, by definition, that that ball is  
<br />
having causal effects on those neurons. (And not just the causal  
<br />
effects that any physical object has on any nearby physical object.)
<br />
<br /><em class="quotelev1">&gt; And things will even be more confusing after MGA 2, but that's the
</em><br />
<em class="quotelev1">&gt; goal. MEC + MAT should give a contradiction, we will extract some
</em><br />
<em class="quotelev1">&gt; weirder and weirder proposition until the contradiction will be
</em><br />
<em class="quotelev1">&gt; utterly clear. OK?
</em><br />
<br />Of course I'm entirely on board with the spirit of your thought  
<br />
experiment. You think MECH and MAT implies that Lucky Alice is  
<br />
conscious, but I don't think it does. I'm not sure how important that  
<br />
difference is. It seems substantial. But I can also predict where  
<br />
you're going with your thought experiment, and it's the exact same  
<br />
place I go. So by all means, continue on to MGA 2, and we'll see what  
<br />
happens.
<br />
<br />-- Kory
<br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Fri Nov 21 2008 - 04:45:50 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start15324">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="15325.html" title="Next message in the list">Kory Heath: "Re: Little exercise"</a></li>
<li><dfn>Previous message</dfn>: <a href="15323.html" title="Previous message in the list">Jason Resch: "Re: Mathematical methods for the discrete space-time."</a></li>
<li><dfn>In reply to</dfn>: <a href="15312.html" title="Message to which this message replies">Bruno Marchal: "Re: MGA 1"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="15331.html" title="Next message in this discussion thread">Bruno Marchal: "Re: MGA 1"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="15331.html" title="Message sent in reply to this message">Bruno Marchal: "Re: MGA 1"</a></li>
<li><dfn>Reply</dfn>: <a href="15332.html" title="Message sent in reply to this message">Jason Resch: "Re: MGA 1"</a></li>
<li><dfn>Reply</dfn>: <a href="15334.html" title="Message sent in reply to this message">Brent Meeker: "Re: MGA 1"</a></li>
<li><dfn>Reply</dfn>: <a href="15373.html" title="Message sent in reply to this message">Bruno Marchal: "Re: MGA 1"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15324" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15324" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15324" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15324" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
