<?xml version="1.0" encoding="windows-1252"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Consciousness is information? from Bruno Marchal on 2009-05-23 (everything)</title>
<meta name="Author" content="Bruno Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: Consciousness is information?" />
<meta name="Date" content="2009-05-23" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Consciousness is information?</h1>
<!-- received="Sat May 23 14:47:14 2009" -->
<!-- isoreceived="20090523214714" -->
<!-- sent="Sat, 23 May 2009 14:47:14 +0200" -->
<!-- isosent="20090523124714" -->
<!-- name="Bruno Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: Consciousness is information?" -->
<!-- id="D570D0CB-8D5C-4259-B901-D8CACA476B30.domain.name.hidden" -->
<!-- charset="windows-1252" -->
<!-- inreplyto="c8d958e90905230035p604b3bfcy65edb775c89d98c9.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start16674" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="16675.html" accesskey="d" title="Brent Meeker: &quot;Re: Consciousness is information?&quot;">Next message</a> ]
[ <a href="16673.html" title="John Mikes: &quot;Re: Consciousness is information?&quot;">Previous message</a> ]
[ <a href="16671.html" title="Kelly Harmon: &quot;Re: Consciousness is information?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="16677.html" accesskey="t" title="Kelly Harmon: &quot;Re: Consciousness is information?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg16674" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg16674" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg16674" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg16674" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Bruno Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20Consciousness%20is%20information%3F">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sat, 23 May 2009 14:47:14 +0200</span><br />
</address>
<br />
On 23 May 2009, at 09:35, Kelly Harmon wrote:
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Okay, below are three passages that I think give a good sense of what
</em><br />
<em class="quotelev1">&gt; I mean by &quot;information&quot; when I say that &quot;consciousness is
</em><br />
<em class="quotelev1">&gt; information&quot;.  The first is from David Chalmers' &quot;Facing up to the
</em><br />
<em class="quotelev1">&gt; Problem of Consciousness.&quot;  The second is from the SEP article on
</em><br />
<em class="quotelev1">&gt; &quot;Semantic Conceptions of Information&quot;, and the third is from &quot;Symbol
</em><br />
<em class="quotelev1">&gt; Grounding and Meaning:  A comparison of High-Dimensional and Embodied
</em><br />
<em class="quotelev1">&gt; Theories of Meaning&quot;, by Arthur Glenberg and David Robertson.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; So I'm looking at these largely from a static, timeless, platonic
</em><br />
<em class="quotelev1">&gt; view.
</em><br />
<br />We agree then. Assuming comp we have no choice in the matter here.
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt; In my view, there are ungrounded abstract symbols that acquire
</em><br />
<em class="quotelev1">&gt; meaning via constraints placed on them by their relationships to other
</em><br />
<em class="quotelev1">&gt; symbols.
</em><br />
<br />Absolutely so.
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt;  The only &quot;grounding&quot; comes from the conscious experience
</em><br />
<em class="quotelev1">&gt; that is intrinsic to a particular set of relationships.
</em><br />
<br /><br />Exactly.
<br />
<br /><br /><br /><em class="quotelev1">&gt; To repeat my
</em><br />
<em class="quotelev1">&gt; earlier Chalmers quote, &quot;Experience is information from the inside;
</em><br />
<em class="quotelev1">&gt; physics is information from the outside.&quot;  It is this subjective
</em><br />
<em class="quotelev1">&gt; experience of information that provides meaning to the otherwise
</em><br />
<em class="quotelev1">&gt; completely abstract &quot;platonic&quot; symbols.
</em><br />
<br /><br />I insist on this well before Chalmers. We are agreeing on this.
<br />
But then you associate consciousness with the experience of information.
<br />
This is what I told you. I can understand the relation between  
<br />
consciousness and information content.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; So I think that something like David Lewis' &quot;modal realism&quot; is true by
</em><br />
<em class="quotelev1">&gt; virtue of the fact that all possible sets of relationships are
</em><br />
<em class="quotelev1">&gt; realized in Platonia.
</em><br />
<br /><br />We agree. This is explained in detail in &quot;conscience et mécanisme&quot;.  
<br />
Comp forces modal realism. AUDA just gives the precise modal logics,  
<br />
extracted from the theory of the self-referentially correct machine.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Note that I don't have Bruno's fear of white rabbits.
</em><br />
<br /><br />Then you disagree with all reader of David Lewis, including David  
<br />
lewis himself who recognizes this inflation of to many realities as a  
<br />
weakness of its modal realism. My point is that the comp constraints  
<br />
leads to a solution of that problem, indeed a solution close to the  
<br />
quantum Everett solution. But the existence of white rabbits, and thus  
<br />
the correctness of comp remains to be tested.
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt; Assuming that
</em><br />
<em class="quotelev1">&gt; we are typical observers is fine as a starting point, and is a good
</em><br />
<em class="quotelev1">&gt; way to choose between otherwise equivalent explanations, but I don't
</em><br />
<em class="quotelev1">&gt; think it should hold a unilateral veto over our final conclusions.  If
</em><br />
<em class="quotelev1">&gt; the most reasonable explanation says that our observations aren't
</em><br />
<em class="quotelev1">&gt; especially typical, then so be it.  Not everyone can be typical.
</em><br />
<br />It is just a question of testing a theory. You seem to say something  
<br />
like &quot;if the theory predict that water under fire will typically boil,  
<br />
and that experience does not confirm that typicality (water froze  
<br />
regularly) then it means we are just very unlucky&quot;. But then all  
<br />
theories are correct.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I think the final passage from Glenberg and Robertson (from a paper
</em><br />
<em class="quotelev1">&gt; that actually argues against what's being described) gives the best
</em><br />
<em class="quotelev1">&gt; sense of what I have in mind, though obviously I'm extrapolating out
</em><br />
<em class="quotelev1">&gt; quite abit from the ideas presented.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Okay, so the passages of interest:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; --
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; David Chalmers:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The basic principle that I suggest centrally involves the notion of
</em><br />
<em class="quotelev1">&gt; information. I understand information in more or less the sense of
</em><br />
<em class="quotelev1">&gt; Shannon (1948). Where there is information, there are information
</em><br />
<em class="quotelev1">&gt; states embedded in an information space. An information space has a
</em><br />
<em class="quotelev1">&gt; basic structure of difference relations between its elements,
</em><br />
<em class="quotelev1">&gt; characterizing the ways in which different elements in a space are
</em><br />
<em class="quotelev1">&gt; similar or different, possibly in complex ways. An information space
</em><br />
<em class="quotelev1">&gt; is an abstract object, but following Shannon we can see information as
</em><br />
<em class="quotelev1">&gt; physically embodied when there is a space of distinct physical states,
</em><br />
<em class="quotelev1">&gt; the differences between which can be transmitted down some causal
</em><br />
<em class="quotelev1">&gt; pathway. The states that are transmitted can be seen as themselves
</em><br />
<em class="quotelev1">&gt; constituting an information space. To borrow a phrase from Bateson
</em><br />
<em class="quotelev1">&gt; (1972), physical information is a difference that makes a difference.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The double-aspect principle stems from the observation that there is a
</em><br />
<em class="quotelev1">&gt; direct isomorphism between certain physically embodied information
</em><br />
<em class="quotelev1">&gt; spaces and certain phenomenal (or experiential) information spaces.
</em><br />
<br />This can be shown false in Quantum theory without collapse, and more  
<br />
easily with the comp assumption.
<br />
No problem if you tell me that you reject both Everett and comp.  
<br />
Chalmers seems in some place to accept both Everett and comp, indeed.  
<br />
He explains to me that he stops at step 3. He believes that after a  
<br />
duplication you feel to be simultaneously at the both place, even  
<br />
assuming comp. I think and can argue that this is non sense. Nobody  
<br />
defends this on the list. Are you defending an idea like that?
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; From the same sort of observations that went into the principle of
</em><br />
<em class="quotelev1">&gt; structural coherence, we can note that the differences between
</em><br />
<em class="quotelev1">&gt; phenomenal states have a structure that corresponds directly to the
</em><br />
<em class="quotelev1">&gt; differences embedded in physical processes; in particular, to those
</em><br />
<em class="quotelev1">&gt; differences that make a difference down certain causal pathways
</em><br />
<em class="quotelev1">&gt; implicated in global availability and control. That is, we can find
</em><br />
<em class="quotelev1">&gt; the same abstract information space embedded in physical processing
</em><br />
<em class="quotelev1">&gt; and in conscious experience.
</em><br />
<br />Assuming comp, the expression &quot;physical processing&quot; cannot be taken  
<br />
for granted. It has to be explained.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; --
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; SEP:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Information cannot be dataless but, in the simplest case, it can
</em><br />
<em class="quotelev1">&gt; consist of a single datum.  A datum is reducible to just a lack of
</em><br />
<em class="quotelev1">&gt; uniformity (diaphora is the Greek word for “difference”), so a general
</em><br />
<em class="quotelev1">&gt; definition of a datum is:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The Diaphoric Definition of Data (DDD):
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; A datum is a putative fact regarding some difference or lack of
</em><br />
<em class="quotelev1">&gt; uniformity within some context.  [In particular data as diaphora de
</em><br />
<em class="quotelev1">&gt; dicto, that is, lack of uniformity between two symbols, for example
</em><br />
<em class="quotelev1">&gt; the letters A and B in the Latin alphabet.]
</em><br />
<br /><br />No problem with that.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; --
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Glenberg and Robertson:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Meaning arises from the syntactic combination of abstract, amodal
</em><br />
<em class="quotelev1">&gt; symbols that are arbitrarily related to what they signify.  A new form
</em><br />
<em class="quotelev1">&gt; of the abstract symbol approach to meaning affords the opportunity to
</em><br />
<em class="quotelev1">&gt; examine its adequacy as a psychological theory of meaning.  This form
</em><br />
<em class="quotelev1">&gt; is represented by two theories of linguistic meaning (that is, the
</em><br />
<em class="quotelev1">&gt; meaning of words, sentences, and discourses), both of which take
</em><br />
<em class="quotelev1">&gt; advantage of the mathematics of high-dimensional spaces. The
</em><br />
<em class="quotelev1">&gt; Hyperspace Analogue to Language (HAL; Burgess &amp; Lund, 1997) posits
</em><br />
<em class="quotelev1">&gt; that the meaning of a word is its vector representation in a space
</em><br />
<em class="quotelev1">&gt; based on 140,000 word–word co-occurrences. Latent Semantic Analysis
</em><br />
<em class="quotelev1">&gt; (LSA; Landauer &amp; Dumais, 1997) posits that the meaning of a word is
</em><br />
<em class="quotelev1">&gt; its vector representation in a space with approximately 300 dimensions
</em><br />
<em class="quotelev1">&gt; derived from a space with many more dimensions. The vector elements
</em><br />
<em class="quotelev1">&gt; found in both theories are just the sort of abstract features that are
</em><br />
<em class="quotelev1">&gt; prototypical in the cognitive psychology of meaning.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Landauer and Dumais also apply LSA to sentence and discourse
</em><br />
<em class="quotelev1">&gt; understanding. A sentence is represented as the average of the vectors
</em><br />
<em class="quotelev1">&gt; of the words it contains, and the coherence between sentences is
</em><br />
<em class="quotelev1">&gt; predicted by the cosine of the angle (in multidimensional space)
</em><br />
<em class="quotelev1">&gt; between the vectors corresponding to successive sentences.  They claim
</em><br />
<em class="quotelev1">&gt; that LSA averaged vectors capture “the central meaning” of passages
</em><br />
<em class="quotelev1">&gt; (p. 231).
</em><br />
<br /><br />Perhaps. I don't see the relevance. It is quite coherent with comp  
<br />
that some form of meaning can be approached in this or similar ways.  
<br />
Assuming comp, what can be considered as lacking is the self-reference  
<br />
of the universal machine involved in the attribution of meaning.
<br />
<br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Consider a thought experiment (adapted from Harnad, 1990, and related
</em><br />
<em class="quotelev1">&gt; to the Chinese Room Argument) that suggests that something critical is
</em><br />
<em class="quotelev1">&gt; missing from HAL and LSA. Imagine that you just landed at an airport
</em><br />
<em class="quotelev1">&gt; in a foreign country and that you do not speak the local language. As
</em><br />
<em class="quotelev1">&gt; you disembark, you notice a sign printed in the foreign language
</em><br />
<em class="quotelev1">&gt; (whose words are arbitrary abstract symbols to you). Your only
</em><br />
<em class="quotelev1">&gt; resource is a dictionary printed in that language; that is, the
</em><br />
<em class="quotelev1">&gt; dictionary consists of other arbitrary abstract symbols. You use the
</em><br />
<em class="quotelev1">&gt; dictionary to look up the first word in the sign, but you don’t know
</em><br />
<em class="quotelev1">&gt; the meaning of any of the words in the definition.  So, you look up
</em><br />
<em class="quotelev1">&gt; the first word in the definition, but you don’t know the meaning of
</em><br />
<em class="quotelev1">&gt; the words in that definition, and so on. Obviously, no matter how many
</em><br />
<em class="quotelev1">&gt; words you look up, that is, no matter how many structural relations
</em><br />
<em class="quotelev1">&gt; you determine among the arbitrary abstract symbols, you will never
</em><br />
<em class="quotelev1">&gt; figure out the meaning of any of the words.
</em><br />
<br />?
<br />
How do you thing a computer work?  (Well, I guess I am asking Harnad  
<br />
here).
<br />
<br /><br /><br /><em class="quotelev1">&gt; This is the symbol
</em><br />
<em class="quotelev1">&gt; grounding problem (Harnad, 1990): To know the meaning of an abstract
</em><br />
<em class="quotelev1">&gt; symbol such as an LSA vector or an English word, the symbol has to be
</em><br />
<em class="quotelev1">&gt; grounded in something other than more abstract symbols.
</em><br />
<br /><br />This has been a recurrent critics of mechanism and platonism. But  
<br />
unless introducing a substantial soul and dualism (and non  
<br />
computationalism) I don't see how such approach can work.
<br />
The grounding problem is what the notion of universal machine explains  
<br />
the best, at least if you agree that the arithmetical reality (not the  
<br />
formalism!) is independent of you (this is needed to even make a  
<br />
theory of information).
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Landauer and Dumais summarize the symbol grounding problem by noting,
</em><br />
<em class="quotelev1">&gt; “But still, to be more than an abstract system like mathematics words
</em><br />
<em class="quotelev1">&gt; must touch reality at least occasionally” (p. 227).
</em><br />
<br />Touch reality? Or touch physical reality? It is ambiguous in our  
<br />
context.
<br />
<br /><br /><br /><em class="quotelev1">&gt; Their proposed
</em><br />
<em class="quotelev1">&gt; solution is to encode, along with the word stream, the streams from
</em><br />
<em class="quotelev1">&gt; other sensory modalities.
</em><br />
<br /><br />With comp, those other &quot;sensory modalities&quot; are coded before being  
<br />
processed by the brain, or the universal machine under consideration.
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt; “Because, purely at the word–word level,
</em><br />
<em class="quotelev1">&gt; rabbit has been indirectly preestablished to be something like dog,
</em><br />
<em class="quotelev1">&gt; animal, object, furry, cute, fast, ears, etc., it is much less
</em><br />
<em class="quotelev1">&gt; mysterious that a few contiguous pairings of the word with scenes
</em><br />
<em class="quotelev1">&gt; including the thing itself can teach the proper correspondences.
</em><br />
<em class="quotelev1">&gt; Indeed, if one judiciously added numerous pictures of scenes with and
</em><br />
<em class="quotelev1">&gt; without rabbits to the context columns in the encyclopedia corpus
</em><br />
<em class="quotelev1">&gt; matrix, and filled in a handful of appropriate cells in the rabbit and
</em><br />
<em class="quotelev1">&gt; hare word rows, LSA could easily learn that the words rabbit and hare
</em><br />
<em class="quotelev1">&gt; go with pictures containing rabbits and not to ones without, and so
</em><br />
<em class="quotelev1">&gt; forth” (p. 227). Burgess and Lund (1997) offer a similar solution, “We
</em><br />
<em class="quotelev1">&gt; do think a HAL-like model that was sensitive to the same
</em><br />
<em class="quotelev1">&gt; co-occurrences in the natural environment as a human language learner
</em><br />
<em class="quotelev1">&gt; (not just the language stream) would be able to capitalize on this
</em><br />
<em class="quotelev1">&gt; additional information and construct more meaningful representations”
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; (p. 29).
</em><br />
<br /><br />This could be of interest for criticizing some implementation of  
<br />
artificial intelligence. But it is not relevant in our fundamental  
<br />
description because both the term &quot;rabbit&quot; and the picture of the  
<br />
rabbit have to be encoded in the universal machine. lewis Carroll  
<br />
himself we aware of the fun you can make with dictionary based theory  
<br />
of meaning.
<br />
<br />Kelly, the question is: do we disagree? I criticize your statement  
<br />
&quot;consciousness = information&quot; for vagueness, but only BECAUSE you have  
<br />
oppose it to the computationalist hypothesis, (and this despite you  
<br />
seem to appreciate its the platonist idealist consequence). It is a  
<br />
bit weird. Now, I am not even sure you criticize the computationalist  
<br />
hypothesis.
<br />
Neither you nor me can accept Chalmers dualism which relies on both  
<br />
comp and primitive matter, which I show to be epistemologically  
<br />
incompatible. But this is going in your direction. Where is the problem?
<br />
<br />Bruno
<br />
<br /><a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
<br />
<br /><br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sat May 23 2009 - 14:47:14 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start16674">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="16675.html" title="Next message in the list">Brent Meeker: "Re: Consciousness is information?"</a></li>
<li><dfn>Previous message</dfn>: <a href="16673.html" title="Previous message in the list">John Mikes: "Re: Consciousness is information?"</a></li>
<li><dfn>In reply to</dfn>: <a href="16671.html" title="Message to which this message replies">Kelly Harmon: "Re: Consciousness is information?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="16677.html" title="Next message in this discussion thread">Kelly Harmon: "Re: Consciousness is information?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="16677.html" title="Message sent in reply to this message">Kelly Harmon: "Re: Consciousness is information?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg16674" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg16674" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg16674" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg16674" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
