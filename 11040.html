<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: computationalism and supervenience from Brent Meeker on 2006-09-11 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: computationalism and supervenience" />
<meta name="Date" content="2006-09-11" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: computationalism and supervenience</h1>
<!-- received="Tue Sep 12 00:47:10 2006" -->
<!-- isoreceived="20060912074710" -->
<!-- sent="Mon, 11 Sep 2006 21:46:08 -0700" -->
<!-- isosent="20060912044608" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: computationalism and supervenience" -->
<!-- id="45063B90.1040009.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="BAY124-W7AB08D216D7CE685C7015D22B0.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start11040" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="11041.html" accesskey="d" title="Brent Meeker: &quot;Re: computationalism and supervenience&quot;">Next message</a> ]
[ <a href="11039.html" title="Colin Hales: &quot;RE: computationalism and supervenience&quot;">Previous message</a> ]
[ <a href="11038.html" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="11042.html" accesskey="t" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg11040" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg11040" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg11040" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg11040" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20computationalism%20and%20supervenience">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon, 11 Sep 2006 21:46:08 -0700</span><br />
</address>
<br />
Stathis Papaioannou wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Brent meeker writes:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;I could make a robot that, having suitable thermocouples, would quickly withdraw it's 
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;hand from a fire; but not be conscious of it.  Even if I provide the robot with 
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;&quot;feelings&quot;, i.e. judgements about good/bad/pain/pleasure I'm not sure it would be 
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;conscious.  But if I provide it with &quot;attention&quot; and memory, so that it noted the 
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;painful event as important and necessary to remember because of it's strong negative 
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;affect; then I think it would be conscious.
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;It's interesting that people actually withdraw their hand from the fire *before* they experience 
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;the pain. The withdrawl is a reflex, presumably evolved in organisms with the most primitive 
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;central nervour systems, while the pain seems to be there as an afterthought to teach us a 
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;lesson so we won't do it again. Thus, from consideration of evolutionary utility consciousness 
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;does indeed seem to be a side-effect of memory and learning. 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;Even more curious, volitional action also occurs before one is aware of it. Are you 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;familiar with the experiments of Benjamin Libet and Grey Walter?
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;These experiments showed that in apparently voluntarily initiated motion, motor cortex activity 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;actually preceded the subject's awareness of his intention by a substantial fraction of a second. 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;In other words, we act first, then &quot;decide&quot; to act. These studies did not examine pre-planned 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;action (presumably that would be far more technically difficult) but it is easy to imagine the analogous 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;situation whereby the action is unconsciously &quot;planned&quot; before we become aware of our decision. In 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;other words, free will is just a feeling which occurs after the fact. This is consistent with the logical 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;impossibility of something that is neither random nor determined, which is what I feel my free will to be.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;I also think that this is an argument against zombies. If it were possible for an organism to 
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;behave just like a conscious being, but actually be unconscious, then why would consciousness 
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;have evolved? 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;An interesting point - but hard to give any answer before pinning down what we mean 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;by consciousness.  For example Bruno, Julian Jaynes, and Daniel Dennett have 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;explanations; but they explain somewhat different consciousnesses, or at least 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;different aspects.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;Consciousness is the hardest thing to explain but the easiest thing to understand, if it's your own 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;consciousness at issue. I think we can go a long way discussing it assuming that we do know what 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;we are talking about even though we can't explain it. The question I ask is, why did people evolve 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;with this consciousness thing, whatever it is? The answer must be, I think, that it is a necessary 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;side-effect of the sort of neural complexity that underpins our behaviour. If it were not, and it 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;were possible that beings could behave exactly like humans and not be conscious, then it would 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;have been wasteful of nature to have provided us with consciousness. 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;This is not necessarily so.  First, evolution is constrained by what goes before. 
</em><br />
<em class="quotelev2">&gt;&gt;Its engineering solutions often seem rube-goldberg, e.g. backward retina in mammals. 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Sure, but vision itself would not have evolved unnecessarily.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt;&gt;  Second, there is selection against some evolved feature only to the extent it has a 
</em><br />
<em class="quotelev2">&gt;&gt;(net) cost.  For example, Jaynes explanation of consciousness conforms to these two 
</em><br />
<em class="quotelev2">&gt;&gt;criteria.  I think that any species that evolves intelligence comparable to ours will 
</em><br />
<em class="quotelev2">&gt;&gt;be conscious for reasons somewhat like Jaynes theory.  They will be social and this 
</em><br />
<em class="quotelev2">&gt;&gt;combined with intelligence will make language a good evolutionary move.  Once they 
</em><br />
<em class="quotelev2">&gt;&gt;have language, remembering what has happened, in order to communicate and plan, in 
</em><br />
<em class="quotelev2">&gt;&gt;symbolic terms will be a easy and natural evolvement.  Whether that leads to hearing 
</em><br />
<em class="quotelev2">&gt;&gt;your own narrative in your head, as Jaynes supposes, is questionable; but it would be 
</em><br />
<em class="quotelev2">&gt;&gt;consistent with evolution. It takes advantage of existing structure and functions to 
</em><br />
<em class="quotelev2">&gt;&gt;realize a useful new function.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Agreed. So consciousness is either there for a reason or it's a necessary side-effect of the sort 
</em><br />
<em class="quotelev1">&gt; of brains we have and the way we have evolved. It's still theoretically possible that if the latter 
</em><br />
<em class="quotelev1">&gt; is the case, we might have been unconscious if we had evolved completely different kinds of 
</em><br />
<em class="quotelev1">&gt; brains, but similar behaviour - although I think it unlikely.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;This does not necessarily 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;mean that computers can be conscious: maybe if we had evolved with electronic circuits in our 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;heads rather than neurons consciousness would not have been a necessary side-effect. 
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;But my point is that this may come down to what we would mean by a computer being 
</em><br />
<em class="quotelev2">&gt;&gt;conscious.  Bruno has an answer in terms of what the computer can prove.  Jaynes (and 
</em><br />
<em class="quotelev2">&gt;&gt;probably John McCarthy) would say a computer is conscious if it creates a narrative 
</em><br />
<em class="quotelev2">&gt;&gt;of its experience which it can access as memory.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Maybe this is a copout, but I just don't think it is even logically possible to explain what consciousness 
</em><br />
<em class="quotelev1">&gt; *is* unless you have it. 
</em><br />
<br />Not being *logically* possible means entailing a contradiction - I doubt that.  But 
<br />
anyway you do have it and you think I do because of the way we interact.  So if you 
<br />
interacted the same way with a computer and you further found out that the computer 
<br />
was a neural network that had learned through interaction with people over a period 
<br />
of years, you'd probably infer that the computer was conscious - at least you 
<br />
wouldn't be sure it wasn't.
<br />
<br /><em class="quotelev1">&gt;It's like the problem of explaining vision to a blind man: he might be the world's 
</em><br />
<em class="quotelev1">&gt; greatest scientific expert on it but still have zero idea of what it is like to see - and that's even though 
</em><br />
<em class="quotelev1">&gt; he shares most of the rest of his cognitive structure with other humans, and can understand analogies 
</em><br />
<em class="quotelev1">&gt; using other sensations. Knowing what sort of program a conscious computer would have to run to be 
</em><br />
<em class="quotelev1">&gt; conscious, what the purpose of consciousness is, and so on, does not help me to understand what the 
</em><br />
<em class="quotelev1">&gt; computer would be experiencing, except by analogy with what I myself experience. 
</em><br />
<br />But that's true of everything.  Suppose we knew a lot more about brains and we 
<br />
created an intelligent computer using brain-like functional architecture and it acted 
<br />
like a conscious human being, then I'd say we understood its consciousness better 
<br />
than we understand quantum field theory or global economics.
<br />
<br />Brent Meeker
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Stathis Papaioannou
</em><br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue Sep 12 2006 - 00:47:10 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start11040">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="11041.html" title="Next message in the list">Brent Meeker: "Re: computationalism and supervenience"</a></li>
<li><dfn>Previous message</dfn>: <a href="11039.html" title="Previous message in the list">Colin Hales: "RE: computationalism and supervenience"</a></li>
<li><dfn>In reply to</dfn>: <a href="11038.html" title="Message to which this message replies">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="11042.html" title="Next message in this discussion thread">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg11040" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg11040" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg11040" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg11040" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
