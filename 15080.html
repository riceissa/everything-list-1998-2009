<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: QTI &amp; euthanasia from Bruno Marchal on 2008-11-02 (everything)</title>
<meta name="Author" content="Bruno Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: QTI &amp; euthanasia" />
<meta name="Date" content="2008-11-02" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: QTI &amp; euthanasia</h1>
<!-- received="Sun Nov  2 11:08:44 2008" -->
<!-- isoreceived="20081102190844" -->
<!-- sent="Sun, 2 Nov 2008 17:08:32 +0100" -->
<!-- isosent="20081102160832" -->
<!-- name="Bruno Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: QTI &amp; euthanasia" -->
<!-- id="76887636-F652-45CE-B4CB-B6D2DA90FA61.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="7f53025b0811010426ta0fc0ecqae80cd34a0e07879.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start15080" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="15081.html" accesskey="d" title="Bruno Marchal: &quot;Re: QTI &#0038; euthanasia&quot;">Next message</a> ]
[ <a href="15079.html" title="Quentin Anciaux: &quot;Re: QTI &#0038; euthanasia&quot;">Previous message</a> ]
[ <a href="15066.html" title="Jason Resch: &quot;Re: QTI &#0038; euthanasia&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="15088.html" accesskey="t" title="Brent Meeker: &quot;Re: QTI &#0038; euthanasia&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15080" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15080" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15080" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15080" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Bruno Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20QTI%20%26%20euthanasia">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sun, 2 Nov 2008 17:08:32 +0100</span><br />
</address>
<br />
Replies to Jason Resch and Brent Meeker:
<br />
<br /><br />On 01 Nov 2008, at 12:26, Jason Resch wrote:
<br />
<br /><br /><em class="quotelev1">&gt; I've thought of an interesting modification to the original UDA  
</em><br />
<em class="quotelev1">&gt; argument which would suggest that one's consciousness is at both  
</em><br />
<em class="quotelev1">&gt; locations simultaneously.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Since the UDA accepts digital mechanism as its first premise, then  
</em><br />
<em class="quotelev1">&gt; it is possible to instantiate a consciousness within a computer.   
</em><br />
<em class="quotelev1">&gt; Therefore instead of a physical teleportation from Brussels to  
</em><br />
<em class="quotelev1">&gt; Washington and Moscow instead we will have a digital transfer.  This  
</em><br />
<em class="quotelev1">&gt; will allow the experimenter to have complete control over the input  
</em><br />
<em class="quotelev1">&gt; each mind receives and guarantee identical content of experience.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; A volunteer in Brussels has her brain frozen and scanned at the  
</em><br />
<em class="quotelev1">&gt; necessary substitution level and the results are loaded into a  
</em><br />
<em class="quotelev1">&gt; computer with the appropriate simulation software that can  
</em><br />
<em class="quotelev1">&gt; accurately model her brain's functions, therefore from her  
</em><br />
<em class="quotelev1">&gt; perspective, her consciousness continues onward from the time her  
</em><br />
<em class="quotelev1">&gt; brain was frozen.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; To implement the teleportation, the simulation in the computer in  
</em><br />
<em class="quotelev1">&gt; Brussels is paused, and a snapshot of the current state is sent over  
</em><br />
<em class="quotelev1">&gt; the Internet to two computers, one in Washington and the other in  
</em><br />
<em class="quotelev1">&gt; Moscow, each of these computers has the same simulation software and  
</em><br />
<em class="quotelev1">&gt; upon receipt, resume the simulation of the brain where it left off  
</em><br />
<em class="quotelev1">&gt; in Brussels.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The question is: if the sensory input is pre-fabricated and  
</em><br />
<em class="quotelev1">&gt; identical in both computers, are there two minds, or simply two  
</em><br />
<em class="quotelev1">&gt; implementations of the same mind?  If you believe there are two  
</em><br />
<em class="quotelev1">&gt; minds, consider the following additional steps.
</em><br />
<br /><br /><br />Only one mind, belonging to two relative histories (among an infinity).
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Since it was established that the experimenter can &quot;teleport&quot; minds  
</em><br />
<em class="quotelev1">&gt; by pausing a simulation, sending their content over the network, and  
</em><br />
<em class="quotelev1">&gt; resuming it elsewhere, then what happens if the experimenter wants  
</em><br />
<em class="quotelev1">&gt; to teleport the Washington mind to Moscow, and the Moscow mind to  
</em><br />
<em class="quotelev1">&gt; Washington?  Assume that both computers were preset to run the  
</em><br />
<em class="quotelev1">&gt; simulation for X number of CPU instructions before pausing the  
</em><br />
<em class="quotelev1">&gt; simulation and transferring the state, such that the states are  
</em><br />
<em class="quotelev1">&gt; exactly the same when each is sent.  Further assume that the  
</em><br />
<em class="quotelev1">&gt; harddrive space on the computers is limited, so as they receive the  
</em><br />
<em class="quotelev1">&gt; brain state, they overwrite their original save.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; During this procedure, the computers in Washington and Moscow each  
</em><br />
<em class="quotelev1">&gt; receive the other's brain state, however, it is exactly the same as  
</em><br />
<em class="quotelev1">&gt; the one they already had.  Therefore the overwriting is a no-op.   
</em><br />
<em class="quotelev1">&gt; After the transfer is complete, each computer resumes the  
</em><br />
<em class="quotelev1">&gt; simulation.  Now is Moscow's mind on the Washington computer?  If so  
</em><br />
<em class="quotelev1">&gt; how did a no-op (overwriting the file with the same bits) accomplish  
</em><br />
<em class="quotelev1">&gt; the teleportation, if not, what makes the teleportation fail?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; What happens in the case where the Washington and Moscow computer  
</em><br />
<em class="quotelev1">&gt; shutdown for some period of time (5 minutes for example) and then  
</em><br />
<em class="quotelev1">&gt; ONLY the Moscow computer is turned back on.  Did a &quot;virtual&quot;  
</em><br />
<em class="quotelev1">&gt; teleportation occur between Washington and Moscow to allow the  
</em><br />
<em class="quotelev1">&gt; consciousness that was in Washington to continue?  If not, then  
</em><br />
<em class="quotelev1">&gt; would a physical transfer of the data from Washington to Moscow have  
</em><br />
<em class="quotelev1">&gt; saved its consciousness, and if so, what happened to the Moscow  
</em><br />
<em class="quotelev1">&gt; consciousness?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; The above thought experiments led me to conclude that both computers  
</em><br />
<em class="quotelev1">&gt; implement the same mind and are the same mind, despite  having  
</em><br />
<em class="quotelev1">&gt; different explanations.
</em><br />
<br />Rigth.
<br />
<br /><br /><em class="quotelev1">&gt;  Turning off one of the computers in either Washington or Moscow,  
</em><br />
<em class="quotelev1">&gt; therefore, does not end the consciousness.
</em><br />
<br /><br />Yes.
<br />
<br /><br /><em class="quotelev1">&gt; Per the conclusions put forth in the UDA, the volunteer in Brussels  
</em><br />
<em class="quotelev1">&gt; would say she has a 1/2 chance of ending up in the Washington  
</em><br />
<em class="quotelev1">&gt; computer and 1/2 chance of ending up in the Moscow computer.   
</em><br />
<em class="quotelev1">&gt; Therefore, if you told her &quot;15 minutes after the teleportation the  
</em><br />
<em class="quotelev1">&gt; computer in Washington will be shut off forever&quot; she should expect a  
</em><br />
<em class="quotelev1">&gt; 1/2 chance of dying.  This seems to be a contradiction, as there is  
</em><br />
<em class="quotelev1">&gt; a &quot;virtual&quot; teleportation from Washington to Moscow which saves the  
</em><br />
<em class="quotelev1">&gt; consciousness in Washington from oblivion.  So her chances of death  
</em><br />
<em class="quotelev1">&gt; are 0, not 1/2, which is only explainable if we assume that her mind  
</em><br />
<em class="quotelev1">&gt; is subjectively in both places after the first teleport from  
</em><br />
<em class="quotelev1">&gt; Brussels, and so long as a simulation of her mind exists somewhere  
</em><br />
<em class="quotelev1">&gt; she will never die.
</em><br />
<br /><br />And an infinity of those simulations exists, a-spatially and a- 
<br />
temporally, in arithmetic, (or in  the &quot;standard model of  
<br />
arithmetic&quot;)  which entails comp-immortality (need step 8!). Actually  
<br />
a mind is never really located somewhere. Location is a construct of  
<br />
the mind. A (relative) body is what makes it possible for a mind to  
<br />
manifest itself relatively to some history/computation-from-inside.
<br />
The movie graph argument (the 8th of UDA) justifies the necessity of  
<br />
this, but just meditation on the phantom limbs can help. The pain is  
<br />
not in the limb (given the absence of the limb), and the pain is not  
<br />
in the brain, (the brain is not sensitive) yet the subject locates the  
<br />
pain in the limb. Similarly we located ourself in space time, but if  
<br />
you push the logic of comp to its ultimate conclusion you understand  
<br />
that, assuming comp, space time is a phantom itself. Plato was on the  
<br />
right (with respect to comp) track.
<br />
<br />(Math: And computer science makes it possible to derive the  
<br />
mathematical description of that phantom,  making comp Popper  
<br />
falsifiable. The phantom can be mathematically recovered from  
<br />
intensional variants of self-referential (Godel) provability modality  
<br />
G and G*).
<br />
<br /><br />==========================
<br />
Brent Meeker wrote
<br />
<br /><em class="quotelev1">&gt; My guess is that eventually we'll be able to create AI/robots that  
</em><br />
<em class="quotelev1">&gt; seem
</em><br />
<em class="quotelev1">&gt; as intelligent and conscious as, for example, dogs seem.
</em><br />
<em class="quotelev1">&gt; We'll also be
</em><br />
<em class="quotelev1">&gt; able to partially map brains so that we can say that when these  
</em><br />
<em class="quotelev1">&gt; neurons
</em><br />
<em class="quotelev1">&gt; do this the person is thinking thus and so. Once we have this degree  
</em><br />
<em class="quotelev1">&gt; of
</em><br />
<em class="quotelev1">&gt; understanding and control, questions about &quot;consciousness&quot; will no
</em><br />
<em class="quotelev1">&gt; longer seem relevant.  They'll be like the questions that philosophers
</em><br />
<em class="quotelev1">&gt; asked about life before we understood the molecular functions of  
</em><br />
<em class="quotelev1">&gt; living
</em><br />
<em class="quotelev1">&gt; systems.  They would ask:Where is the life?  Is a virus alive?  How  
</em><br />
<em class="quotelev1">&gt; does
</em><br />
<em class="quotelev1">&gt; life get passed from parent to child?   The questions won't get
</em><br />
<em class="quotelev1">&gt; answered; they'll just be seen as the wrong questions.
</em><br />
<br /><br /><br />You don't get the point. Mechanism is incompatible with naturalism. To  
<br />
solve the mind body problem, keeping mechanism, the laws of physicist  
<br />
have to be explained from computer science, even from the gap between  
<br />
computer science and computer's computer science ...
<br />
Physics is the fixed point of universal machine self observation.
<br />
Let me know at which step (1?, ... 8?) you have a problem? The only  
<br />
one not discussed thoroughly is the 8th one.
<br />
<br />To be sure, do you understand the nuance between the following theses:
<br />
<br />WEAK AI: some machines can behave as if their were conscious (but  
<br />
could as well be zombies)
<br />
STRONG AI: some machines can be conscious
<br />
COMP: I am a machine
<br />
<br />We have
<br />
<br />COMP =&gt; STRONG AI =&gt; WEAK AI
<br />
<br />WEAK does not imply STRONG AI which does not imply COMP. (it is not  
<br />
because machine can be conscious that we are necessarily machine  
<br />
ourself, of course with occam razor, STRONG AI go in the direction of  
<br />
COMP).
<br />
<br />Does those nuances make sense? If not (1...8) does not, indeed, make  
<br />
sense. You just don't believe in consciousness and/or person like in  
<br />
the eliminative materialism of neuro-philosophers ( the Churchland,  
<br />
amost Dennett in &quot;consciousness explained&quot;).
<br />
<br />Or you make us very special infinite analogical machines, but then you  
<br />
drop the digital mechanist thesis (even the naturalist one, which has  
<br />
been shown inconsistent by 1...8.)
<br />
<br /><br />Bruno Marchal
<br />
<br /><a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
<br />
<br /><br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sun Nov 02 2008 - 11:08:44 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start15080">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="15081.html" title="Next message in the list">Bruno Marchal: "Re: QTI &#0038; euthanasia"</a></li>
<li><dfn>Previous message</dfn>: <a href="15079.html" title="Previous message in the list">Quentin Anciaux: "Re: QTI &#0038; euthanasia"</a></li>
<li><dfn>In reply to</dfn>: <a href="15066.html" title="Message to which this message replies">Jason Resch: "Re: QTI &#0038; euthanasia"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="15088.html" title="Next message in this discussion thread">Brent Meeker: "Re: QTI &#0038; euthanasia"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="15088.html" title="Message sent in reply to this message">Brent Meeker: "Re: QTI &#0038; euthanasia"</a></li>
<li><dfn>Reply</dfn>: <a href="15174.html" title="Message sent in reply to this message">Brent Meeker: "Re: QTI &#0038; euthanasia"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15080" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15080" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15080" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15080" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
