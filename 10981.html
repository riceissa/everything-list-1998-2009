<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: computationalism and supervenience from Brent Meeker on 2006-09-08 (everything)</title>
<meta name="Author" content="Brent Meeker (meekerdb.domain.name.hidden)" />
<meta name="Subject" content="Re: computationalism and supervenience" />
<meta name="Date" content="2006-09-08" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: computationalism and supervenience</h1>
<!-- received="Fri Sep  8 03:40:28 2006" -->
<!-- isoreceived="20060908104028" -->
<!-- sent="Fri, 08 Sep 2006 00:38:15 -0700" -->
<!-- isosent="20060908073815" -->
<!-- name="Brent Meeker" -->
<!-- email="meekerdb.domain.name.hidden" -->
<!-- subject="Re: computationalism and supervenience" -->
<!-- id="45011DE7.402.domain.name.hidden" -->
<!-- charset="US-ASCII" -->
<!-- inreplyto="BAY124-W7FEA52DD8328501E48F1CD2370.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start10981" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="10982.html" accesskey="d" title="1Z: &quot;Re: computationalism and supervenience&quot;">Next message</a> ]
[ <a href="10980.html" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">Previous message</a> ]
[ <a href="10980.html" title="Stathis Papaioannou: &quot;RE: computationalism and supervenience&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="10989.html" accesskey="t" title="Brent Meeker: &quot;Re: computationalism and supervenience&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10981" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10981" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10981" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10981" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Brent Meeker &lt;<a href="mailto:meekerdb.domain.name.hidden?Subject=Re%3A%20computationalism%20and%20supervenience">meekerdb.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Fri, 08 Sep 2006 00:38:15 -0700</span><br />
</address>
<br />
Stathis Papaioannou wrote:
<br />
<em class="quotelev1">&gt; Brent Meeker writes:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;A non-conscious computation cannot be *useful* without the manual/interpretation,
</em><br />
<em class="quotelev3">&gt;&gt;&gt;and in this sense could be called just a potential computation, but a conscious
</em><br />
<em class="quotelev3">&gt;&gt;&gt;computation is still *conscious* even if no-one else is able to figure this out or
</em><br />
<em class="quotelev3">&gt;&gt;&gt;interact with it. If a working brain in a vat were sealed in a box and sent into
</em><br />
<em class="quotelev3">&gt;&gt;&gt;space, it could still be dreaming away even after the whole human race and all
</em><br />
<em class="quotelev3">&gt;&gt;&gt;their information on brain function are destroyed in a supernova explosion. As far
</em><br />
<em class="quotelev3">&gt;&gt;&gt;as any alien is concerned who comes across it, the brain might be completely
</em><br />
<em class="quotelev3">&gt;&gt;&gt;inscrutable, but that would not make the slightest difference to its conscious
</em><br />
<em class="quotelev3">&gt;&gt;&gt;experience.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;Suppose the aliens re-implanted the brain in a human body so they could interact with
</em><br />
<em class="quotelev2">&gt;&gt;it.  They ask it what is was &quot;dreaming&quot; all those years?  I think the answer might
</em><br />
<em class="quotelev2">&gt;&gt;be, &quot;Years?  What years?  It was just a few seconds ago I was in the hospital for an
</em><br />
<em class="quotelev2">&gt;&gt;appendectomy.  What happened?  And who are you guys?&quot;
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Maybe so; even more likely, the brain would just die. But these are contingent facts about 
</em><br />
<em class="quotelev1">&gt; human brains, while thought experiments rely on theoretical possibility.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev3">&gt;&gt;&gt;&gt;&gt;&gt;&gt;then it can be seen as implementing more than one computation
</em><br />
<em class="quotelev3">&gt;&gt;&gt;&gt;&gt;&gt;&gt;simultaneously during the given interval.
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;&gt;&gt;&gt;&gt;AFAICS that is only true in terms of dictionaries.
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;Right: without the dictionary, it's not very interesting or relevant to *us*.
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;If we were to actually map a random physical process onto an arbitrary
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;computation of interest, that would be at least as much work as building and
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;programming a conventional computer to carry out the computation. However,
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;doing the mapping does not make a difference to the *system* (assuming we
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;aren't going to use it to interact with it). If we say that under a certain
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;interpretation - here it is, printed out on paper - the system is implementing
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;a conscious computation, it would still be implementing that computation if we
</em><br />
<em class="quotelev1">&gt;&gt;&gt;&gt;&gt;had never determined and printed out the interpretation.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;And if you added the random values of the physical process as an appendix in the
</em><br />
<em class="quotelev2">&gt;&gt;manual, would the manual itself then be a computation (the record problem)?  If so
</em><br />
<em class="quotelev2">&gt;&gt;how would you tell if it were a conscious computation?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; The actual physical process becomes almost irrelevant. In the limiting case, all of the 
</em><br />
<em class="quotelev1">&gt; computation is contained in the manual, the physical existence of which makes no 
</em><br />
<em class="quotelev1">&gt; difference to whether or not the computation is implemented, since it makes no difference 
</em><br />
<em class="quotelev1">&gt; to the actual physical activity of the system and the theory under consideration is that 
</em><br />
<em class="quotelev1">&gt; consciousness supervenes on this physical activity. If we get rid of the qualifier &quot;almost&quot; 
</em><br />
<em class="quotelev1">&gt; the result is close to Bruno's theory, according to which the physical activity is irrelevant 
</em><br />
<em class="quotelev1">&gt; and the computation is &quot;run&quot; by virtue of its status as a Platonic object. As I understand 
</em><br />
<em class="quotelev1">&gt; it, Bruno arrives at this idea because it seems less absurd than the idea that consciousness 
</em><br />
<em class="quotelev1">&gt; supervenes on any and every physical process, while Maudlin finds both ideas absurd and 
</em><br />
<em class="quotelev1">&gt; thinks there is something wrong with computationalism.
</em><br />
<em class="quotelev1">&gt;  
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;The problem remains that the system's own self awareness, or lack thereof, is
</em><br />
<em class="quotelev4">&gt;&gt;&gt;&gt;not observer-relative. something has to give.
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;
</em><br />
<em class="quotelev3">&gt;&gt;&gt;Self-awareness is observer-relative with the observer being oneself. Where is the
</em><br />
<em class="quotelev3">&gt;&gt;&gt;difficulty?
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt;Self-awareness is awareness of some specific aspect of a construct called &quot;myself&quot;.
</em><br />
<em class="quotelev2">&gt;&gt;It is not strictly reflexive awareness of the being aware of being aware...  So in
</em><br />
<em class="quotelev2">&gt;&gt;the abstract computation it is just this part of a computation having some relation
</em><br />
<em class="quotelev2">&gt;&gt;we identify as &quot;awareness&quot; relative to some other part of the computation.  I think
</em><br />
<em class="quotelev2">&gt;&gt;it is a matter of constructing a narrative for memory in which &quot;I&quot; is just another
</em><br />
<em class="quotelev2">&gt;&gt;player.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I don't think &quot;self-awareness&quot; captures the essence of consciousness. 
</em><br />
<br />Neither do I; I was just responding to you noting that self-awareness is 
<br />
&quot;observer-relative&quot;.  The &quot;observer&quot; is really just a construct forced on us by 
<br />
grammar which demands that an action be done by someone or something.  We could more 
<br />
accurately say there is observation.
<br />
<br /><em class="quotelev1">&gt;We commonly think 
</em><br />
<em class="quotelev1">&gt; that consciousness is associated with intelligence, which is perhaps why it is often stated 
</em><br />
<em class="quotelev1">&gt; that a recording cannot be conscious, since a recording will not adapt to its environment in 
</em><br />
<em class="quotelev1">&gt; the manner we normally expect of intelligent agents. However, consider the experience of 
</em><br />
<em class="quotelev1">&gt; pain when you put your hand over a flame. There is certainly intelligent behaviour associated 
</em><br />
<em class="quotelev1">&gt; with this experience - learning to avoid it - but there is nothing &quot;intelligent&quot; about the raw 
</em><br />
<em class="quotelev1">&gt; experience of pain itself. It simply seems that when certain neurons in the brain fire, you 
</em><br />
<em class="quotelev1">&gt; experience a pain, as reliably and as stupidly as flicking a switch turns on a light. When an 
</em><br />
<em class="quotelev1">&gt; infant or an animal screams in agony it is not engaging in self-reflection, and for that matter 
</em><br />
<em class="quotelev1">&gt; neither is a philosopher: acute pain usually displaces every other concurrent conscious 
</em><br />
<em class="quotelev1">&gt; experience. A being  played a recording of a painful experience over and over into the relevant 
</em><br />
<em class="quotelev1">&gt; neural pathways may not be able to meaningfully interact with its environment, but it will 
</em><br />
<em class="quotelev1">&gt; be hellishly conscious nonetheless.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Stathis Papaioannou
</em><br />
<br />I could make a robot that, having suitable thermocouples, would quickly withdraw it's 
<br />
hand from a fire; but not be conscious of it.  Even if I provide the robot with 
<br />
&quot;feelings&quot;, i.e. judgements about good/bad/pain/pleasure I'm not sure it would be 
<br />
conscious.  But if I provide it with &quot;attention&quot; and memory, so that it noted the 
<br />
painful event as important and necessary to remember because of it's strong negative 
<br />
affect; then I think it would be conscious.
<br />
<br />Brent Meeker
<br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list">http://groups.google.com/group/everything-list</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Fri Sep 08 2006 - 03:40:28 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start10981">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="10982.html" title="Next message in the list">1Z: "Re: computationalism and supervenience"</a></li>
<li><dfn>Previous message</dfn>: <a href="10980.html" title="Previous message in the list">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<li><dfn>In reply to</dfn>: <a href="10980.html" title="Message to which this message replies">Stathis Papaioannou: "RE: computationalism and supervenience"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="10989.html" title="Next message in this discussion thread">Brent Meeker: "Re: computationalism and supervenience"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg10981" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg10981" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg10981" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg10981" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:12 PST
</em></small></p>
</body>
</html>
