<?xml version="1.0" encoding="us-ascii"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=us-ascii" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: against computationalism from Christopher Maloney on 1999-08-02 (everything)</title>
<meta name="Author" content="Christopher Maloney (dude.domain.name.hidden)" />
<meta name="Subject" content="Re: against computationalism" />
<meta name="Date" content="1999-08-02" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: against computationalism</h1>
<!-- received="Mon Aug  2 05:01:17 1999" -->
<!-- isoreceived="19990802120117" -->
<!-- sent="Mon, 02 Aug 1999 07:49:40 -0400" -->
<!-- isosent="19990802114940" -->
<!-- name="Christopher Maloney" -->
<!-- email="dude.domain.name.hidden" -->
<!-- subject="Re: against computationalism" -->
<!-- id="37A585D4.A5EBF910.domain.name.hidden" -->
<!-- charset="us-ascii" -->
<!-- inreplyto="v03020900b3c0ca93b6beF-AT_SYMBOL-[195.220.79.74]" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start1063" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="1064.html" accesskey="d" title="Christopher Maloney: &quot;Re: Fwd: Implementation/Relativity&quot;">Next message</a> ]
[ <a href="1062.html" title="Hans Moravec: &quot;Re: Implementation&quot;">Previous message</a> ]
[ <a href="1060.html" title="Gilles HENRI: &quot;against computationalism&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="1068.html" accesskey="t" title="Gilles HENRI: &quot;Re: against computationalism&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1063" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1063" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1063" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1063" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Christopher Maloney &lt;<a href="mailto:dude.domain.name.hidden?Subject=Re%3A%20against%20computationalism">dude.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Mon, 02 Aug 1999 07:49:40 -0400</span><br />
</address>
<br />
Gilles HENRI wrote:
<br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I'd like to expose some arguments against computationalism - mainly
</em><br />
<em class="quotelev1">&gt; elaborated through the various discussions on this list, many thanks to all
</em><br />
<em class="quotelev1">&gt; contributors!
</em><br />
<em class="quotelev1">&gt; I think we should distinguish between two forms of computationalism, which
</em><br />
<em class="quotelev1">&gt; are unfortunately often confused in many discussions:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; comp1 : the brain is an EXACT implementation of some digital computation
</em><br />
<em class="quotelev1">&gt; equivalent to a TM. The running of this computation on any equivalent TM
</em><br />
<em class="quotelev1">&gt; would produce exactly the same output.
</em><br />
<em class="quotelev1">&gt; In other words, we are just running a very complicated digital program
</em><br />
<em class="quotelev1">&gt; (much like Word but still more complicated!) that could run on any platform
</em><br />
<em class="quotelev1">&gt; (complicated enough). Like our ordinary computers, the implementation must
</em><br />
<em class="quotelev1">&gt; be independant of the material structure of the platform, and thus the
</em><br />
<em class="quotelev1">&gt; information must lie at a (much) higher level than the molecular one, most
</em><br />
<em class="quotelev1">&gt; probably at the level of a neuron state, just like the bits of a computer.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; I think we will all agree that the experimental facts from neurobiology are
</em><br />
<em class="quotelev1">&gt; enough to conclude that comp1 is FALSE, because a neuron state can not be
</em><br />
<em class="quotelev1">&gt; defined in a discrete, deterministic way. The firing pattern depends also
</em><br />
<em class="quotelev1">&gt; on many analogic quantities (temperature, concentration of various
</em><br />
<em class="quotelev1">&gt; neurotransmettors,  possible drugs) and has a strong probabilistic
</em><br />
<em class="quotelev1">&gt; (pseudo-random) behaviour.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Most of you seem to conclude : &quot;ok, no problem. We know that all these
</em><br />
<em class="quotelev1">&gt; analogic parameters can be modelized by deterministic equations; it's
</em><br />
<em class="quotelev1">&gt; enough to implement the solution of these equations to produce the same
</em><br />
<em class="quotelev1">&gt; output as the brain, and THUS consciousness, and that's it.&quot;.
</em><br />
<em class="quotelev1">&gt; Most of the (if not all) devices dicussed as &quot;artificial conscious
</em><br />
<em class="quotelev1">&gt; machines&quot;,(including Bruno's &quot;crackpot&quot; dreaming machine) are based on this
</em><br />
<em class="quotelev1">&gt; assumption.  As the brain is in fact interacting with the outer world (a
</em><br />
<em class="quotelev1">&gt; point that would deserve more discussions : I think that even dreams or
</em><br />
<em class="quotelev1">&gt; hallucinations would not be possible if the brain had NEVER interacted with
</em><br />
<em class="quotelev1">&gt; its environment), you soon realize that the equations must take into
</em><br />
<em class="quotelev1">&gt; account the whole Universe, a la Schmidhuber. To recall last Tegmark's
</em><br />
<em class="quotelev1">&gt; quote:
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev2">&gt; &gt;   Let us imagine a hypothetical Universe much larger than our own,
</em><br />
<em class="quotelev2">&gt; &gt;   which contains a computer so powerful that it can simulate the time-
</em><br />
<em class="quotelev2">&gt; &gt;   evolution of our entire Universe.  BY HYPOTHESIS (*I emphasize*), the
</em><br />
<em class="quotelev2">&gt; &gt;humans in this
</em><br />
<em class="quotelev2">&gt; &gt;   simulated world would perceive their world as being as real as we
</em><br />
<em class="quotelev2">&gt; &gt;   perceive ours, so by definition, the simulated universe would have
</em><br />
<em class="quotelev2">&gt; &gt;   PE [physical existence].
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt;   So you are led to another hypothesis, that I will call comp2, which is in
</em><br />
<em class="quotelev1">&gt; fact Bruno's &quot;comp&quot; postulate.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; comp2 : all the physical world is EXACTLY equivalent to some computation of
</em><br />
<em class="quotelev1">&gt; its analogic properties at a finite level .
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; As Bruno shows it magnificently, comp2 leads inevitably to the actual
</em><br />
<em class="quotelev1">&gt; disappearance of the physical world, replaced by a world of computations.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; However, I want to stress here that comp2 is indeed a huge jump: in fact it
</em><br />
<em class="quotelev1">&gt; does not COMPLEMENT but rather CONTRADICT comp1; it is the source of all
</em><br />
<em class="quotelev1">&gt; paradoxes and worst, it it completely useless to understand the origin of
</em><br />
<em class="quotelev1">&gt; consciousness.
</em><br />
<br />What paradoxes?
<br />
<br /><em class="quotelev1">&gt; comp2 contradicts comp1 because the essence of comp1 is the independance of
</em><br />
<em class="quotelev1">&gt; the results with respect to the material implementation, whereas comp2
</em><br />
<em class="quotelev1">&gt; requires the precize definition of this implementation (of course the
</em><br />
<em class="quotelev1">&gt; simulation made in comp2 could be runned on any TM, but the object of the
</em><br />
<em class="quotelev1">&gt; simulation must be one precise physical system).
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br />I don't see that as necessarily true.  Couldn't comp2 be an ensemble of
<br />
computations, each of which represents one &quot;universe&quot;, or one set of
<br />
physical laws?  We are interested in that ensemble which contains SASs
<br />
that can be mapped to ourselves.  So we can be existing in multiple
<br />
universes simultaneously.
<br />
<br />Even if not, I don't follow your reasoning that comp1 is contradicted.
<br />
When you say &quot;of course the simulation made in comp2 could be running
<br />
on any TM&quot;, I understand that to be thing in comp1 that you are saying
<br />
is contradicted.  So where's the problem, exactly?
<br />
<br /><em class="quotelev1">&gt; One of the problem is to find the actual level at which this simulation
</em><br />
<em class="quotelev1">&gt; should be made. As I already stressed, the physical laws we are using do
</em><br />
<em class="quotelev1">&gt; not describe the REALITY, but only our REPRESENTATION of it. Although it is
</em><br />
<em class="quotelev1">&gt; plausible that there is SOMETHING objective, we have no idea what this
</em><br />
<em class="quotelev1">&gt; could be (&quot;das Ding an sich following Kant). So which representation to
</em><br />
<em class="quotelev1">&gt; choose ? The chemical description ? The QM state ? String theory  ?(with
</em><br />
<em class="quotelev1">&gt; the supplementary difficulty that beyond the QM level, no measurement of
</em><br />
<em class="quotelev1">&gt; the Q-state is possible). You could try to accept any level giving an
</em><br />
<em class="quotelev1">&gt; acceptable output, but then isn't Hans right when he assumes that even
</em><br />
<em class="quotelev1">&gt; Teddy bears and movies characters have &quot;acceptable enough&quot; outputs to be
</em><br />
<em class="quotelev1">&gt; considered as conscious?
</em><br />
<em class="quotelev1">&gt; Note that this first difficulty did not exist with comp1, but we are facing
</em><br />
<em class="quotelev1">&gt; it inevitably with comp2.
</em><br />
<br />No, I don't think so.  I think we will find that these laws are derivable
<br />
from comp2 and what Bruno calls &quot;computational indeterminacy&quot; -- that we
<br />
don't know &quot;which&quot; computation we are in.
<br />
<br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Assume you have solved this difficulty, either by finding a known (e.g.
</em><br />
<em class="quotelev1">&gt; electro/chemical) level at which the brain evolution IS predictible, or by
</em><br />
<em class="quotelev1">&gt; finding a (subquantum) TOE reproducing exactly all know features of the
</em><br />
<em class="quotelev1">&gt; Universe. You may hope to describe your brain at this level and calculate
</em><br />
<em class="quotelev1">&gt; its evolution. You may think (with comp2) that a TM calculating the state
</em><br />
<em class="quotelev1">&gt; of your brain would actually be conscious LIKE YOU.
</em><br />
<em class="quotelev1">&gt; I will not recall all paradoxes associated with this hypothesis (for
</em><br />
<em class="quotelev1">&gt; example Olympia/Karas paradox) But taking again just the chinese room
</em><br />
<em class="quotelev1">&gt; example, let think of the case where your brain would be actually simulated
</em><br />
<em class="quotelev1">&gt; not by a machine but BY SOMEBODY ELSE ? Who or what would feel your
</em><br />
<em class="quotelev1">&gt; consciousness ? You could imagine a situation where the entirely state of
</em><br />
<em class="quotelev1">&gt; your brain at some instant is stored in a huge library, and somebody (for
</em><br />
<em class="quotelev1">&gt; example me) is put in charge to calculate its evolution (for example
</em><br />
<em class="quotelev1">&gt; applying id\psi/dt = H \psi to a quantum state). What do I have to do for
</em><br />
<em class="quotelev1">&gt; this device to actually think (like you, not me) ? Must I write the output
</em><br />
<em class="quotelev1">&gt; of my calculation somewhere? with a pen? on a magnetic tape? what if I read
</em><br />
<em class="quotelev1">&gt; a stored file of a previous calculation ? And if it is read by somebody
</em><br />
<em class="quotelev1">&gt; else that does not know what it represents? Please tell me ! I am paid for
</em><br />
<em class="quotelev1">&gt; this job and I don't want to be fired!
</em><br />
<em class="quotelev1">&gt; Of course I just point out again the contradictions between comp2 and
</em><br />
<em class="quotelev1">&gt; physical supervenience, but abandonning Phys-sup does not solve the first
</em><br />
<em class="quotelev1">&gt; point. It makes it still worse because abandoning the idea of physical
</em><br />
<em class="quotelev1">&gt; reality (Marchal) means also the impossibility of linking a computation
</em><br />
<em class="quotelev1">&gt; with a physical state, which is the starting point of comp2 and
</em><br />
<em class="quotelev1">&gt; Tegmark-Schmidhuber and co..theory!!!
</em><br />
<br />I disagree completely with your analysis in the last paragraph.  The
<br />
Chinese room thought experiment, as well as Maudlin's argument, are
<br />
entirely bogus.  In short, let me try to explain why.  Let me draw an
<br />
analogy between the common-sense view of physical reality and your
<br />
&quot;library&quot; example.  In the former, there are physical laws which govern
<br />
the motion and interaction of innumerable sub-atomic particles in my
<br />
brain, which map in some way into a computation.  They map as surely
<br />
as a macroscopic digital computer maps -- but in a much more complicated
<br />
and diffuse way.  
<br />
<br />In the latter (your library example), you have to consider the entire
<br />
system - library, books, you, the food you'd eat - everything.  Then you'd
<br />
find that that entire system maps onto a computation by virtue of the
<br />
actions you'd take in performing your job.  So I'd say that the system as
<br />
a whole is conscious.  It might be a ridiculously precarious consciousness -
<br />
as you say - you might not be very reliable in doing your job.  But that
<br />
would, I'd suggest, be analogous to (in the common-sense physics view)
<br />
having a fatal disease that could kill me at any second.
<br />
<br />&nbsp;
<br />
<em class="quotelev1">&gt; A third and last difficulty is that comp2 does not solve the problem of
</em><br />
<em class="quotelev1">&gt; consciousness. For if everything is assimilable to computations, what makes
</em><br />
<em class="quotelev1">&gt; some computations or parts of computations conscious or not (see Wei)? So
</em><br />
<em class="quotelev1">&gt; how to found Bruno's &quot;computational psychology&quot; ? What is the dream of a
</em><br />
<em class="quotelev1">&gt; string? Complexity is not enough, because for example the chemical
</em><br />
<em class="quotelev1">&gt; evolution of a thinking brain is not more complex to that of a dead brain
</em><br />
<em class="quotelev1">&gt; leading to putrefaction. At the analogic level of comp2, you have lost the
</em><br />
<em class="quotelev1">&gt; information level of comp1 ! I agree that the problem is the same with
</em><br />
<em class="quotelev1">&gt; materialism - I just point out that it is not easier with comp2.
</em><br />
<br />Asking a rhetorical question, &quot;what makes some computations or parts of 
<br />
computations conscious or not,&quot; is not the same as a refutation.  I don't
<br />
see how you have presented any problem about comp2 in this preceding
<br />
paragraph.
<br />
<br /><br /><em class="quotelev1">&gt; So I think that pure computationalism, either comp1 or comp2, is very hard
</em><br />
<em class="quotelev1">&gt; to maintain. Another comp3 proposition?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; One remark is that all &quot;thinking&quot; devices based on digital simulations of
</em><br />
<em class="quotelev1">&gt; the analogic state of the brain handle in fact much more (and too much)
</em><br />
<em class="quotelev1">&gt; information than the brain itself, which is totally unaware of its own
</em><br />
<em class="quotelev1">&gt; material structure. A very important fact is that they ALL require an
</em><br />
<em class="quotelev1">&gt; external structure able to store the relevant information and program them
</em><br />
<em class="quotelev1">&gt; adequately, which is NOT the case of actual brains (and I guess of possible
</em><br />
<em class="quotelev1">&gt; future thinking machines).
</em><br />
<br />What!!???  Of course the program being run by a brain requires an external
<br />
structure - the brain!  What do you mean by this last paragraph?
<br />
<br /><br /><em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt;  So my guess is that consciousness requires not only a proper handling of
</em><br />
<em class="quotelev1">&gt; information, but that this handling must be a natural consequence of
</em><br />
<em class="quotelev1">&gt; physical evolution without ANY interaction with an external storage of
</em><br />
<em class="quotelev1">&gt; information about its own structure, even for its construction. This would
</em><br />
<em class="quotelev1">&gt; insure the proper handling of counterfactuals which is in fact nothing else
</em><br />
<em class="quotelev1">&gt; than the self-construction of consciousness. This is NOT to be taken as a
</em><br />
<em class="quotelev1">&gt; formal definition of consciousness but only a possible restriction to get
</em><br />
<em class="quotelev1">&gt; an actually conscious device. It would not be pure computationalism because
</em><br />
<em class="quotelev1">&gt; it would put restrictions on the kind of implementations it requires.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Comments?
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Gilles
</em><br />
<br /><pre>
-- 
Chris Maloney
<a href="http://www.chrismaloney.com">http://www.chrismaloney.com</a>
&quot;Donuts are so sweet and tasty.&quot;
-- Homer Simpson
</pre>
<span id="received"><dfn>Received on</dfn> Mon Aug 02 1999 - 05:01:17 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start1063">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="1064.html" title="Next message in the list">Christopher Maloney: "Re: Fwd: Implementation/Relativity"</a></li>
<li><dfn>Previous message</dfn>: <a href="1062.html" title="Previous message in the list">Hans Moravec: "Re: Implementation"</a></li>
<li><dfn>In reply to</dfn>: <a href="1060.html" title="Message to which this message replies">Gilles HENRI: "against computationalism"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="1068.html" title="Next message in this discussion thread">Gilles HENRI: "Re: against computationalism"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="1068.html" title="Message sent in reply to this message">Gilles HENRI: "Re: against computationalism"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg1063" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg1063" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg1063" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg1063" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:06 PST
</em></small></p>
</body>
</html>
