<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: How would a computer know if it were conscious? from Quentin Anciaux on 2007-06-02 (everything)</title>
<meta name="Author" content="Quentin Anciaux (allcolor.domain.name.hidden)" />
<meta name="Subject" content="Re: How would a computer know if it were conscious?" />
<meta name="Date" content="2007-06-02" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: How would a computer know if it were conscious?</h1>
<!-- received="Sat Jun  2 17:36:31 2007" -->
<!-- isoreceived="20070603003631" -->
<!-- sent="Sat, 2 Jun 2007 23:36:18 +0200" -->
<!-- isosent="20070602213618" -->
<!-- name="Quentin Anciaux" -->
<!-- email="allcolor.domain.name.hidden" -->
<!-- subject="Re: How would a computer know if it were conscious?" -->
<!-- id="200706022336.18516.allcolor.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20070602201330.14EC014F6BC.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13437" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13438.html" accesskey="d" title="Brent Meeker: &quot;Re: How would a computer know if it were conscious?&quot;">Next message</a> ]
[ <a href="13436.html" title="Quentin Anciaux: &quot;Re: How would a computer know if it were conscious?&quot;">Previous message</a> ]
[ <a href="13435.html" title="Hal Finney: &quot;How would a computer know if it were conscious?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13438.html" accesskey="t" title="Brent Meeker: &quot;Re: How would a computer know if it were conscious?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13437" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13437" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13437" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13437" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Quentin Anciaux &lt;<a href="mailto:allcolor.domain.name.hidden?Subject=Re%3A%20How%20would%20a%20computer%20know%20if%20it%20were%20conscious%3F">allcolor.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Sat, 2 Jun 2007 23:36:18 +0200</span><br />
</address>
<br />
I'd like to add a &quot;definition&quot; of consciousness.
<br />
<br />Consciousness is the inner narative composed of sounds/images/feelings which 
<br />
present itself as 'I'. What is (the origin/meaning) of 'I', I don't know, 
<br />
but 'I' is the consciousness.
<br />
<br />Quentin
<br />
<br />On Saturday 02 June 2007 22:13:30 Hal Finney wrote:
<br />
<em class="quotelev1">&gt; Various projects exist today aiming at building a true Artificial
</em><br />
<em class="quotelev1">&gt; Intelligence.  Sometimes these researchers use the term AGI, Artificial
</em><br />
<em class="quotelev1">&gt; General Intelligence, to distinguish their projects from mainstream AI
</em><br />
<em class="quotelev1">&gt; which tends to focus on specific tasks.  A conference on such projects
</em><br />
<em class="quotelev1">&gt; will be held next year, agi-08.org.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Suppose one of these projects achieves one of the milestone goals of
</em><br />
<em class="quotelev1">&gt; such efforts; their AI becomes able to educate itself by reading books
</em><br />
<em class="quotelev1">&gt; and reference material, rather than having to have facts put in by
</em><br />
<em class="quotelev1">&gt; the developers.  Perhaps it requires some help with this, and various
</em><br />
<em class="quotelev1">&gt; questions and ambiguities need to be answered by humans, but still this is
</em><br />
<em class="quotelev1">&gt; a huge advancement as the AI can now in principle learn almost any field.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Keep in mind that this AI is far from passing the Turing test; it is able
</em><br />
<em class="quotelev1">&gt; to absorb and digest material and then answer questions or perhaps even
</em><br />
<em class="quotelev1">&gt; engage in a dialog about it.  But its complexity is, we will suppose,
</em><br />
<em class="quotelev1">&gt; substantially less than the human brain.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Now at some point the AI reads about the philosophy of mind, and the
</em><br />
<em class="quotelev1">&gt; question is put to it: are you conscious?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; How might an AI program go about answering a question like this?
</em><br />
<em class="quotelev1">&gt; What kind of reasoning would be applicable?  In principle, how would
</em><br />
<em class="quotelev1">&gt; you expect a well-designed AI to decide if it is conscious?  And then,
</em><br />
<em class="quotelev1">&gt; how or why is the reasoning different if a human rather than an AI is
</em><br />
<em class="quotelev1">&gt; answering them?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Clearly the AI has to start with the definition.  It needs to know what
</em><br />
<em class="quotelev1">&gt; consciousness is, what the word means, in order to decide if it applies.
</em><br />
<em class="quotelev1">&gt; Unfortunately such definitions usually amount to either a list of
</em><br />
<em class="quotelev1">&gt; synonyms for consciousness, or use the common human biological heritage
</em><br />
<em class="quotelev1">&gt; as a reference.  From the Wikipedia: &quot;Consciousness is a quality of the
</em><br />
<em class="quotelev1">&gt; mind generally regarded to comprise qualities such as subjectivity,
</em><br />
<em class="quotelev1">&gt; self-awareness, sentience, sapience, and the ability to perceive the
</em><br />
<em class="quotelev1">&gt; relationship between oneself and one's environment.&quot;  Here we have four
</em><br />
<em class="quotelev1">&gt; synonyms and one relational description which would arguably apply to
</em><br />
<em class="quotelev1">&gt; any computer system that has environmental sensors, unless &quot;perceive&quot;
</em><br />
<em class="quotelev1">&gt; is also merely another synonym for conscious perception.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It looks to me like AIs, even ones much more sophisticated than I am
</em><br />
<em class="quotelev1">&gt; describing here, are going to have a hard time deciding whether they
</em><br />
<em class="quotelev1">&gt; are conscious in the human sense.  Since humans seem essentially unable
</em><br />
<em class="quotelev1">&gt; to describe consciousness in any reasonable operational terms, there
</em><br />
<em class="quotelev1">&gt; doesn't seem any acceptable way for an AI to decide whether the word
</em><br />
<em class="quotelev1">&gt; applies to itself.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; And given this failure, it calls into question the ease with which
</em><br />
<em class="quotelev1">&gt; humans assert that they are conscious.  How do we really know that
</em><br />
<em class="quotelev1">&gt; we are conscious?  For example, how do we know that what we call
</em><br />
<em class="quotelev1">&gt; consciousness is what everyone else calls consciousness?  I am worried
</em><br />
<em class="quotelev1">&gt; that many people believe they are conscious simply because as children,
</em><br />
<em class="quotelev1">&gt; they were told they were conscious.  They were told that consciousness
</em><br />
<em class="quotelev1">&gt; is the difference between being awake and being asleep, and assume on
</em><br />
<em class="quotelev1">&gt; that basis that when they are awake they are conscious.  Then all those
</em><br />
<em class="quotelev1">&gt; other synonyms are treated the same way.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Yet most humans would not admit to any doubt that they are conscious.
</em><br />
<em class="quotelev1">&gt; For such a slippery and seemingly undefinable concept, it seems odd
</em><br />
<em class="quotelev1">&gt; that people are so sure of it.  Why, then, can't an AI achieve a similar
</em><br />
<em class="quotelev1">&gt; degree of certainty?  Do you think a properly programmed AI would ever
</em><br />
<em class="quotelev1">&gt; say, yes, I am conscious, because I have subjectivity, self-awareness,
</em><br />
<em class="quotelev1">&gt; sentience, sapience, etc., and I know this because it is just inherent in
</em><br />
<em class="quotelev1">&gt; my artificial brain?  Presumably we could program the AI to say this,
</em><br />
<em class="quotelev1">&gt; and to believe it (in whatever sense that word applies), but is it
</em><br />
<em class="quotelev1">&gt; something an AI could logically conclude?
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Hal
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Sat Jun 02 2007 - 17:36:31 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13437">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13438.html" title="Next message in the list">Brent Meeker: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13436.html" title="Previous message in the list">Quentin Anciaux: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13435.html" title="Message to which this message replies">Hal Finney: "How would a computer know if it were conscious?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13438.html" title="Next message in this discussion thread">Brent Meeker: "Re: How would a computer know if it were conscious?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="13438.html" title="Message sent in reply to this message">Brent Meeker: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13437" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13437" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13437" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13437" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
