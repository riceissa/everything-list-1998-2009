<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: MGA 1 from Bruno Marchal on 2008-11-25 (everything)</title>
<meta name="Author" content="Bruno Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: MGA 1" />
<meta name="Date" content="2008-11-25" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: MGA 1</h1>
<!-- received="Tue Nov 25 13:54:52 2008" -->
<!-- isoreceived="20081125215452" -->
<!-- sent="Tue, 25 Nov 2008 19:00:01 +0100" -->
<!-- isosent="20081125180001" -->
<!-- name="Bruno Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: MGA 1" -->
<!-- id="7EA52564-47B8-471F-B4A5-C5BED7756E4F.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="294BDFBC-92F4-4796-AD71-C920C9ED683B.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start15449" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="15450.html" accesskey="d" title="Brent Meeker: &quot;Re: MGA 1&quot;">Next message</a> ]
[ <a href="15448.html" title="Kory Heath: &quot;Re: MGA 2&quot;">Previous message</a> ]
[ <a href="15447.html" title="Kory Heath: &quot;Re: MGA 1&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="15450.html" accesskey="t" title="Brent Meeker: &quot;Re: MGA 1&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15449" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15449" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15449" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15449" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Bruno Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20MGA%201">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 25 Nov 2008 19:00:01 +0100</span><br />
</address>
<br />
On 25 Nov 2008, at 15:49, Kory Heath wrote:
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; On Nov 25, 2008, at 2:55 AM, Bruno Marchal wrote:
</em><br />
<em class="quotelev2">&gt;&gt; So you agree that MGA 1 does show that Lucky Alice is conscious
</em><br />
<em class="quotelev2">&gt;&gt; (logically).
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I think I have a less rigorous view of the argument than you do. You
</em><br />
<em class="quotelev1">&gt; want the argument to have the rigor of a mathematical proof.
</em><br />
<br /><br /><br />Yes. But it is applied mathematics, in a difficult domain (psychology/ 
<br />
theology and foundation of physics).
<br />
<br />There is a minimum of common sense and candidness which is asked for.  
<br />
The proof is rigorous in the way it should give to anyone the feeling  
<br />
that it could be entirely formalized in some intensional mathematics,  
<br />
S4 with quantifiers, or in the modal variant of G and G*. This is  
<br />
eventually the purpose of the interview of the lobian machine (using  
<br />
Theaetetus epistemological definition). But this is normally not  
<br />
needed for &quot;conscious english speaking being with enough common sense  
<br />
and some interest in the matter&quot;.
<br />
<br /><br /><em class="quotelev1">&gt; You say
</em><br />
<em class="quotelev1">&gt; &quot;Let's start with the mechanist-materialist assumption that Fully-
</em><br />
<em class="quotelev1">&gt; Functional Alice is conscious. We can replace her neurons one-by-one
</em><br />
<em class="quotelev1">&gt; with random neurons
</em><br />
<br /><br />They are random in the sense that ALL strings are random. They are not  
<br />
random in Kolmogorov sense for example. MGA 2 should make this clear.
<br />
<br /><br /><br /><em class="quotelev1">&gt; that just happen to do what the fully-functional
</em><br />
<em class="quotelev1">&gt; ones were going to do.
</em><br />
<br /><br />It is not random for that very reason. It is luckiness in MGA 1, and  
<br />
the record of computations in MGA 2.
<br />
<br /><br /><br /><em class="quotelev1">&gt; By definition none of her exterior or interior
</em><br />
<em class="quotelev1">&gt; behavior changes.
</em><br />
<br /><br />I never use those terms in this context, except in comp jokes like  
<br />
&quot;the brain is in the brain&quot;. It is dangerous because interior/exterior  
<br />
can refer both to the in-the skull/outside-the-skull,  and objective/ 
<br />
subjective.
<br />
<br />I just use the fact that you say &quot;yes&quot; to a doctor &quot;qua  
<br />
computatio&quot; (with or without MAT).
<br />
<br /><br /><br /><em class="quotelev1">&gt; Therefore, the resulting Lucky Alice must be exactly
</em><br />
<em class="quotelev1">&gt; as conscious as Fully-Functional Alice.&quot;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; To me, this argument doesn't have the full rigor of a mathematical
</em><br />
<em class="quotelev1">&gt; proof, because it's not entirely clear what the mechanist-materialists
</em><br />
<em class="quotelev1">&gt; really mean when they say that Fully-Functional Alice is conscious,
</em><br />
<br /><br />Consciousness does not need to be defined more precisely than it is  
<br />
needed for saying &quot;yes&quot; to the doctor qua computatio, like a  
<br />
naturalist could say &quot;yes&quot; for an artificial heart.
<br />
Consciousness and (primitive) Matter don't need to be defined more  
<br />
precisely than needed to understand the physical supervenience thesis.
<br />
Despite term like &quot;existence of a primitive physical universe&quot; or the  
<br />
very general &quot;supervenience&quot; term itself.
<br />
You could have perhaps still a problem with the definitions or with  
<br />
the hypotheses?
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; and it's not clear whether or not they would agree that &quot;none of her
</em><br />
<em class="quotelev1">&gt; exterior or interior behavior changes (in any way that's relevant)&quot;.
</em><br />
<em class="quotelev1">&gt; There *is* an objective physical difference between Fully-Functional
</em><br />
<em class="quotelev1">&gt; Alice and Lucky Alice - it's precisely the (discoverable, physical)
</em><br />
<em class="quotelev1">&gt; fact that her neurons are all being stimulated by cosmic rays rather
</em><br />
<em class="quotelev1">&gt; than by each other.
</em><br />
<br /><br /><br />There is an objective difference between very young Alice with her  
<br />
&quot;biological brain&quot; and very young Alice the day after the digital  
<br />
graft. But taking both MEC and MAT together, you cannot use that  
<br />
difference. If you want use that difference, you have to make change  
<br />
to MEC and/or to MAT. You can always be confused by the reasoning in a  
<br />
way which pushes you to (re)consider MEC or MAT, and to interpret them  
<br />
more vaguely so that those changes are made possible. But then we  
<br />
learn nothing &quot;clear&quot; from the reasoning. We learn if we do the same,  
<br />
but precisely.
<br />
<br /><br /><br /><br /><br /><em class="quotelev1">&gt; I don't see why the mechanist-materialists are
</em><br />
<em class="quotelev1">&gt; logically disallowed from incorporating that kind of physical
</em><br />
<em class="quotelev1">&gt; difference into their notion of consciousness.
</em><br />
<br /><br />In our setting, it means that the neuron/logic gates have some form of  
<br />
prescience.
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Of course, in practice, Lucky Alice presents a conundrum for such
</em><br />
<em class="quotelev1">&gt; mechanist-materialists. But it's not obvious to me that the conundrum
</em><br />
<em class="quotelev1">&gt; is unanswerable for them, because the whole notion of &quot;consciousness&quot;
</em><br />
<em class="quotelev1">&gt; in this context seems so vague.
</em><br />
<br />No, what could be vague is the idea of linking consciousness with  
<br />
matter, but that is the point of the reasoning. If we keep comp, we  
<br />
have to (re)define the general notion of matter.
<br />
<br /><br /><br /><em class="quotelev1">&gt; Bostrom's views about fractional
</em><br />
<em class="quotelev1">&gt; &quot;quantities&quot; of experience are a case in point.
</em><br />
<br />If that was true, why would you say &quot;yes&quot; to the doctor without  
<br />
knowing the thickness of the artificial axons?
<br />
How can you be sure your consciousness will not half diminish when the  
<br />
doctor proposes to you the new cheaper brain which use thinner fibers,  
<br />
or half the number of redundant security fibers (thanks to a progress  
<br />
in security software)?
<br />
I would no more dare to say &quot;yes&quot; to the doctor if I could loose a  
<br />
fraction of my consciousness and become a partial zombie.
<br />
<br /><br /><em class="quotelev1">&gt; He clearly takes a
</em><br />
<em class="quotelev1">&gt; mechanist-materialist view of consciousness,
</em><br />
<br /><br />Many believes in naturalism. At least, its move shows that he is aware  
<br />
of the difficulty of the mind body problem. But he has to modify comp  
<br />
deeply, for making its move meaningful.
<br />
If anything physical/geometrical about the neurons is needed, let the  
<br />
digital machine take into account that physical/geometrical feature.  
<br />
This means, let the level be refined. But once the level is correctly  
<br />
choose, comp forces us to abstract from the functioning of the  
<br />
elementary boolean gates.
<br />
<br /><br /><em class="quotelev1">&gt; and he believes that a
</em><br />
<em class="quotelev1">&gt; grid of randomly-flipping bits cannot be conscious,
</em><br />
<br /><br />(I am ok with that. I mean, this will remain true both with comp and  
<br />
NON MAT).
<br />
<br /><br /><br /><em class="quotelev1">&gt; no matter what it
</em><br />
<em class="quotelev1">&gt; does. He would argue that, during Fully-Functional Alice's slide into
</em><br />
<em class="quotelev1">&gt; Lucky Alice, her subjective quality of consciousness doesn't change,
</em><br />
<em class="quotelev1">&gt; but her &quot;quantity&quot; of consciousness gradually reduces until it becomes
</em><br />
<em class="quotelev1">&gt; zero. That seems weird to me, but I don't see how to &quot;logically prove&quot;
</em><br />
<em class="quotelev1">&gt; that it's wrong. All I have are messy philosophical arguments and
</em><br />
<em class="quotelev1">&gt; thought experiments - what Dennett calls &quot;intuition pumps&quot;.
</em><br />
<br /><br /><br />Because I would have to say NO to the doctor who proposes me a digital  
<br />
neural net with &quot;infinitesimally&quot; or very thin but solid fibers&quot;. I  
<br />
would become a zombie if Bostrom is right. Bostrom does not use the  
<br />
digital MEC hypothesis.
<br />
<br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That being said, I'm happy to proceed as if our hypothetical  
</em><br />
<em class="quotelev1">&gt; mechanist-
</em><br />
<em class="quotelev1">&gt; materialists have accepted the force of your argument as a logical
</em><br />
<em class="quotelev1">&gt; proof. Yes, they claim, given the assumptions of our mechanism-
</em><br />
<em class="quotelev1">&gt; materialism, if Fully-Functional Alice is conscious, Lucky Alice must
</em><br />
<em class="quotelev1">&gt; *necessarily* also be conscious. If the laser-graph is conscious, then
</em><br />
<em class="quotelev1">&gt; the movie of it must *necessarily* be conscious. What's the problem
</em><br />
<em class="quotelev1">&gt; (they ask)? On to MGA 3.
</em><br />
<br /><br />Hmmm.... (asap). Still disentangling MGA 3 and MGA 4 ...
<br />
<br />Bruno
<br />
<br /><br /><a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
<br />
<br /><br /><br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue Nov 25 2008 - 13:54:52 PST</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start15449">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="15450.html" title="Next message in the list">Brent Meeker: "Re: MGA 1"</a></li>
<li><dfn>Previous message</dfn>: <a href="15448.html" title="Previous message in the list">Kory Heath: "Re: MGA 2"</a></li>
<li><dfn>In reply to</dfn>: <a href="15447.html" title="Message to which this message replies">Kory Heath: "Re: MGA 1"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="15450.html" title="Next message in this discussion thread">Brent Meeker: "Re: MGA 1"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="15450.html" title="Message sent in reply to this message">Brent Meeker: "Re: MGA 1"</a></li>
<li><dfn>Reply</dfn>: <a href="15455.html" title="Message sent in reply to this message">Kory Heath: "Re: MGA 1"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg15449" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg15449" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg15449" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg15449" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:15 PST
</em></small></p>
</body>
</html>
