<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: How would a computer know if it were conscious? from Bruno Marchal on 2007-06-05 (everything)</title>
<meta name="Author" content="Bruno Marchal (marchal.domain.name.hidden)" />
<meta name="Subject" content="Re: How would a computer know if it were conscious?" />
<meta name="Date" content="2007-06-05" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: How would a computer know if it were conscious?</h1>
<!-- received="Tue Jun  5 10:12:16 2007" -->
<!-- isoreceived="20070605171216" -->
<!-- sent="Tue, 5 Jun 2007 16:12:09 +0200" -->
<!-- isosent="20070605141209" -->
<!-- name="Bruno Marchal" -->
<!-- email="marchal.domain.name.hidden" -->
<!-- subject="Re: How would a computer know if it were conscious?" -->
<!-- id="99682fb966f6db910944d3cac039299d.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20070603195217.7769A14F6BC.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13472" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13473.html" accesskey="d" title="Brent Meeker: &quot;Re: How would a computer know if it were conscious?&quot;">Next message</a> ]
[ <a href="13471.html" title="Stathis Papaioannou: &quot;Re: How would a computer know if it were conscious?&quot;">Previous message</a> ]
[ <a href="13446.html" title="Hal Finney: &quot;Re: How would a computer know if it were conscious?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13475.html" accesskey="t" title="Tom Caylor: &quot;Re: How would a computer know if it were conscious?&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13472" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13472" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13472" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13472" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Bruno Marchal &lt;<a href="mailto:marchal.domain.name.hidden?Subject=Re%3A%20How%20would%20a%20computer%20know%20if%20it%20were%20conscious%3F">marchal.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 5 Jun 2007 16:12:09 +0200</span><br />
</address>
<br />
Le 03-juin-07, à 21:52, Hal Finney a écrit :
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; Part of what I wanted to get at in my thought experiment is the
</em><br />
<em class="quotelev1">&gt; bafflement and confusion an AI should feel when exposed to human ideas
</em><br />
<em class="quotelev1">&gt; about consciousness.  Various people here have proffered their own
</em><br />
<em class="quotelev1">&gt; ideas, and we might assume that the AI would read these suggestions,
</em><br />
<em class="quotelev1">&gt; along with many other ideas that contradict the ones offered here.
</em><br />
<em class="quotelev1">&gt; It seems hard to escape the conclusion that the only logical response
</em><br />
<em class="quotelev1">&gt; is for the AI to figuratively throw up its hands and say that it is
</em><br />
<em class="quotelev1">&gt; impossible to know if it is conscious, because even humans cannot agree
</em><br />
<em class="quotelev1">&gt; on what consciousness is.
</em><br />
<br /><br /><br /><br />Augustin said about (subjective) *time* that he knows perfectly what it 
<br />
is, but that if you ask him to say what it is, then he admits being 
<br />
unable to say anything. I think that this applies to &quot;consciousness&quot;. 
<br />
We know what it is, although only in some personal and uncommunicable 
<br />
way.
<br />
Now this happens to be true also for many mathematical concept. 
<br />
Strictly speaking we don't know how to define the natural numbers, and 
<br />
we know today that indeed we cannot define them in a communicable way, 
<br />
that is without assuming the auditor knows already what they are.
<br />
<br />So what can we do. We can do what mathematicians do all the time. We 
<br />
can abandon the very idea of *defining* what consciousness is, and try 
<br />
instead to focus on principles or statements about which we can agree 
<br />
that they apply to consciousness. Then we can search for (mathematical) 
<br />
object obeying to such or similar principles. This can be made easier 
<br />
by admitting some theory or realm for consciousness like the idea that 
<br />
consciousness could apply to *some* machine or to some *computational 
<br />
events&quot; etc.
<br />
<br />We could agree for example that:
<br />
1) each one of us know what consciousness is, but nobody can prove 
<br />
he/she/it is conscious.
<br />
2) consciousness is related to inner personal or self-referential 
<br />
modality
<br />
etc.
<br />
<br />This is how I proceed in &quot;Conscience et Mécanisme&quot;.  (&quot;conscience&quot; is 
<br />
the french for consciousness, &quot;conscience morale&quot; is the french for the 
<br />
english &quot;conscience&quot;).
<br />
<br /><br /><br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; In particular I don't think an AI could be expected to claim that it
</em><br />
<em class="quotelev1">&gt; knows that it is conscious, that consciousness is a deep and intrinsic
</em><br />
<em class="quotelev1">&gt; part of itself, that whatever else it might be mistaken about it could
</em><br />
<em class="quotelev1">&gt; not be mistaken about being conscious.  I don't see any logical way it
</em><br />
<em class="quotelev1">&gt; could reach this conclusion by studying the corpus of writings on the
</em><br />
<em class="quotelev1">&gt; topic.  If anyone disagrees, I'd like to hear how it could happen.
</em><br />
<br /><br /><br />As far as a machine is correct, when she introspects herself, she 
<br />
cannot not discover a gap between truth (p) and provability (Bp). The 
<br />
machine can discover correctly (but not necessarily in a completely 
<br />
communicable way) a gap between provability (which can potentially 
<br />
leads to falsities, despite correctness) and the incorrigible 
<br />
knowability or knowledgeability (Bp &amp; p), and then the gap between 
<br />
those notions and observability (Bp &amp; Dp) and sensibility (Bp &amp; Dp &amp; 
<br />
p). Even without using the conventional name of &quot;consciousness&quot;,  
<br />
machines can discover semantical fixpoint playing the role of non 
<br />
expressible but true statements.
<br />
We can *already* talk with machine about those true unnameable things, 
<br />
as have done Tarski, Godel, Lob, Solovay, Boolos, Goldblatt, etc.
<br />
<br /><br /><br /><br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; And the corollary to this is that perhaps humans also cannot 
</em><br />
<em class="quotelev1">&gt; legitimately
</em><br />
<em class="quotelev1">&gt; make such claims, since logically their position is not so different
</em><br />
<em class="quotelev1">&gt; from that of the AI.  In that case the seemingly axiomatic question of
</em><br />
<em class="quotelev1">&gt; whether we are conscious may after all be something that we could be
</em><br />
<em class="quotelev1">&gt; mistaken about.
</em><br />
<br /><br />This is an inference from &quot;I cannot express p&quot; to &quot;I can express not 
<br />
p&quot;. Or from ~Bp to B~p.  Many atheist reason like that about the 
<br />
concept of &quot;unameable&quot; reality, but it is a logical error.
<br />
Even for someone who is not willing to take the comp hyp into 
<br />
consideration, it is a third person communicable fact that 
<br />
self-observing machines can discover and talk about many non 3-provable 
<br />
and sometimes even non 3-definable true &quot;statements&quot; about them. Some 
<br />
true statements can only be interrogated.
<br />
Personally I don' think we can be *personally* mistaken about our own 
<br />
consciousness even if we can be mistaken about anything that 
<br />
consciousness could be about.
<br />
<br />Bruno
<br />
<br /><br /><a href="http://iridia.ulb.ac.be/~marchal/">http://iridia.ulb.ac.be/~marchal/</a>
<br />
<br /><br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue Jun 05 2007 - 10:12:16 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13472">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13473.html" title="Next message in the list">Brent Meeker: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13471.html" title="Previous message in the list">Stathis Papaioannou: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13446.html" title="Message to which this message replies">Hal Finney: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13475.html" title="Next message in this discussion thread">Tom Caylor: "Re: How would a computer know if it were conscious?"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="13475.html" title="Message sent in reply to this message">Tom Caylor: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Reply</dfn>: <a href="13599.html" title="Message sent in reply to this message">David Nyman: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13472" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13472" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13472" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13472" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
