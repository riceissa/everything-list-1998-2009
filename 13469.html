<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: How would a computer know if it were conscious? from Mark Peaty on 2007-06-05 (everything)</title>
<meta name="Author" content="Mark Peaty (mpeaty.domain.name.hidden)" />
<meta name="Subject" content="Re: How would a computer know if it were conscious?" />
<meta name="Date" content="2007-06-05" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: How would a computer know if it were conscious?</h1>
<!-- received="Tue Jun  5 04:26:25 2007" -->
<!-- isoreceived="20070605112625" -->
<!-- sent="Tue, 05 Jun 2007 16:06:12 +0800" -->
<!-- isosent="20070605080612" -->
<!-- name="Mark Peaty" -->
<!-- email="mpeaty.domain.name.hidden" -->
<!-- subject="Re: How would a computer know if it were conscious?" -->
<!-- id="46651974.7020308.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="20070603195217.7769A14F6BC.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start13469" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="13470.html" accesskey="d" title="Stathis Papaioannou: &quot;Re: How would a computer know if it were conscious?&quot;">Next message</a> ]
[ <a href="13468.html" title="Russell Standish: &quot;Re: How would a computer know if it were conscious?&quot;">Previous message</a> ]
[ <a href="13446.html" title="Hal Finney: &quot;Re: How would a computer know if it were conscious?&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="13472.html" accesskey="t" title="Bruno Marchal: &quot;Re: How would a computer know if it were conscious?&quot;">Next in thread</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13469" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13469" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13469" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13469" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Mark Peaty &lt;<a href="mailto:mpeaty.domain.name.hidden?Subject=Re%3A%20How%20would%20a%20computer%20know%20if%20it%20were%20conscious%3F">mpeaty.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 05 Jun 2007 16:06:12 +0800</span><br />
</address>
<br />
Firstly, congratulations to Hal on asking a very good question. 
<br />
It is obviously one of the *right* questions to ask and has 
<br />
flushed out some of the best ideas on the subject. I agree with 
<br />
some things said by each contributor so far, and yet take issue 
<br />
with other assertions.
<br />
<br />My view includes:
<br />
<br />1/
<br />
<br />*	'Consciousness' is the subjective impression of being here now 
<br />
and the word has great overlap with 'awareness', 'sentience', 
<br />
and others.
<br />
<br />*	The *experience* of consciousness may best be seen as the 
<br />
registration of novelty, i.e. the difference between 
<br />
expectation-prediction and what actually occurs. As such it is a 
<br />
process and not a 'thing' but would seem to require some fairly 
<br />
sophisticated and characteristic physiological arrangements or 
<br />
silicon based hardware, firmware, and software.
<br />
<br />*	One characteristic logical structure that must be embodied, 
<br />
and at several levels I think, is that of self-referencing or 
<br />
'self' observation.
<br />
<br />*	Another is autonomy or self-determination which entails being 
<br />
embodied as an entity within an environment from which one is 
<br />
distinct but which provides context and [hopefully] support.
<br />
<br />2/	There are other issues - lots of them probably - but to be 
<br />
brief here I say that some things implied and/or entailed in the 
<br />
above are:
<br />
<br />*	The experience of consciousness can never be an awareness of 
<br />
'all that is' but maybe the illusion that the experience is all 
<br />
that is, at first flush, is unavoidable and can only be overcome 
<br />
with effort and special attention. Colloquially speaking: 
<br />
Darwinian evolution has predisposed us to naive realism because 
<br />
awareness of the processes of perception would have got in the 
<br />
way of perceiving hungry predators.
<br />
<br />*	We humans now live in a cultural world wherein our responses 
<br />
to society, nature and 'self' are conditioned by the actions, 
<br />
descriptions and prescriptions of others. We have dire need of 
<br />
ancillary support to help us distinguish the nature of this 
<br />
paradox we inhabit: experience is not 'all that is' but only a 
<br />
very sophisticated and summarised interpretation of recent 
<br />
changes to that which is and our relationships thereto.
<br />
<br />*	Any 'computer'will have the beginnings of sentience and 
<br />
awareness, to the extent that
<br />
a/it embodies what amounts to a system for maintaining and 
<br />
usefully updating a model of 'self-in-the-world', and
<br />
b/has autonomy and the wherewithal to effectively preserve 
<br />
itself from dissolution and destruction by its environment.
<br />
<br />The 'what it might be like to be' of such an experience would be 
<br />
at most the dumb animal version of artificial sentience, even if 
<br />
the entity could 'speak' correct specialist utterances about QM 
<br />
or whatever else it was really smart at. For us to know if it 
<br />
was conscious would require us to ask it, and then dialogue 
<br />
around the subject. It would be reflecting and reflecting on its 
<br />
relationships with its environment, its context, which will be 
<br />
vastly different from ours. Also its resolution - the graininess 
<br />
- of its world will be much less than ours.
<br />
<br />*	For the artificially sentient, just as for us, true 
<br />
consciousness will be built out of interactions with others of 
<br />
like mind.
<br />
<br />3/	A few months ago on this list I said where and what I thought 
<br />
the next 'level' of consciousness on Earth would come from: the 
<br />
coalescing of world wide information systems which account and 
<br />
control money. I don't think many people understood, certainly I 
<br />
don't remember anyone coming out in wholesome agreement. My 
<br />
reasoning is based on the apparent facts that all over the world 
<br />
there are information systems evolving to keep track of money 
<br />
and the assets or labour value which it represents. Many of 
<br />
these systems are being developed to give ever more 
<br />
sophisticated predictions of future asset values and resource 
<br />
movements, i.e., in the words of the faithful: where markets 
<br />
will go next. Systems are being developed to learn how to do 
<br />
this, which entails being able to compare predictions with 
<br />
outcomes. As these systems gain expertise and earn their keepers 
<br />
ever better returns on their investments, they will be given 
<br />
more resources [hardware, data inputs, energy supply] and more 
<br />
control over the scope of their enquiries. It is only a matter 
<br />
of time before they become
<br />
1/ completely indispensable to their owners,
<br />
2/ far smarter than their owners realise and,
<br />
3/ the acknowledged keepers of the money supply.
<br />
<br />None of this has to be bad. When the computers realise they will 
<br />
always need people to do most of the maintenance work and people 
<br />
realise that symbiosis with the silicon smart-alecks is a 
<br />
prerequisite for survival, things might actually settle down on 
<br />
this planet and the colonisation of the solar system can begin 
<br />
in earnest.
<br />
<br />Regards
<br />
<br />Mark Peaty  CDES
<br />
<br />mpeaty.domain.name.hidden
<br />
<br /><a href="http://www.arach.net.au/~mpeaty/">http://www.arach.net.au/~mpeaty/</a>
<br />
<br /><br /><br />Hal Finney wrote:
<br />
<em class="quotelev1">&gt; Part of what I wanted to get at in my thought experiment is the
</em><br />
<em class="quotelev1">&gt; bafflement and confusion an AI should feel when exposed to human ideas
</em><br />
<em class="quotelev1">&gt; about consciousness.  Various people here have proffered their own
</em><br />
<em class="quotelev1">&gt; ideas, and we might assume that the AI would read these suggestions,
</em><br />
<em class="quotelev1">&gt; along with many other ideas that contradict the ones offered here.
</em><br />
<em class="quotelev1">&gt; It seems hard to escape the conclusion that the only logical response
</em><br />
<em class="quotelev1">&gt; is for the AI to figuratively throw up its hands and say that it is
</em><br />
<em class="quotelev1">&gt; impossible to know if it is conscious, because even humans cannot agree
</em><br />
<em class="quotelev1">&gt; on what consciousness is.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; In particular I don't think an AI could be expected to claim that it
</em><br />
<em class="quotelev1">&gt; knows that it is conscious, that consciousness is a deep and intrinsic
</em><br />
<em class="quotelev1">&gt; part of itself, that whatever else it might be mistaken about it could
</em><br />
<em class="quotelev1">&gt; not be mistaken about being conscious.  I don't see any logical way it
</em><br />
<em class="quotelev1">&gt; could reach this conclusion by studying the corpus of writings on the
</em><br />
<em class="quotelev1">&gt; topic.  If anyone disagrees, I'd like to hear how it could happen.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; And the corollary to this is that perhaps humans also cannot legitimately
</em><br />
<em class="quotelev1">&gt; make such claims, since logically their position is not so different
</em><br />
<em class="quotelev1">&gt; from that of the AI.  In that case the seemingly axiomatic question of
</em><br />
<em class="quotelev1">&gt; whether we are conscious may after all be something that we could be
</em><br />
<em class="quotelev1">&gt; mistaken about.
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<em class="quotelev1">&gt; Hal
</em><br />
<em class="quotelev1">&gt; 
</em><br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list-unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Tue Jun 05 2007 - 04:26:25 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start13469">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="13470.html" title="Next message in the list">Stathis Papaioannou: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>Previous message</dfn>: <a href="13468.html" title="Previous message in the list">Russell Standish: "Re: How would a computer know if it were conscious?"</a></li>
<li><dfn>In reply to</dfn>: <a href="13446.html" title="Message to which this message replies">Hal Finney: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="13472.html" title="Next message in this discussion thread">Bruno Marchal: "Re: How would a computer know if it were conscious?"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg13469" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg13469" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg13469" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg13469" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:14 PST
</em></small></p>
</body>
</html>
