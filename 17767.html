<?xml version="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>Re: Dreaming On from David Nyman on 2009-09-10 (everything)</title>
<meta name="Author" content="David Nyman (david.nyman.domain.name.hidden)" />
<meta name="Subject" content="Re: Dreaming On" />
<meta name="Date" content="2009-09-10" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>Re: Dreaming On</h1>
<!-- received="Thu Sep 10 14:56:55 2009" -->
<!-- isoreceived="20090910215655" -->
<!-- sent="Thu, 10 Sep 2009 14:56:55 +0100" -->
<!-- isosent="20090910135655" -->
<!-- name="David Nyman" -->
<!-- email="david.nyman.domain.name.hidden" -->
<!-- subject="Re: Dreaming On" -->
<!-- id="b0b263660909100656j3af691b7q4595e0ee0c8fecc4.domain.name.hidden" -->
<!-- charset="ISO-8859-1" -->
<!-- inreplyto="4df8d851-e09e-4f69-b4cf-504eac21a5cd.domain.name.hidden" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start17767" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="17768.html" accesskey="d" title="ronaldheld: &quot;Re: Brain-computer interface and quantum robots&quot;">Next message</a> ]
[ <a href="17766.html" title="John Mikes: &quot;Re: Brain-computer interface and quantum robots&quot;">Previous message</a> ]
[ <a href="17764.html" title="Flammarion: &quot;Re: Dreaming On&quot;">In reply to</a> ]
<!-- unextthread="start" -->
[ <a href="17770.html" accesskey="t" title="Brent Meeker: &quot;Re: Dreaming On&quot;">Next in thread</a> ]
 [ <a href="#replies">Replies</a> ]
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg17767" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg17767" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg17767" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg17767" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: David Nyman &lt;<a href="mailto:david.nyman.domain.name.hidden?Subject=Re%3A%20Dreaming%20On">david.nyman.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Thu, 10 Sep 2009 14:56:55 +0100</span><br />
</address>
<br />
2009/9/9 Flammarion &lt;peterdjones.domain.name.hidden&gt;:
<br />
<br /><em class="quotelev2">&gt;&gt; What you say above seems pretty much in sympathy with the reductio
</em><br />
<em class="quotelev2">&gt;&gt; arguments based on arbitrariness of implementation.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It is strictly an argument against the claim that
</em><br />
<em class="quotelev1">&gt; computation causes consciousness , as opposed
</em><br />
<em class="quotelev1">&gt; to the claim that mental states are identical to computational
</em><br />
<em class="quotelev1">&gt; states.
</em><br />
<br />I'm not sure I see what distinction you're making.  If as you say the
<br />
realisation of computation in a physical system doesn't cause
<br />
consciousness, that would entail that no physically-realised
<br />
computation could be identical to any mental state. This is what
<br />
follows if one accepts the argument from MGA or Olympia that
<br />
consciousness does not attach to physical states qua computatio.
<br />
<br /><em class="quotelev2">&gt;&gt; But CTM is not engaged on such a project; in fact it entails
</em><br />
<em class="quotelev2">&gt;&gt; the opposite conclusion: i.e. by stipulating its type-token identities
</em><br />
<em class="quotelev2">&gt;&gt; purely functionally it requires that a homogeneous phenomenal state
</em><br />
<em class="quotelev2">&gt;&gt; must somehow be associated with a teeming plurality of heterogeneous
</em><br />
<em class="quotelev2">&gt;&gt; physical states.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It doesn't suggest that any mental state can be associated with any
</em><br />
<em class="quotelev1">&gt; phsycial
</em><br />
<em class="quotelev1">&gt; state.
</em><br />
<br />It doesn't need to say that to be obscure as a physical theory.  The
<br />
point is that it can ex hypothesi say nothing remotely physically
<br />
illuminating about what causes a mental state.  To say that it results
<br />
whenever a physical system implements a specific computation is to say
<br />
nothing physical about that system other than to insist that it is
<br />
'physical'.
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It has been accused of overdoing  Multiple Realisability, but MR
</em><br />
<em class="quotelev1">&gt; can be underdone as well.
</em><br />
<br />I agree.  Nonetheless, when two states are functionally equivalent one
<br />
can still say what it is about them that is physically relevant.  For
<br />
example, in driving from A to B it is functionally irrelevant to my
<br />
experience whether my car is fuelled by petrol or diesel.  But there
<br />
is no ambiguity about the physical details of my car trip or precisely
<br />
how either fuel contributes to this effect.
<br />
<br /><em class="quotelev2">&gt;&gt; Various arguments - Olympia, MGA, the Chinese Room etc. - seek to
</em><br />
<em class="quotelev2">&gt;&gt; expose the myriad physical implausibilities consequential on such
</em><br />
<em class="quotelev2">&gt;&gt; implementation independence.  But the root of all this is that CTM
</em><br />
<em class="quotelev2">&gt;&gt; makes impossible at the outset any possibility of linking a phenomenal
</em><br />
<em class="quotelev2">&gt;&gt; state to any unique, fully-explicated physical reduction.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That's probably a good thing. We want to be able to say that
</em><br />
<em class="quotelev1">&gt; two people with fine-grained differences in their brain structure
</em><br />
<em class="quotelev1">&gt; can both be (for instance) apprehensiveness.
</em><br />
<br />Yes, I agree.  But if we're after a physical theory, we also want to
<br />
be able to give in either case a clear physical account of their
<br />
apprehensiveness, which would include a physical justification of why
<br />
the fine-grained differences make no difference at the level of
<br />
experience.
<br />
<br /><em class="quotelev2">&gt;&gt; If nothing
</em><br />
<em class="quotelev2">&gt;&gt; physical can in principle be ruled out as an explanation for
</em><br />
<em class="quotelev2">&gt;&gt; experience,
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That isn't an implication of CTM. CTM can regard computers as
</em><br />
<em class="quotelev1">&gt; a small subset of physical systems, and conscious computers as
</em><br />
<em class="quotelev1">&gt; a small subset of computers.
</em><br />
<br />Yes, but we needn't push &quot;nothing physical&quot; to the extent of random
<br />
association to make the point at issue.  The relevant point is that,
<br />
in picking out the subset of physical systems solely qua computatio,
<br />
no kind of physical realisation is capable of being ruled out in
<br />
principle.  That is unproblematic in the usual case because our
<br />
interest is restricted to the computational output of such systems,
<br />
and we are unconcerned by the physical details that occasion this.
<br />
But if we are seeking a physical explanation of consciousness, then it
<br />
is precisely the coupling of the physical process and the mental
<br />
process which requires explication in a physical theory, and this is
<br />
now obscured from any general resolution by the computational posit.
<br />
<br /><em class="quotelev2">&gt;&gt; no uniquely-justified physical explanation need - or in
</em><br />
<em class="quotelev2">&gt;&gt; practice could - be explicated.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I don't think &quot;unique justification&quot; is a requirement
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt;The detailed implausibilities
</em><br />
<em class="quotelev2">&gt;&gt; variously invoked all fall out of this.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; So if a physical theory of mind is what is needed, CTM would seem to
</em><br />
<em class="quotelev2">&gt;&gt; fail even as a candidate because its arbitrariness with respect to
</em><br />
<em class="quotelev2">&gt;&gt; physical realisation renders it incapable of grounding consciousness
</em><br />
<em class="quotelev2">&gt;&gt; in any specific fundamental physical reduction.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; MR is not complete arbitrariness.
</em><br />
<br />I can only suppose that complete arbitrariness would be a random
<br />
association between physical states and mental states.  This is not
<br />
what is meant by arbitrary realisation.  What is meant is that the
<br />
requirement that a physical system be deemed conscious purely in
<br />
virtue of its implementing a computation rules out no particular kind
<br />
of physical realisation.  Consequently a theory of this type is
<br />
incapable of explicating general principles of physical-mental
<br />
association independent of its functional posit.
<br />
<br /><em class="quotelev1">&gt; If CTM had the implication that one material
</em><br />
<em class="quotelev1">&gt; system could realise more than one computation, then there
</em><br />
<em class="quotelev1">&gt; would be a conflict with the phsyical supervenience principle.
</em><br />
<br />I agree.
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; But CTM only has the implication that one computation
</em><br />
<em class="quotelev1">&gt; system could be realised more on more than one
</em><br />
<em class="quotelev1">&gt; material system.
</em><br />
<br />Yes, but the upshot is that CTM is reduced to the theory that
<br />
conscious states can be associated with material systems only in a
<br />
manner that ex hypothesi must obscure any prospect of a general
<br />
reduction of their detailed material causes, because any such causes
<br />
could only be specific to each realisation.  Doesn't that make CTM
<br />
somewhat spurious as a materialist theory of consciousness?
<br />
<br /><em class="quotelev2">&gt;&gt;Indeed, its success could only be in direct
</em><br />
<em class="quotelev2">&gt;&gt; opposition to the principles of materialist reductive theory.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I don't think that follows at all.
</em><br />
<br />Shouldn't the business of a physical theory be to seek general
<br />
physical principles that lead to a detailed physical reduction?
<br />
<br />David
<br />
<br /><em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; On 09 Sep, 01:39, David Nyman &lt;david.ny....domain.name.hidden&gt; wrote:
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   1. Computationalism in general associates that consciousness with a
</em><br />
<em class="quotelev3">&gt;&gt; &gt; specific comptuer programme, programme C let's say.
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   2. Let us combine that with the further claim that programme C
</em><br />
<em class="quotelev3">&gt;&gt; &gt; causes cosnciousness, somehow leveraging the physical causality of the
</em><br />
<em class="quotelev3">&gt;&gt; &gt; hardware it is running on.
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   3. A corrolary of that is that running programme C will always
</em><br />
<em class="quotelev3">&gt;&gt; &gt; cause the same effect.
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   4. Running a programme on hardware is a physical process with
</em><br />
<em class="quotelev3">&gt;&gt; &gt; physical effects.
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   5. It is in the nature of causality that the same kind of cause
</em><br />
<em class="quotelev3">&gt;&gt; &gt; produces the same kind of effects-- that is, causaliy attaches to
</em><br />
<em class="quotelev3">&gt;&gt; &gt; types not tokens.
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   6. Running a programme on hardware will cause physical effects, and
</em><br />
<em class="quotelev3">&gt;&gt; &gt; these will be determined by the kind of physical hardware. (Valve
</em><br />
<em class="quotelev3">&gt;&gt; &gt; computers will generate heat, cogwheel computers will generate noise,
</em><br />
<em class="quotelev3">&gt;&gt; &gt; etc).
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   7. Therefore, running programme C on different kinds of hardware
</em><br />
<em class="quotelev3">&gt;&gt; &gt; will not produce a uniform effect as required by 1.
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   8. Programmes do not have a physical typology: they are not natural
</em><br />
<em class="quotelev3">&gt;&gt; &gt; kinds. In that sense they are abstract. (Arguably, that is not as
</em><br />
<em class="quotelev3">&gt;&gt; &gt; abstract as the square root of two, since they still have physical
</em><br />
<em class="quotelev3">&gt;&gt; &gt; tokens. There may be more than one kind or level of abstraction).
</em><br />
<em class="quotelev3">&gt;&gt; &gt;   9. Conclusion: even running programmes are not apt to cause
</em><br />
<em class="quotelev3">&gt;&gt; &gt; consciousness. They are still too abstract.
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; What you say above seems pretty much in sympathy with the reductio
</em><br />
<em class="quotelev2">&gt;&gt; arguments based on arbitrariness of implementation.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It is strictly an argument against the claim that
</em><br />
<em class="quotelev1">&gt; computation causes consciousness , as opposed
</em><br />
<em class="quotelev1">&gt; to the claim that mental states are identical to computational
</em><br />
<em class="quotelev1">&gt; states.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; As you say above &quot;consciousness might depend on specific properties of
</em><br />
<em class="quotelev2">&gt;&gt; hardware, of matter&quot;.  If so, this would demand an explicitly physical
</em><br />
<em class="quotelev2">&gt;&gt; theory of mind, and such a 'Searlian' project would consequently seek
</em><br />
<em class="quotelev2">&gt;&gt; to associate a specific phenomenal state with specific physical
</em><br />
<em class="quotelev2">&gt;&gt; events.  But CTM is not engaged on such a project; in fact it entails
</em><br />
<em class="quotelev2">&gt;&gt; the opposite conclusion: i.e. by stipulating its type-token identities
</em><br />
<em class="quotelev2">&gt;&gt; purely functionally it requires that a homogeneous phenomenal state
</em><br />
<em class="quotelev2">&gt;&gt; must somehow be associated with a teeming plurality of heterogeneous
</em><br />
<em class="quotelev2">&gt;&gt; physical states.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It doesn't suggest that any mental state can be associated with any
</em><br />
<em class="quotelev1">&gt; phsycial
</em><br />
<em class="quotelev1">&gt; state.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It has been accused of overdoing  Multiple Realisability, but MR
</em><br />
<em class="quotelev1">&gt; can be underdone as well.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Various arguments - Olympia, MGA, the Chinese Room etc. - seek to
</em><br />
<em class="quotelev2">&gt;&gt; expose the myriad physical implausibilities consequential on such
</em><br />
<em class="quotelev2">&gt;&gt; implementation independence.  But the root of all this is that CTM
</em><br />
<em class="quotelev2">&gt;&gt; makes impossible at the outset any possibility of linking a phenomenal
</em><br />
<em class="quotelev2">&gt;&gt; state to any unique, fully-explicated physical reduction.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That's probably a good thing. We want to be able to say that
</em><br />
<em class="quotelev1">&gt; two people with fine-grained differences in their brain structure
</em><br />
<em class="quotelev1">&gt; can both be (for instance) apprehensiveness.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; If nothing
</em><br />
<em class="quotelev2">&gt;&gt; physical can in principle be ruled out as an explanation for
</em><br />
<em class="quotelev2">&gt;&gt; experience,
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; That isn't an implication of CTM. CTM can regard computers as
</em><br />
<em class="quotelev1">&gt; a small subset of physical systems, and conscious computers as
</em><br />
<em class="quotelev1">&gt; a small subset of computers.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; no uniquely-justified physical explanation need - or in
</em><br />
<em class="quotelev2">&gt;&gt; practice could - be explicated.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I don't think &quot;unique justification&quot; is a requirement
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt;The detailed implausibilities
</em><br />
<em class="quotelev2">&gt;&gt; variously invoked all fall out of this.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; So if a physical theory of mind is what is needed, CTM would seem to
</em><br />
<em class="quotelev2">&gt;&gt; fail even as a candidate because its arbitrariness with respect to
</em><br />
<em class="quotelev2">&gt;&gt; physical realisation renders it incapable of grounding consciousness
</em><br />
<em class="quotelev2">&gt;&gt; in any specific fundamental physical reduction.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; MR is not complete arbitrariness.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Indeed defences of
</em><br />
<em class="quotelev2">&gt;&gt; functionalism against its various critics never cite any physical
</em><br />
<em class="quotelev2">&gt;&gt; grounds for the plausibility of conscious supervenience on the
</em><br />
<em class="quotelev2">&gt;&gt; physical composition of, say, the Chinese room, but focus instead on
</em><br />
<em class="quotelev2">&gt;&gt; defending the functional relevance of various features of the
</em><br />
<em class="quotelev2">&gt;&gt; experimental setup.  Hence, without an explicitly physical, as opposed
</em><br />
<em class="quotelev2">&gt;&gt; to functional, criterion for what counts as a 'physical' explanation,
</em><br />
<em class="quotelev2">&gt;&gt; it is hard to see how CTM is compatible with any intelligible notion
</em><br />
<em class="quotelev2">&gt;&gt; of materialism.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; It is compatible with materialism because brains and computers
</em><br />
<em class="quotelev1">&gt; are material. If CTM had the implication that one material
</em><br />
<em class="quotelev1">&gt; system could realise more than one computation, then there
</em><br />
<em class="quotelev1">&gt; would be a conflict with the phsyical supervenience principle.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; But CTM only has the implication that one computation
</em><br />
<em class="quotelev1">&gt; system could be realised more on more than one
</em><br />
<em class="quotelev1">&gt; material system.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt;Indeed, its success could only be in direct
</em><br />
<em class="quotelev2">&gt;&gt; opposition to the principles of materialist reductive theory.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev1">&gt; I don't think that follows at all.
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt;&gt; Isn't
</em><br />
<em class="quotelev2">&gt;&gt; that a reasonable conclusion?
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev2">&gt;&gt; David
</em><br />
<em class="quotelev2">&gt;&gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<em class="quotelev2">&gt; &gt;
</em><br />
<em class="quotelev1">&gt;
</em><br />
<br />--~--~---------~--~----~------------~-------~--~----~
<br />
You received this message because you are subscribed to the Google Groups &quot;Everything List&quot; group.
<br />
To post to this group, send email to everything-list.domain.name.hidden
<br />
To unsubscribe from this group, send email to everything-list+unsubscribe.domain.name.hidden
<br />
For more options, visit this group at <a href="http://groups.google.com/group/everything-list?hl=en">http://groups.google.com/group/everything-list?hl=en</a>
<br />
-~----------~----~----~----~------~----~------~--~---
<br />
<span id="received"><dfn>Received on</dfn> Thu Sep 10 2009 - 14:56:55 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start17767">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="17768.html" title="Next message in the list">ronaldheld: "Re: Brain-computer interface and quantum robots"</a></li>
<li><dfn>Previous message</dfn>: <a href="17766.html" title="Previous message in the list">John Mikes: "Re: Brain-computer interface and quantum robots"</a></li>
<li><dfn>In reply to</dfn>: <a href="17764.html" title="Message to which this message replies">Flammarion: "Re: Dreaming On"</a></li>
<!-- lnextthread="start" -->
<li><dfn>Next in thread</dfn>: <a href="17770.html" title="Next message in this discussion thread">Brent Meeker: "Re: Dreaming On"</a></li>
<li><a name="replies" id="replies"></a>
<dfn>Reply</dfn>: <a href="17770.html" title="Message sent in reply to this message">Brent Meeker: "Re: Dreaming On"</a></li>
<li><dfn>Reply</dfn>: <a href="17776.html" title="Message sent in reply to this message">Flammarion: "Re: Dreaming On"</a></li>
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg17767" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg17767" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg17767" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg17767" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:16 PST
</em></small></p>
</body>
</html>
