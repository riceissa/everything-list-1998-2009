<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1" />
<meta name="generator" content="hypermail 2.3.0, see http://www.hypermail-project.org/" />
<title>SIA and the presumptuous philosopher from Wei Dai on 2002-08-13 (everything)</title>
<meta name="Author" content="Wei Dai (weidai.domain.name.hidden)" />
<meta name="Subject" content="SIA and the presumptuous philosopher" />
<meta name="Date" content="2002-08-13" />
<style type="text/css">
/*<![CDATA[*/
/* To be incorporated in the main stylesheet, don't code it in hypermail! */
body {color: black; background: #ffffff}
dfn {font-weight: bold;}
pre { background-color:inherit;}
.head { border-bottom:1px solid black;}
.foot { border-top:1px solid black;}
th {font-style:italic;}
table { margin-left:2em;}map ul {list-style:none;}
#mid { font-size:0.9em;}
#received { float:right;}
address { font-style:inherit ;}
/*]]>*/
.quotelev1 {color : #990099}
.quotelev2 {color : #ff7700}
.quotelev3 {color : #007799}
.quotelev4 {color : #95c500}
.period {font-weight: bold}
</style>
</head>
<body>
<div class="head">
<h1>SIA and the presumptuous philosopher</h1>
<!-- received="Tue Aug 13 19:52:05 2002" -->
<!-- isoreceived="20020814025205" -->
<!-- sent="Tue, 13 Aug 2002 19:48:00 -0700" -->
<!-- isosent="20020814024800" -->
<!-- name="Wei Dai" -->
<!-- email="weidai.domain.name.hidden" -->
<!-- subject="SIA and the presumptuous philosopher" -->
<!-- id="20020813194759.A11872.domain.name.hidden" -->
<!-- charset="iso-8859-1" -->
<!-- expires="-1" -->
<map id="navbar" name="navbar">
<ul class="links">
<li>
<dfn>This message</dfn>:
[ <a href="#start3929" name="options1" id="options1" tabindex="1">Message body</a> ]
 [ More options (<a href="#options2">top</a>, <a href="#options3">bottom</a>) ]
</li>
<li>
<dfn>Related messages</dfn>:
<!-- unext="start" -->
[ <a href="3930.html" accesskey="d" title="Tim May: &quot;Re: modal logic and possible worlds&quot;">Next message</a> ]
[ <a href="3928.html" title="Wei Dai: &quot;Re: modal logic and possible worlds&quot;">Previous message</a> ]
<!-- unextthread="start" -->
<!-- ureply="end" -->
</li>
</ul>
</map>
<ul class="links">
<li><a name="options2" id="options2"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg3929" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg3929" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg3929" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg3929" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</div>
<!-- body="start" -->
<div class="mail">
<address class="headers">
<span id="from">
<dfn>From</dfn>: Wei Dai &lt;<a href="mailto:weidai.domain.name.hidden?Subject=Re%3A%20SIA%20and%20the%20presumptuous%20philosopher">weidai.domain.name.hidden</a>&gt;
</span><br />
<span id="date"><dfn>Date</dfn>: Tue, 13 Aug 2002 19:48:00 -0700</span><br />
</address>
<br />
When making decisions without knowing which observer moment you're at,
<br />
there are two equivalent ways to go about it if you can ignore game
<br />
theoretic considerations (meaning there is no reason to expect a
<br />
non-Pareto-optimal outcome). You can think of yourself as being at all of
<br />
the candidate observer moments, or at just one of them. In my &quot;framework
<br />
for multiverse decision theory&quot; post, I used the latter approach because
<br />
it's more general - it works even when game theoretic concerns are
<br />
present. However, when they are not, the first approach gives an
<br />
additional prespective on the problem.
<br />
<br />Consider a thought experiment from Nick Bostrom's Ph.d. thesis (available
<br />
at <a href="http://www.anthropic-principle.com/phd/phdhtml.html">http://www.anthropic-principle.com/phd/phdhtml.html</a>), which is meant to
<br />
show the counterintuitiveness of the self indication axiom (SIA):
<br />
<br />It is the year 2100 and physicists have narrowed down the search for a 
<br />
theory of everything to only two remaining plausible candidate theories, 
<br />
T1 and T2 (using considerations from super-duper symmetry). According to 
<br />
T1 the world is very, very big but finite, and there are a total of a 
<br />
trillion trillion observers in the cosmos. According to T2, the world is 
<br />
very, very, very big but finite, and there are a trillion trillion 
<br />
trillion observers. The super-duper symmetry considerations seem to be 
<br />
roughly indifferent between these two theories. The physicists are 
<br />
planning on carrying out a simple experiment that will falsify one of the 
<br />
theories. Enter the presumptuous philosopher: &quot;Hey guys, it is completely 
<br />
unnecessary for you to do the experiment, because I can already show to 
<br />
you that T2 is about a trillion times more likely to be true than T1 
<br />
(whereupon the philosopher runs the God&#x2019;s Coin Toss thought experiment and 
<br />
explains Model 3)!&quot;
<br />
<br />One suspects the Nobel Prize committee to be a bit hesitant about awarding 
<br />
the presumptuous philosopher the big one for this contribution.
<br />
(end quote)
<br />
<br />First, let me add some details to make the problem more precise. Suppose
<br />
that there are two possible multiverses, one of which is real. The first
<br />
contains one universe, W1, and the second contains one universe, W2. T1 is
<br />
true for W1 and T2 is true for W2. W2 consists of one trillion identical
<br />
copies of a space-time region whose history is identical to W1 until the
<br />
time of the experiment. You are the observer in W1 or his one trillion
<br />
counterparts in W2 who is in charge of deciding whether or not to perform
<br />
the experiment. The cost of doing the experiment is $1 (per copy). The
<br />
cost of not doing the experiment and just assuming that T2 is true is $x
<br />
(for W1 only; think of this as money wasted trying to contact the other
<br />
copies).  Both costs are your personal responsibility.
<br />
<br />So here are the two ways of thinking about this problem:
<br />
<br />1. You are either in W1 or are all of the one trillion copies in W2. Let 
<br />
the probability of you being in W1 be p. The expected utility of doing the 
<br />
experiment is U(experiment) = p*U(lose $1) + (1-p)*U(one trillion copies 
<br />
each lose $1). U(do not experiment) = p*U(lose $x). Clearly SIA should not 
<br />
be applied in this case, because the trillion multiplier is already taken 
<br />
into account in &quot;U(one trillion copies each lose $1)&quot;, and there is no 
<br />
other relevant information to make use of, so p = 0.5 seems reasonable.
<br />
<br />2. You are either in W1 or are one of the one trillion copies in W2. Let 
<br />
the probability of you being in W1 be q. U(experiment) = U(lose $1). U(do 
<br />
not experiment) = q*U(lose $x). 
<br />
<br />Suppose p = 0.5, what would q have to be so that 1 and 2 both reach the 
<br />
same conclusion? Let's assume that x is chosen so that you are indifferent 
<br />
between experiment and not experiment. That means:
<br />
<br />U(experiment) = p*U(lose $1) + (1-p)*U(one trillion copies each lose $1) = 
<br />
U(do not experiment) = p*U(lose $x)
<br />
U(lose $1) + U(one trillion copies each lose $1) = U(lose $x)
<br />
<br />and
<br />
<br />U(experiment) = U(lose $1) = U(do not experiment) = q*U(lose $x)
<br />
<br />so
<br />
<br />q = U(lose $1) / U(lose $x)
<br />
&nbsp;&nbsp;= U(lose $1) / (U(lose $1) + U(one trillion copies each lose $1))
<br />
<br />So it turns out that SIA is true if and only if U(one trillion copies each 
<br />
lose $1) = 10^12 * U(lose $1), and on the other hand q = 0.5 if and only 
<br />
if U(lose $1) = U(one trillion copies each lose $1). I argue that neither 
<br />
should be assumed in general. It's a subjective value judgement how much 
<br />
worse it is for one trillion copies to lose $1 than for one copy to lose 
<br />
$1. It could be any number between 1 and 10^12, depending on one's 
<br />
personal philosophy about the value of identical copies. (Where does the 
<br />
intution that the presumptuous philosopher does not deserve the Nobel 
<br />
Prize come from? If must be that most of us do not think it's anywhere 
<br />
near 10^12 times worse.) But that means q, despite being named a 
<br />
probability, is also a matter of value judgement. There can be no 
<br />
principle of rational reasoning (such as the SIA) that uniquely determines 
<br />
what q should be.
<br />
<br />Well not quite. I cheated a bit above in analysis 2. U(experiment) is 
<br />
actually q * U(lose $1 | T1) + (1-q) * U(lose $1 | T2), so I actually 
<br />
implicitly assumed that U(lose $1 | T1) = U(lose $1 | T2). What if we hold 
<br />
q fixed and look at what U(lose $1 | T2) would have to be to make you 
<br />
indifferent between experiment and not experiment? Some algebraic 
<br />
manipulation shows U(lose $1 | T2) = q/(1-q)*U(one trillion copies each 
<br />
lose $1). So if we assume q = 0.5, then U(lose $1 | T2) = U(one trillion 
<br />
copies each lose $1), and if we assume instead the SIA, so that q = 
<br />
1/(10^12+1), then U(lose $1 | T2) = U(one trillion copies each lose $1) / 
<br />
10^12. 
<br />
<br />So now we have three choices. Either make q a matter of value judgement,
<br />
or choose q = 0.5, or the SIA. I think q = 0.5 can be ruled out first,
<br />
because U(lose $1 | T2) = U(one trillion copies each lose $1) is
<br />
completely unintuitive. The SIA is problematic when there are potentially
<br />
infinite number of observers. Suppose we replace &quot;trillion copies&quot; with
<br />
&quot;infinite number of copies&quot; in this thought experiment. Then the SIA
<br />
implies q = 0 and U(lose $1 | T2) = 0, which makes no sense. That
<br />
leaves q a matter of value judgement, which seems somewhat unsatisfactory
<br />
also. But perhaps it's the best solution we can get.
<br />
<span id="received"><dfn>Received on</dfn> Tue Aug 13 2002 - 19:52:05 PDT</span>
</div>
<!-- body="end" -->
<div class="foot">
<map id="navbarfoot" name="navbarfoot" title="Related messages">
<ul class="links">
<li><dfn>This message</dfn>: [ <a href="#start3929">Message body</a> ]</li>
<!-- lnext="start" -->
<li><dfn>Next message</dfn>: <a href="3930.html" title="Next message in the list">Tim May: "Re: modal logic and possible worlds"</a></li>
<li><dfn>Previous message</dfn>: <a href="3928.html" title="Previous message in the list">Wei Dai: "Re: modal logic and possible worlds"</a></li>
<!-- lnextthread="start" -->
<!-- lreply="end" -->
</ul>
<ul class="links">
<li><a name="options3" id="options3"></a><dfn>Contemporary messages sorted</dfn>: [ <a href="date.html#msg3929" title="Contemporary messages by date">by date</a> ] [ <a href="index.html#msg3929" title="Contemporary discussion threads">by thread</a> ] [ <a href="subject.html#msg3929" title="Contemporary messages by subject">by subject</a> ] [ <a href="author.html#msg3929" title="Contemporary messages by author">by author</a> ] [ <a href="attachment.html" title="Contemporary messages by attachment">by messages with attachments</a> ]</li>
</ul>
</map>
</div>
<!-- trailer="footer" -->
<p><small><em>
This archive was generated by <a href="http://www.hypermail-project.org/">hypermail 2.3.0</a>
: Fri Feb 16 2018 - 13:20:07 PST
</em></small></p>
</body>
</html>
